---
title: "Communication dynamics in OSS communities"
output:
  html_document:
    keep_md: yes
    number_sections: yes
    toc: true
---

This R markdown provides the data preparation for our forthcoming manuscript
(Paxton, Varoquaux, Geiger, & Holdgraf, *in preparation*).

To run this from scratch, you will need the following files:

* `../../data/analysis_data/sentiment_frame_tickets-for_r.csv`: Contains cleaned
**posts**-related data (sometimes also referred to as *tickets*) and 
derived variables from scraped GitHub data.
* `../../data/analysis_data/sentiment_frame_comments-for_r.csv`: Contains
cleaned **comments**-related data and derived variables from scraped GitHub
data.
* `./utils/ossc-libraries_and_functions.r`: Loads in necessary libraries and
creates new functions for our analyses.
* `./utils/data-loading.R`: loads functions related to data loading and
preprocessing.

**Code written by**: A. Paxton (University of Connecticut) & N. Varoquaux
(CNRS)

**Date last compiled**:  `r Sys.time()`

```{r silent-preparations, include=FALSE}
library(knitr)
knitr::opts_chunk$set(cache=TRUE, autodep=TRUE, cache.lazy=FALSE)
options(scipen=999)
```

***

# Preliminaries

```{r prelim, warning = FALSE, error = FALSE, message = FALSE}

# clear everything
rm(list=ls())

# load libraries and add new functions
source('./utils/ossc-libraries_and_functions.r')
source("./utils/data-loading.R")
```

```{r choosing_dataset}

# select the dataset we'll be working on
tickets_frame = loading_tickets_data(dataset="original")
comments_frame = loading_comments_data(dataset="original")

```

***

## Basic summary stats

The data have been largely cleaned by the time we load them. 
Let's take a look at some basic patterns in the aggregate and
broken down by specific projects.

```{r user-stats, include=FALSE, eval=TRUE}

# get unique values
unique_commenters = as.character(unique(comments_frame$author_name))
unique_ticketers = as.character(unique(tickets_frame$author_name))
unique_users = as.character(unique(append(unique_commenters, unique_ticketers)))

```

```{r activity-stats, echo=FALSE, eval=TRUE, message=FALSE}

# get counts of ticket activity per project
ticket_projectwise_counts = tickets_frame %>% ungroup() %>%
  dplyr::select(project, id, ticket_family) %>%
  distinct() %>%
  group_by(project, ticket_family) %>%
  summarize(unique_tickets = n()) %>%
  mutate(ticket_family = as.character(ticket_family))

# get counts of post activity by post type
ticket_familywise_counts = tickets_frame %>% ungroup() %>%
  dplyr::select(project, id, ticket_family) %>%
  distinct() %>%
  group_by(ticket_family) %>%
  summarize(unique_tickets = n()) %>%
  mutate(ticket_family = as.character(ticket_family))

# get counts of comment activity per project
comment_projectwise_counts = comments_frame %>% ungroup() %>%
  dplyr::select(project, id, ticket_id, type) %>%
  distinct() %>%
  group_by(project,type) %>%
  summarize(unique_comments = n()) %>%
  mutate(type = ifelse(type == "issue_reply",
                       "issue",
                       "pr"))

# get counts of comment activity by post type
comment_familywise_counts = comments_frame %>% ungroup() %>%
  dplyr::select(project, id, ticket_id, type) %>%
  distinct() %>%
  group_by(type) %>%
  summarize(unique_comments = n()) %>%
  mutate(type = ifelse(type == "issue_reply",
                       "issue",
                       "pr"))

# bind the two
contribution_projectwise_counts = dplyr::full_join(ticket_projectwise_counts, comment_projectwise_counts,
                                                   by=c('project',
                                                        'ticket_family'='type'))
contribution_familywise_counts = dplyr::full_join(ticket_familywise_counts, comment_familywise_counts,
                                                  by=c('ticket_family'='type'))

# print the table and then clean up a bit
pander(contribution_familywise_counts, style = 'rmarkdown')
pander(contribution_projectwise_counts, style = 'rmarkdown')

# save out some variables we'll need

# grab total overview stats
unique_total_projects = dim(contribution_projectwise_counts)[1]/2
unique_commenters = length(unique_commenters)
unique_posters = length(unique_ticketers)
unique_users = length(unique_users)

# grab posted issue stats
unique_posted_issues = contribution_familywise_counts %>% 
  dplyr::filter(ticket_family=='issue') %>% 
  .$unique_tickets
mean_issues_per_project = mean(contribution_projectwise_counts %>% 
                                 dplyr::filter(ticket_family=='issue') %>% 
                                 .$unique_tickets)

# grab posted pr stats
unique_posted_prs = contribution_familywise_counts %>% 
  dplyr::filter(ticket_family=='pr') %>% 
  .$unique_tickets
mean_prs_per_project = mean(contribution_projectwise_counts %>% 
                              dplyr::filter(ticket_family=='pr') %>% 
                              .$unique_tickets)

# grab issue comment stats
unique_issue_comments = contribution_familywise_counts %>% 
  dplyr::filter(ticket_family=='issue') %>% .$unique_comments
mean_issue_comments_per_project = mean(contribution_projectwise_counts %>% 
                                         dplyr::filter(ticket_family=='issue') %>% 
                                         .$unique_comments)

# grab PR comment stats
unique_pr_comments = contribution_familywise_counts %>% 
  dplyr::filter(ticket_family=='pr') %>% 
  .$unique_comments
mean_pr_comments_per_project = mean(contribution_projectwise_counts %>% 
                                      dplyr::filter(ticket_family=='pr') %>% 
                                      .$unique_comments)

```

Our dataset includes `r unique_total_projects` unique projects. The dataset has
total of `r unique_posted_issues` unique posted issues, with a mean of 
`r mean_issues_per_project` posted issues per project. It also includes a total of 
`r unique_posted_prs` unique posted pull requests, with a mean of 
`r mean_prs_per_project` posted pull requests per project.

On these contributions, the dataset includes
`r unique_issue_comments` unique comments on issues and 
`r unique_pr_comments` unique comments on pull requests. This includes an average of
`r mean_issue_comments_per_project` comments on issues per project and an average of 
`r mean_pr_comments_per_project` 
comments on pull requests per project.

In total, we have `r unique_commenters` unique commenters,
`r unique_posters` unique post creators, and
`r unique_users` overall unique users.

***

# Data analysis

***

## Model Series 1: Sentiment analysis

***

### Data preparation

Before we can run Model Series 1, we need to combine `tickets_frame` and
`comments_frame` into a single dataframe. We do this using the
`combine_tickets_and_comments` function, `defined in utils/data-loading.R`

```{r prepare-data-for-sentiment-analysis, message=FALSE}
sentiment_frame = combine_tickets_and_comments(tickets_frame, comments_frame)
```

```{r save-sentiment-frame, echo=FALSE}
# For plotting purposes

dir.create("results/data", showWarnings=FALSE, recursive=TRUE)
write.table(sentiment_frame,
            file="results/data/sentiment_frame_original.tsv",
            sep="\t")
```

***

### Model 1.1: Do different kinds of activities materially differ in emotion?

<!-- Now we begin the actual modeling. Our first general question is whether users' -->
<!-- patterns of sentiment differ materially by whether they are a member of the -->
<!-- community versus a nonmember of the community and by their different kinds of -->
<!-- possible contributions (i.e., a posted pull request, a reply to a pull request, -->
<!-- a posted issue, or a reply to an issue). -->

<!-- #### Model 1.1a: Overall effects with linear mixed-effects models -->

<!-- This model presents the analyses in a way that is typical of psychological -->
<!-- analyses. We predict the changes in emotion by community membership and  -->
<!-- activity type, including random effects for project and for author. This -->
<!-- allows us to explore the general patterns of the main and interaction terms, -->
<!-- rather than focusing in on the project-specific variability. -->

<!-- ```{r model-emotion-by-type-and-author} -->

<!-- # do posts and comments materially differ in emotion? -->
<!-- creators_v_commenters_emotion_by_project = lmer(compound_emotion ~ type * author_group  + -->
<!--                                                   (1 | project) + (1 | author_name), -->
<!--                                                 data = sentiment_frame, -->
<!--                                                 REML = FALSE) -->

<!-- ``` -->

<!-- ```{r print-model-emotion-by-type-and-author, eval=TRUE, echo=FALSE} -->

<!-- # print results -->
<!-- pander_lme(creators_v_commenters_emotion_by_project) -->

<!-- ``` -->

<!-- While we see significant differences in the model, interpreting the results is -->
<!-- difficult because of the way that `lmer` handles factor comparisons. All  -->
<!-- factors are compared against a "reference level," the first level in the model. -->
<!-- This makes intepreting models with factors that include more than two levels -->
<!-- incredibly difficult, because the intercept is essentially an interaction term -->
<!-- among all reference levels of all factors. -->

<!-- As a result, we turn to the biostatistics approach of multiple *t*-tests  -->
<!-- (corrected for comparisons) of the model estimates to better understand the  -->
<!-- effects. -->

<!-- #### Model 1.1b: In-depth investigation through *t*-tests of model estimates -->

First, we build a series of linear mixed-effects models with one term included
in each model (either main term or interaction term). We then use the estimates
from those models to perform *t*-tests to investigate how different levels of
the effects differ from one another (and not just from the model-level 
intercept).

Projects here are random effects, but the rest of the model is the same as 
before. This allows us to do pairwise testing of main and interaction terms,
along with better exploring inter-project variability.

#### Model 1.1a: Does sentiment vary significantly by community membership?

First, look at whether there are differences in sentiment between author 
groups.

```{r model-emotion-by-author-group}

# do members and nonmembers materially differ in emotion?
fixed_creators_v_commenters_emotion = lmer(
  compound_emotion ~ 0 + author_group + (1 | author_name) + (1 | project),
  data=sentiment_frame,
  REML=FALSE)

```

Run *t*-tests among levels and prepare for the Model 1.1 table later.

```{r clean-up-model-1.1a-output}

# convert Model 1.1a output to dataframe
coefficients_and_se = data.frame(
  summary(fixed_creators_v_commenters_emotion)$coefficients)

# get comparison names as rownames
row_names = gsub("author_group", "", 
                 gsub("type", "", row.names(coefficients_and_se)))

# convert model estimates to a dataframe
means = coefficients_and_se$Estimate
names(means) = row_names

# convert standard error to dataframe
se = coefficients_and_se$Std..Error
names(se) = row_names

# compute t-statistics and p-values for desired contrasts
contrasts = c("member-nonmember")
author_groups_tests = compute_t_statistics(
  means, se,
  contrasts)
author_groups_tests[, "p_value"] = compute_p_value_from_t_stats(
  author_groups_tests$t_stats)
```

```{r saving_results-model-1.1a}
dir.create("results/models", showWarnings=FALSE)
write.table(coefficients_and_se,
            file="results/models/model-1.1b1.tsv",
            sep="\t")

```

#### Model 1.1b: Does sentiment vary significantly across activity types?

Now, look at whether there are differences in sentiment between activity
types.

```{r model-emotion-by-type}

# do posts and comments materially differ in emotion?
fixed_types_emotion = lmer(
  compound_emotion ~ 0 + type + (1 | author_name) + (1 | project),
  data=sentiment_frame,
  REML=FALSE)

```

Run *t*-tests among levels and prepare for the Model 1.1 table later.

```{r clean-up-model-1.1b-output}

# convert Model 1.1b output to dataframe
coefficients_and_se = data.frame(
  summary(fixed_types_emotion)$coefficients)

# get comparison names as rownames
row_names = gsub("author_group", "", 
                 gsub("type", "", row.names(coefficients_and_se)))

# convert model estimates to a dataframe
means = coefficients_and_se$Estimate
names(means) = row_names

# convert standard error to dataframe
se = coefficients_and_se$Std..Error
names(se) = row_names

# compute t-statistics and p-values for desired contrasts
contrasts = c("issue_post-issue_reply", # issues: posts vs. replies
              "pr_post-pr_reply",       # PRs: posts vs. replies
              "issue_post-pr_post",     # posts: issues vs. PRs
              "issue_reply-pr_reply")   # replies: issues vs. PRs
types_tests = compute_t_statistics(
  means, se,
  contrasts)
types_tests[, "p_value"] = compute_p_value_from_t_stats(types_tests$t_stats)

```

```{r saving_results-model-1.1b}
write.table(coefficients_and_se,
            file="results/models/model-1.1b2.tsv",
            sep="\t")
```


#### Model 1.1c: Does sentiment vary significantly across community memberships and activity types?

Finally, let's look at the interaction between membership and activity.

```{r model-emotion-by-type-and-author-interaction-only}

# does emotion differ by the interaction between activity and authorship group?
community_contribution_emotion = lmer(
  compound_emotion ~ 0 + type:author_group + (1 | author_name) + (1 | project),
  data=sentiment_frame,
  REML=FALSE)

```

Run *t*-tests among levels and prepare for the Model 1.1 table later.

```{r clean-up-model-1.1c-output}

# convert Model 1.1c output to dataframe
coefficients_and_se = data.frame(
  summary(community_contribution_emotion)$coefficients)

# get comparison names as rownames
row_names = gsub("author_group", "", gsub("type", "", row.names(coefficients_and_se)))

# convert model estimates to a dataframe
means = coefficients_and_se$Estimate
names(means) = row_names

# convert standard error to dataframe
se = coefficients_and_se$Std..Error
names(se) = row_names

# compute t-statistics and p-values for desired contrasts
contrasts = c(
  "issue_post:member-issue_post:nonmember",     # activity static (issue posts); membership varies (members v. nonmembers)
  "issue_reply:member-issue_reply:nonmember",   # activity static (issue replies); membership varies (members v. nonmembers)
  "pr_post:member-pr_post:nonmember",           # activity static (PR posts); membership varies (members v. nonmembers)
  "pr_reply:member-pr_reply:nonmember",         # activity static (PR replies); membership varies (members v. nonmembers)
  "issue_post:member-issue_reply:member",       # activity varies (issue posts vs. issue replies); membership static (members)
  "issue_post:nonmember-issue_reply:nonmember", # activity varies (issue posts vs. issue replies); membership static (nonmembers)
  "pr_post:member-pr_reply:member",             # activity varies (PR posts vs. PR replies); membership static (members)
  "pr_post:nonmember-pr_reply:nonmember",       # activity varies (PR posts vs. PR replies); membership static (nonmembers)
  "issue_post:member-pr_post:member",           # activity varies (issue posts vs. PR posts); membership static (members)
  "issue_post:nonmember-pr_post:nonmember",     # activity varies (issue posts vs. PR posts); membership static (nonmembers)
  "issue_reply:member-pr_reply:member",         # activity varies (issue replies vs. PR replies); membership static (members)
  "issue_reply:nonmember-pr_reply:nonmember")   # activity varies (issue replies vs. PR replies); membership static (nonmembers)
types_author_groups_tests = compute_t_statistics(
  means, se,
  contrasts)
types_author_groups_tests[, "p_value"] = compute_p_value_from_t_stats(
  types_author_groups_tests$"t_stats")

```

```{r saving_results-model-1.1c}
write.table(coefficients_and_se,
            file="results/models/model-1.1b3.tsv",
            sep="\t")
```


#### Model 1.1d : Do different kinds of activities differ in emotion by projects?

Now adding projects into the mix to understand how the previous analysis
varies across projects.

```{r model-emotion-by-type-and-author-and-project}

# do posts and comments materially differ in emotion by projects?
creators_v_commenters_emotion_by_project = lmer(
  compound_emotion ~ 0 + project:type:author_group + (1 | author_name),
  data = sentiment_frame,
  REML = FALSE)

```

Run *t*-tests among levels and prepare for the Model 1.1 table later.

```{r clean-up-model-1.1d-output}

# convert Model 1.1d output to dataframe
coefficients_and_se = data.frame(
  summary(creators_v_commenters_emotion_by_project)$coefficients)

# get comparison names as rownames
row_names = gsub(
  "project", "", gsub(
    "author_group", "", gsub(
      "type", "", row.names(coefficients_and_se))))

# replace hyphens in project names with periods
row_names = gsub(
  "scikit-", "scikit.", gsub(
    "sphinx-", "sphinx.", row_names))

# convert model estimates to a dataframe
means = coefficients_and_se$Estimate
names(means) = row_names

# convert standard error to dataframe
se = coefficients_and_se$Std..Error
names(se) = row_names

# compute t-statistics and p-values for desired contrasts
# (note: ordering of contrasts within each project is identical to Model 1.1c)
contrasts = c(
  
  # scikit-learn
  "scikit.learn:issue_post:member-scikit.learn:issue_post:nonmember",   
  "scikit.learn:issue_reply:member-scikit.learn:issue_reply:nonmember",
  "scikit.learn:pr_post:member-scikit.learn:pr_post:nonmember",
  "scikit.learn:pr_reply:member-scikit.learn:pr_reply:nonmember",
  "scikit.learn:issue_post:member-scikit.learn:issue_reply:member",
  "scikit.learn:issue_post:nonmember-scikit.learn:issue_reply:nonmember",
  "scikit.learn:pr_post:member-scikit.learn:pr_reply:member",
  "scikit.learn:pr_post:nonmember-scikit.learn:pr_reply:nonmember",
  "scikit.learn:issue_post:member-scikit.learn:pr_post:member",
  "scikit.learn:issue_post:nonmember-scikit.learn:pr_post:nonmember",    
  "scikit.learn:issue_reply:member-scikit.learn:pr_reply:member",  
  "scikit.learn:issue_reply:nonmember-scikit.learn:pr_reply:nonmember",
  
  # scikit-image
  "scikit.image:issue_post:member-scikit.image:issue_post:nonmember", 
  "scikit.image:issue_reply:member-scikit.image:issue_reply:nonmember",
  "scikit.image:pr_post:member-scikit.image:pr_post:nonmember",       
  "scikit.image:pr_reply:member-scikit.image:pr_reply:nonmember",     
  "scikit.image:issue_post:member-scikit.image:issue_reply:member",
  "scikit.image:issue_post:nonmember-scikit.image:issue_reply:nonmember",
  "scikit.image:pr_post:member-scikit.image:pr_reply:member",     
  "scikit.image:pr_post:nonmember-scikit.image:pr_reply:nonmember",    
  "scikit.image:issue_post:member-scikit.image:pr_post:member",   
  "scikit.image:issue_post:nonmember-scikit.image:pr_post:nonmember",    
  "scikit.image:issue_reply:member-scikit.image:pr_reply:member",  
  "scikit.image:issue_reply:nonmember-scikit.image:pr_reply:nonmember",
  
  # matplotlib
  "matplotlib:issue_post:member-matplotlib:issue_post:nonmember", 
  "matplotlib:issue_reply:member-matplotlib:issue_reply:nonmember",
  "matplotlib:pr_post:member-matplotlib:pr_post:nonmember",       
  "matplotlib:pr_reply:member-matplotlib:pr_reply:nonmember",     
  "matplotlib:issue_post:member-matplotlib:issue_reply:member",
  "matplotlib:issue_post:nonmember-matplotlib:issue_reply:nonmember",
  "matplotlib:pr_post:member-matplotlib:pr_reply:member",     
  "matplotlib:pr_post:nonmember-matplotlib:pr_reply:nonmember",    
  "matplotlib:issue_post:member-matplotlib:pr_post:member",   
  "matplotlib:issue_post:nonmember-matplotlib:pr_post:nonmember",    
  "matplotlib:issue_reply:member-matplotlib:pr_reply:member",  
  "matplotlib:issue_reply:nonmember-matplotlib:pr_reply:nonmember",
  
  # mayavi
  "mayavi:issue_post:member-mayavi:issue_post:nonmember", 
  "mayavi:issue_reply:member-mayavi:issue_reply:nonmember",
  "mayavi:pr_post:member-mayavi:pr_post:nonmember",       
  "mayavi:pr_reply:member-mayavi:pr_reply:nonmember",     
  "mayavi:issue_post:member-mayavi:issue_reply:member",
  "mayavi:issue_post:nonmember-mayavi:issue_reply:nonmember",
  "mayavi:pr_post:member-mayavi:pr_reply:member",     
  "mayavi:pr_post:nonmember-mayavi:pr_reply:nonmember",    
  "mayavi:issue_post:member-mayavi:pr_post:member",   
  "mayavi:issue_post:nonmember-mayavi:pr_post:nonmember",    
  "mayavi:issue_reply:member-mayavi:pr_reply:member",  
  "mayavi:issue_reply:nonmember-mayavi:pr_reply:nonmember",
  
  # pandas
  "pandas:issue_post:member-pandas:issue_post:nonmember", 
  "pandas:issue_reply:member-pandas:issue_reply:nonmember",
  "pandas:pr_post:member-pandas:pr_post:nonmember",       
  "pandas:pr_reply:member-pandas:pr_reply:nonmember",     
  "pandas:issue_post:member-pandas:issue_reply:member",
  "pandas:issue_post:nonmember-pandas:issue_reply:nonmember",
  "pandas:pr_post:member-pandas:pr_reply:member",     
  "pandas:pr_post:nonmember-pandas:pr_reply:nonmember",    
  "pandas:issue_post:member-pandas:pr_post:member",   
  "pandas:issue_post:nonmember-pandas:pr_post:nonmember",    
  "pandas:issue_reply:member-pandas:pr_reply:member",  
  "pandas:issue_reply:nonmember-pandas:pr_reply:nonmember",
  
  # scipy
  "scipy:issue_post:member-scipy:issue_post:nonmember", 
  "scipy:issue_reply:member-scipy:issue_reply:nonmember",
  "scipy:pr_post:member-scipy:pr_post:nonmember",       
  "scipy:pr_reply:member-scipy:pr_reply:nonmember",     
  "scipy:issue_post:member-scipy:issue_reply:member",
  "scipy:issue_post:nonmember-scipy:issue_reply:nonmember",
  "scipy:pr_post:member-scipy:pr_reply:member",     
  "scipy:pr_post:nonmember-scipy:pr_reply:nonmember",    
  "scipy:issue_post:member-scipy:pr_post:member",   
  "scipy:issue_post:nonmember-scipy:pr_post:nonmember",    
  "scipy:issue_reply:member-scipy:pr_reply:member",  
  "scipy:issue_reply:nonmember-scipy:pr_reply:nonmember",
  
  # numpy
  "numpy:issue_post:member-numpy:issue_post:nonmember", 
  "numpy:issue_reply:member-numpy:issue_reply:nonmember",
  "numpy:pr_post:member-numpy:pr_post:nonmember",       
  "numpy:pr_reply:member-numpy:pr_reply:nonmember",     
  "numpy:issue_post:member-numpy:issue_reply:member",
  "numpy:issue_post:nonmember-numpy:issue_reply:nonmember",
  "numpy:pr_post:member-numpy:pr_reply:member",     
  "numpy:pr_post:nonmember-numpy:pr_reply:nonmember",    
  "numpy:issue_post:member-numpy:pr_post:member",   
  "numpy:issue_post:nonmember-numpy:pr_post:nonmember",    
  "numpy:issue_reply:member-numpy:pr_reply:member",  
  "numpy:issue_reply:nonmember-numpy:pr_reply:nonmember",
  
  # sphinx-gallery
  "sphinx.gallery:issue_post:member-sphinx.gallery:issue_post:nonmember", 
  "sphinx.gallery:issue_reply:member-sphinx.gallery:issue_reply:nonmember",
  "sphinx.gallery:pr_post:member-sphinx.gallery:pr_post:nonmember",       
  "sphinx.gallery:pr_reply:member-sphinx.gallery:pr_reply:nonmember",     
  "sphinx.gallery:issue_post:member-sphinx.gallery:issue_reply:member",
  "sphinx.gallery:issue_post:nonmember-sphinx.gallery:issue_reply:nonmember",
  "sphinx.gallery:pr_post:member-sphinx.gallery:pr_reply:member",     
  "sphinx.gallery:pr_post:nonmember-sphinx.gallery:pr_reply:nonmember",    
  "sphinx.gallery:issue_post:member-sphinx.gallery:pr_post:member",   
  "sphinx.gallery:issue_post:nonmember-sphinx.gallery:pr_post:nonmember",    
  "sphinx.gallery:issue_reply:member-sphinx.gallery:pr_reply:member",  
  "sphinx.gallery:issue_reply:nonmember-sphinx.gallery:pr_reply:nonmember"
)
project_types_author_group_tests = compute_t_statistics(
  means, se,
  contrasts)
project_types_author_group_tests[, "p_value"] = compute_p_value_from_t_stats(
  project_types_author_group_tests$t_stats) 

```

```{r saving_results-model-1.1d}
write.table(coefficients_and_se,
            file="results/models/model-1.1c.tsv",
            sep="\t")
```


#### Overall results

Now we bring together all analyses from Model 1.1.

```{r output-model1.1-results-table}

# specify main terms
author_groups_tests["contrast"] = row.names(author_groups_tests)
types_tests["contrast"] = row.names(types_tests)
all_tests = merge(author_groups_tests, types_tests, all=TRUE, sort=FALSE)
all_tests["model"] = "Main Terms"

# specify 2-way interactions
types_author_groups_tests["contrast"] = row.names(types_author_groups_tests)
types_author_groups_tests["model"] = "2W: Types x Author Groups"
all_tests = merge(all_tests, types_author_groups_tests, all=TRUE, sort=FALSE)

# specify 3-way interactions
project_types_author_group_tests["contrast"] = row.names(project_types_author_group_tests)
project_types_author_group_tests["model"] = "3W: Types x Author Groups x Project"
all_tests = merge(all_tests, project_types_author_group_tests, all=TRUE,
                  sort=FALSE)

```

Let's correct all tests at once for multiple comparisons.

```{r correct-and-display-all-model-1.1-tests}

# specify all contrasts
row.names(all_tests) = all_tests$contrast
all_tests = subset(all_tests, select=-c(contrast))

# print the table (reordering columns for readibility)
all_tests = all_tests[c("model", "t_stats", "p_value")]
pander_clean_anova(all_tests, rename_columns=FALSE)

```

```{r emotion_write_all_results}
all_tests$p_val_adjusted = p.adjust(all_tests$p_value, method="BH")
write.table(all_tests, file="results/models/model-1.1b_final_pvalues.tsv")
```

Finally, let's plot these effects.

```{r plot-model-emotion-by-type, echo=FALSE, eval=TRUE}

# aggregate sentiment over all projects
sentiment_plot_aggregated = ggplot(data=sentiment_frame,
                                   aes(x=type,
                                       y=compound_emotion,
                                       colour=type)) +
  stat_summary(fun.y=mean, geom="point", size=2) +
  stat_summary(fun.data = mean_se, geom = "errorbar") +
  #coord_cartesian(ylim=c(0,.5)) +
  facet_grid(cols=vars(ticket_family)) +
  ggtitle('Message sentiment by activity\nand community membership') +
  ylab('Sentiment score') +
  xlab('Community membership') +
  labs(color='Activity type') +
  scale_color_manual(labels = c("Issue: Post",
                                "Issue: Reply",
                                "PR: Post",
                                "PR: Reply"),
                     values = c("#e66101", # issue: post (darker)
                                "#fdb863", # issue: reply (lighter)
                                "#5e3c99", # PR: post (darker)
                                "#b2abd2")) # PR: reply (lighter)

```

```{r plot-model-emotion-by-type-and-membership, echo=FALSE, eval=TRUE}

# aggregate sentiment over all projects
sentiment_plot_aggregated = ggplot(data=sentiment_frame,
                                   aes(x=author_group,
                                       y=compound_emotion,
                                       colour=type)) +
  stat_summary(fun.y=mean, geom="point", size=2) +
  stat_summary(fun.data = mean_se, geom = "errorbar") +
  #coord_cartesian(ylim=c(0,.5)) +
  facet_grid(cols=vars(ticket_family)) +
  ggtitle('Message sentiment by activity\nand community membership') +
  ylab('Sentiment score') +
  xlab('Community membership') +
  labs(color='Activity type') +
  scale_color_manual(labels = c("Issue: Post",
                                "Issue: Reply",
                                "PR: Post",
                                "PR: Reply"),
                     values = c("#e66101", # issue: post (darker)
                                "#fdb863", # issue: reply (lighter)
                                "#5e3c99", # PR: post (darker)
                                "#b2abd2")) # PR: reply (lighter)

# plot a full-size version
ggsave(plot = sentiment_plot_aggregated,
       height = 4,
       width = 5,
       filename = '../../figures/sentiment_analysis/ossc-sentiment_membership_contribution-aggregated.jpg')

# plot a smaller one for knitr
ggsave(plot = sentiment_plot_aggregated,
       height = 4,
       width = 5,
       dpi = 150,
       filename = '../../figures/sentiment_analysis/ossc-sentiment_membership_contribution-aggregated-knitr.jpg')

```

![**Figure**. Sentiment by activity type and community membership at the time of posting (member vs. nonmember).](../../figures/sentiment_analysis/ossc-sentiment_membership_contribution-aggregated-knitr.jpg)

```{r plot-model-emotion-by-type-and-membership-and-project, echo=FALSE, eval=TRUE}

# separate across each project
sentiment_plot_by_project = ggplot(data=sentiment_frame,
                                   aes(x=author_group,
                                       y=compound_emotion,
                                       colour=type)) +
  stat_summary(fun.y=mean, geom="point", size=2) +
  stat_summary(fun.data = mean_se, geom = "errorbar") +
  #coord_cartesian(ylim=c(0,.5)) +
  facet_grid(cols=vars(ticket_family),
             rows=vars(project)) +
  ggtitle('Message sentiment by activity\nand community membership') +
  ylab('Sentiment score') +
  xlab('Community membership') +
  labs(color='Activity type') +
  scale_color_manual(labels = c("Issue: Post",
                                "Issue: Reply",
                                "PR: Post",
                                "PR: Reply"),
                     values = c("#e66101", # issue: post (darker)
                                "#fdb863", # issue: reply (lighter)
                                "#5e3c99", # PR: post (darker)
                                "#b2abd2")) # PR: reply (lighter)

# another possible color scheme: #ca0020, #f4a582, #92c5de, #0571b0 (red to blue)

# plot a full-size version
ggsave(plot = sentiment_plot_by_project,
       height = 10,
       width = 4,
       filename = '../../figures/sentiment_analysis/ossc-sentiment_membership_contribution-by_project.jpg')

# plot a smaller one for knitr
ggsave(plot = sentiment_plot_by_project,
       height = 10,
       width = 4,
       dpi = 150,
       filename = '../../figures/sentiment_analysis/ossc-sentiment_membership_contribution-by_project-knitr.jpg')

```

![**Figure**. Sentiment by activity type  and community membership at the time of posting (member vs. nonmember) for each project.](../../figures/sentiment_analysis/ossc-sentiment_membership_contribution-by_project-knitr.jpg)

<!-- ### Model 1.2: More plots, this time using means and std estimated from model-fit -->

<!-- Here, we are going to test whether projects differ from the mean. -->

<!-- ```{r eval=TRUE, echo=TRUE} -->
<!-- coefficients_and_se = data.frame( -->
<!--   summary(creators_v_commenters_emotion_by_project)$coefficients) -->

<!-- # get comparison names as rownames -->
<!-- row_names = gsub( -->
<!--   "project", "", gsub( -->
<!--     "author_group", "", gsub( -->
<!--       "type", "", row.names(coefficients_and_se)))) -->

<!-- # replace hyphens in project names with periods -->
<!-- row_names = gsub( -->
<!--   "scikit-", "scikit.", gsub( -->
<!--     "sphinx-", "sphinx.", row_names)) -->

<!-- # convert model estimates to a dataframe -->
<!-- means = coefficients_and_se$Estimate -->
<!-- names(means) = row_names -->

<!-- # convert standard error to dataframe -->
<!-- se = coefficients_and_se$Std..Error -->
<!-- names(se) = row_names -->
<!-- ``` -->

<!-- ```{r} -->
<!-- projects = c("Matplotlib", "Mayavi", "numpy", "pandas", -->
<!--              "scikit-image", "scikit-learn", "scipy", "sphinx-gallery") -->
<!-- ``` -->

<!-- ```{r plot_pr_post_members, fig.width=8} -->
<!-- group_of_interest = "pr_post:member" -->
<!-- rows_to_plot = grep(group_of_interest, names(means)) -->

<!-- bar_centers = barplot(means[rows_to_plot], names.arg=projects, -->
<!--                       main=group_of_interest,     -->
<!--                       cex.names=0.8) -->
<!-- arrows(bar_centers, -->
<!--        means[rows_to_plot] - se[rows_to_plot] ** 2,  -->
<!--        bar_centers, -->
<!--        means[rows_to_plot] + se[rows_to_plot] ** 2, -->
<!--        angle=90, -->
<!--        code=3) -->
<!-- ``` -->

<!-- ```{r plot_pr_post_nonmembers, fig.width=8} -->
<!-- group_of_interest = "pr_post:nonmember" -->
<!-- rows_to_plot = grep(group_of_interest, names(means)) -->

<!-- bar_centers = barplot(means[rows_to_plot], names.arg=projects, -->
<!--                       main=group_of_interest, -->
<!--                       cex.names=0.8) -->

<!-- arrows(bar_centers, -->
<!--        means[rows_to_plot] - se[rows_to_plot] ** 2,  -->
<!--        bar_centers, -->
<!--        means[rows_to_plot] + se[rows_to_plot] ** 2, -->
<!--        angle=90, -->
<!--        code=3) -->
<!-- ``` -->


<!-- ```{r plot_issue_post_members, fig.width=8} -->
<!-- group_of_interest = "issue_post:member" -->
<!-- rows_to_plot = grep(group_of_interest, names(means)) -->

<!-- bar_centers = barplot(means[rows_to_plot], names.arg=projects, -->
<!--                       main=group_of_interest, -->
<!--                       cex.names=0.8 -->
<!-- ) -->
<!-- arrows(bar_centers, -->
<!--        means[rows_to_plot] - se[rows_to_plot] ** 2,  -->
<!--        bar_centers, -->
<!--        means[rows_to_plot] + se[rows_to_plot] ** 2, -->
<!--        angle=90, -->
<!--        code=3) -->
<!-- ``` -->

<!-- ```{r plot_issue_post_nonmembers, fig.width=8} -->
<!-- group_of_interest = "issue_post:nonmember" -->
<!-- rows_to_plot = grep(group_of_interest, names(means)) -->

<!-- bar_centers = barplot(means[rows_to_plot], names.arg=projects, -->
<!--                       main=group_of_interest, -->
<!--                       cex.names=0.8 -->
<!-- ) -->
<!-- arrows(bar_centers, -->
<!--        means[rows_to_plot] - se[rows_to_plot] ** 2,  -->
<!--        bar_centers, -->
<!--        means[rows_to_plot] + se[rows_to_plot] ** 2, -->
<!--        angle=90, -->
<!--        code=3) -->
<!-- ``` -->


<!-- ```{r plot_pr_reply_members, fig.width=8} -->
<!-- group_of_interest = "pr_reply:member" -->
<!-- rows_to_plot = grep(group_of_interest, names(means)) -->

<!-- bar_centers = barplot(means[rows_to_plot], names.arg=projects, -->
<!--                       main=group_of_interest, -->
<!--                       cex.names=0.8) -->
<!-- arrows(bar_centers, -->
<!--        means[rows_to_plot] - se[rows_to_plot] ** 2,  -->
<!--        bar_centers, -->
<!--        means[rows_to_plot] + se[rows_to_plot] ** 2, -->
<!--        angle=90, -->
<!--        code=3) -->
<!-- ``` -->

<!-- ```{r plot_pr_reply_nonmembers, fig.width=8} -->
<!-- group_of_interest = "pr_reply:nonmember" -->
<!-- rows_to_plot = grep(group_of_interest, names(means)) -->

<!-- bar_centers = barplot(means[rows_to_plot], names.arg=projects, -->
<!--                       main=group_of_interest, -->
<!--                       cex.names=0.8) -->
<!-- arrows(bar_centers, -->
<!--        means[rows_to_plot] - se[rows_to_plot] ** 2,  -->
<!--        bar_centers, -->
<!--        means[rows_to_plot] + se[rows_to_plot] ** 2, -->
<!--        angle=90, -->
<!--        code=3) -->
<!-- ``` -->


<!-- ```{r plot_issue_reply_members, fig.width=8} -->
<!-- group_of_interest = "issue_reply:member" -->
<!-- rows_to_plot = grep(group_of_interest, names(means)) -->

<!-- bar_centers = barplot(means[rows_to_plot], names.arg=projects, -->
<!--                       main=group_of_interest, -->
<!--                       cex.names=0.8) -->
<!-- arrows(bar_centers, -->
<!--        means[rows_to_plot] - se[rows_to_plot] ** 2,  -->
<!--        bar_centers, -->
<!--        means[rows_to_plot] + se[rows_to_plot] ** 2, -->
<!--        angle=90, -->
<!--        code=3) -->
<!-- ``` -->

<!-- ```{r plot_issue_reply_nonmembers, fig.width=8} -->
<!-- group_of_interest = "issue_reply:nonmember" -->
<!-- rows_to_plot = grep(group_of_interest, names(means)) -->

<!-- bar_centers = barplot(means[rows_to_plot], names.arg=projects, -->
<!--                       main=group_of_interest, -->
<!--                       cex.names=0.8) -->
<!-- arrows(bar_centers, -->
<!--        means[rows_to_plot] - se[rows_to_plot] ** 2,  -->
<!--        bar_centers, -->
<!--        means[rows_to_plot] + se[rows_to_plot] ** 2, -->
<!--        angle=90, -->
<!--        code=3) -->
<!-- ``` -->

<!-- ### Model 1.1c Do projects differ in emotion between one another? -->

<!-- One versus all minus one type of approach. -->

<!-- ```{r compound_emotion_all_vs_one} -->
<!-- all_project_tests = NA -->
<!-- all_projects = unique(sentiment_frame$project) -->

<!-- # We're going to fit the model for each projects, and concatenate the results -->
<!-- # in a dataframe. Then, we'll apply multiple correction and display the -->
<!-- # results -->
<!-- for(project in all_projects){ -->
<!--   sentiment_frame$test_group = sentiment_frame$project == project -->
<!--   one_versus_all_emotion = lmer( -->
<!--     compound_emotion ~ 0 + type:author_group:test_group + (1|author_name), -->
<!--     data=sentiment_frame, -->
<!--     REML=FALSE) -->

<!--   # Clean up mode -->
<!--   coefficients_and_se = data.frame( -->
<!--     summary(one_versus_all_emotion)$coefficients) -->
<!--   row_names = gsub( -->
<!--     "author_group", "",  -->
<!--     gsub("type", "", -->
<!--          gsub("project", "", row.names(coefficients_and_se)))) -->

<!--   means = coefficients_and_se$Estimate -->
<!--   names(means) = row_names -->
<!--   se = coefficients_and_se$Std..Error -->
<!--   names(se) = row_names -->

<!--   contrasts = c( -->
<!--     "issue_post:member:test_groupTRUE-issue_post:member:test_groupFALSE", -->
<!--     "pr_post:member:test_groupTRUE-pr_post:member:test_groupFALSE", -->
<!--     "issue_reply:member:test_groupTRUE-issue_reply:member:test_groupFALSE", -->
<!--     "pr_reply:member:test_groupTRUE-pr_reply:member:test_groupFALSE", -->
<!--     "issue_post:nonmember:test_groupTRUE-issue_post:nonmember:test_groupFALSE", -->
<!--     "pr_post:nonmember:test_groupTRUE-pr_post:nonmember:test_groupFALSE", -->
<!--     "issue_reply:nonmember:test_groupTRUE-issue_reply:nonmember:test_groupFALSE", -->
<!--     "pr_reply:nonmember:test_groupTRUE-pr_reply:nonmember:test_groupFALSE" -->
<!--   ) -->

<!--   one_versus_all_emotion_tests = compute_t_statistics( -->
<!--     means, se, -->
<!--     contrasts) -->
<!--   one_versus_all_emotion_tests[, "p_value"] = compute_p_value_from_t_stats( -->
<!--     one_versus_all_emotion_tests$t_stats) -->

<!--   # Add unique identifier based on the project of interest in the table. -->
<!--   row.names(one_versus_all_emotion_tests) = gsub( -->
<!--     "test_group", project, -->
<!--     row.names(one_versus_all_emotion_tests)) -->

<!--   if(is.null(dim(all_project_tests))){ -->
<!--     all_project_tests = one_versus_all_emotion_tests -->
<!--   }else{ -->
<!--     all_project_tests = rbind( -->
<!--       all_project_tests, one_versus_all_emotion_tests) -->
<!--   } -->
<!-- } -->
<!-- ``` -->

<!-- Now apply multiple correction and display the results of the analysis. -->

<!-- ```{r one_versus_all_display_results} -->
<!-- pander_clean_anova(all_project_tests, rename_columns=FALSE) -->
<!-- ``` -->

***

### Model 1.2: Time-course analysis for sentiment

The time-course analysis has been moved in a separate file.

***

### Model 1.3: Do posts and comments materially differ in gratitude?

First, let's take a look at a summary table of expressions of gratitude by
membership status and activity type.

```{r gratitude-summary-stats, eval=TRUE, echo=TRUE}

# create a summary table of gratitude by type and author association
gratitude_summary_stats = sentiment_frame %>% ungroup() %>%
  group_by(author_group, type, grateful_count) %>%
  summarise(n = n())
pander(gratitude_summary_stats, style = 'rmarkdown')

```

Now that we have a better idea of how the underlying data look, let's go ahead
and build our model.

<!-- ```{r model-gratitude-by-type-and-author-and-project-v1, eval = TRUE} -->

<!-- # do users tend to express appreciation and gratitude differently by group and content? -->
<!-- creators_v_commenters_gratitude_by_project = lmer(log(grateful_count + 1) ~ project * author_group * type + -->
<!--                                                     (1 | author_name), -->
<!--                                                   data=sentiment_frame) -->

<!-- # print results -->
<!-- pander_lme(creators_v_commenters_gratitude_by_project) -->

<!-- ``` -->

```{r plot-gratitude-predictors-by-project, include=FALSE, eval=TRUE}
grateful_plot = ggplot(data=sentiment_frame,
                       aes(colour=type,
                           y=grateful_count,
                           x=author_group)) +
  stat_summary(fun.y=mean, geom="point", size=2) +
  stat_summary(fun.data = mean_se, geom = "errorbar") +
  facet_grid(cols = vars(ticket_family),
             rows = vars(project)) +
  ggtitle('Expressions of gratitude by activity\nand community membership') +
  ylab('Gratitude') +
  xlab('Community membership') +
  labs(color='Activity type') +
  scale_color_manual(labels = c("Issue: Post",
                                "Issue: Reply",
                                "PR: Post",
                                "PR: Reply"),
                     values = c("#e66101", # issue: post (darker)
                                "#fdb863", # issue: reply (lighter)
                                "#5e3c99", # PR: post (darker)
                                "#b2abd2")) # PR: reply (lighter)

# save full version
ggsave(plot = grateful_plot,
       height = 5,
       width = 6,
       filename = '../../figures/sentiment_analysis/ossc-grateful_membership_contribution.jpg')

# save smaller version for knitr
ggsave(plot = grateful_plot,
       height = 5,
       width = 6,
       dpi = 150,
       filename = '../../figures/sentiment_analysis/ossc-grateful_membership_contribution-knitr.jpg')

```

![**Figure**. Expressions of gratitude by activity type (posted issue, comment on issue, posted pull request, or comment on pull request) and community membership (member vs. nonmember) at the time of posting.](../../figures/sentiment_analysis/ossc-grateful_membership_contribution-knitr.jpg)

<!-- ### Testing Model 1.3 using Model 1.1 methods -->

<!-- #### Model 1.3a: Overall effects with linear mixed-effects models -->

<!-- This model presents the analyses in a way that is typical of psychological -->
<!-- analyses. We predict the changes in emotion by community membership and  -->
<!-- activity type, including random effects for project and for author. This -->
<!-- allows us to explore the general patterns of the main and interaction terms, -->
<!-- rather than focusing in on the project-specific variability. -->

<!-- ```{r retrying-model-1.3} -->

<!-- # do users tend to express appreciation and gratitude differently by group and content? -->
<!-- retrying_model_1.3 = lmer(log(grateful_count + 1) ~ author_group * type + -->
<!--                             (1 | project), -->
<!--                           data=sentiment_frame) -->

<!-- ``` -->

<!-- ```{r print-retrying-model-1.3, eval=TRUE, echo=FALSE} -->

<!-- # print results -->
<!-- pander_lme(retrying_model_1.3) -->

<!-- ``` -->

<!-- While we see significant differences in the model, interpreting the results is -->
<!-- difficult because of the way that `lmer` handles factor comparisons. All  -->
<!-- factors are compared against a "reference level," the first level in the model. -->
<!-- This makes intepreting models with factors that include more than two levels -->
<!-- incredibly difficult, because the intercept is essentially an interaction term -->
<!-- among all reference levels of all factors. -->

<!-- As a result, we turn to the biostatistics approach of multiple *t*-tests  -->
<!-- (corrected for comparisons) of the model estimates to better understand the  -->
<!-- effects. -->

<!-- #### Model 1.3b: In-depth investigation through *t*-tests of model estimates -->

First, we build a series of linear mixed-effects models with one term included
in each model (either main term or interaction term). We then use the estimates
from those models to perform *t*-tests to investigate how different levels of
the effects differ from one another (and not just from the model-level
intercept).

Projects here are random effects, but the rest of the model is the same as
before. This allows us to do pairwise testing of main and interaction terms,
along with better exploring inter-project variability.

#### Model 1.3b: Does sentiment vary significantly by community membership?

First, look at whether there are differences in sentiment between author
groups.

```{r model-gratitude-by-author-group}

# do members and nonmembers materially differ in emotion?
fixed_authors_gratitude = lmer(
  log(grateful_count + 1) ~ 0 + author_group + (1 | project),
  data=sentiment_frame,
  REML=FALSE)

```

Run *t*-tests among levels and prepare for the Model 1.3 table later.

```{r clean-up-model-1.3b-output}

# convert Model 1.3b output to dataframe
coefficients_and_se = data.frame(
  summary(fixed_authors_gratitude)$coefficients)

# get comparison names as rownames
row_names = gsub("author_group", "",
                 gsub("type", "", row.names(coefficients_and_se)))

# convert model estimates to a dataframe
means = coefficients_and_se$Estimate
names(means) = row_names

# convert standard error to dataframe
se = coefficients_and_se$Std..Error
names(se) = row_names

# compute t-statistics and p-values for desired contrasts
contrasts = c("member-nonmember")
author_groups_tests = compute_t_statistics(
  means, se,
  contrasts)
author_groups_tests[, "p_value"] = compute_p_value_from_t_stats(
  author_groups_tests$t_stats)

```

```{r saving_results-model-1.3b}
write.table(coefficients_and_se,
            file="results/models/model-1.3b1.tsv",
            sep="\t")
```

#### Model 1.3c: Does sentiment vary significantly across activity types?

Now, look at whether there are differences in sentiment between activity
types.

```{r model-gratitude-by-type}

# do posts and comments materially differ in emotion?
fixed_types_gratitude = lmer(
  log(grateful_count + 1) ~ 0 + type + (1 | project),
  data=sentiment_frame,
  REML=FALSE)

```

Run *t*-tests among levels and prepare for the Model 1.3 table later.

```{r clean-up-model-1.3c-output}

# convert Model 1.1c output to dataframe
coefficients_and_se = data.frame(
  summary(fixed_types_gratitude)$coefficients)

# get comparison names as rownames
row_names = gsub("author_group", "",
                 gsub("type", "", row.names(coefficients_and_se)))

# convert model estimates to a dataframe
means = coefficients_and_se$Estimate
names(means) = row_names

# convert standard error to dataframe
se = coefficients_and_se$Std..Error
names(se) = row_names

# compute t-statistics and p-values for desired contrasts
contrasts = c("issue_post-issue_reply", # issues: posts vs. replies
              "pr_post-pr_reply",       # PRs: posts vs. replies
              "issue_post-pr_post",     # posts: issues vs. PRs
              "issue_reply-pr_reply")   # replies: issues vs. PRs
types_tests = compute_t_statistics(
  means, se,
  contrasts)
types_tests[, "p_value"] = compute_p_value_from_t_stats(types_tests$t_stats)

```

```{r saving_results-model-1.3c}
write.table(coefficients_and_se,
            file="results/models/model-1.3b2.tsv",
            sep="\t")
```

#### Model 1.3d: Does sentiment vary significantly across community memberships and activity types?

Finally, let's look at the interaction between membership and activity.

```{r model-gratitude-by-type-and-author-interaction-only}

# does emotion differ by the interaction between activity and authorship group?
community_contribution_gratitude = lmer(
  log(grateful_count + 1) ~ 0 + type:author_group + (1 | project),
  data=sentiment_frame,
  REML=FALSE)

```

Run *t*-tests among levels and prepare for the Model 1.3 table later.

```{r clean-up-model-1.3d-output}

# convert Model 1.3d output to dataframe
coefficients_and_se = data.frame(
  summary(community_contribution_gratitude)$coefficients)

# get comparison names as rownames
row_names = gsub("author_group", "", gsub("type", "", row.names(coefficients_and_se)))

# convert model estimates to a dataframe
means = coefficients_and_se$Estimate
names(means) = row_names

# convert standard error to dataframe
se = coefficients_and_se$Std..Error
names(se) = row_names

# compute t-statistics and p-values for desired contrasts
contrasts = c(
  "issue_post:member-issue_post:nonmember",     # activity static (issue posts); membership varies (members v. nonmembers)
  "issue_reply:member-issue_reply:nonmember",   # activity static (issue replies); membership varies (members v. nonmembers)
  "pr_post:member-pr_post:nonmember",           # activity static (PR posts); membership varies (members v. nonmembers)
  "pr_reply:member-pr_reply:nonmember",         # activity static (PR replies); membership varies (members v. nonmembers)
  "issue_post:member-issue_reply:member",       # activity varies (issue posts vs. issue replies); membership static (members)
  "issue_post:nonmember-issue_reply:nonmember", # activity varies (issue posts vs. issue replies); membership static (nonmembers)
  "pr_post:member-pr_reply:member",             # activity varies (PR posts vs. PR replies); membership static (members)
  "pr_post:nonmember-pr_reply:nonmember",       # activity varies (PR posts vs. PR replies); membership static (nonmembers)
  "issue_post:member-pr_post:member",           # activity varies (issue posts vs. PR posts); membership static (members)
  "issue_post:nonmember-pr_post:nonmember",     # activity varies (issue posts vs. PR posts); membership static (nonmembers)
  "issue_reply:member-pr_reply:member",         # activity varies (issue replies vs. PR replies); membership static (members)
  "issue_reply:nonmember-pr_reply:nonmember")   # activity varies (issue replies vs. PR replies); membership static (nonmembers)
types_author_groups_tests = compute_t_statistics(
  means, se,
  contrasts)
types_author_groups_tests[, "p_value"] = compute_p_value_from_t_stats(
  types_author_groups_tests$"t_stats")

```

```{r saving_results-model-1.3d}
write.table(coefficients_and_se,
            file="results/models/model-1.3b3.tsv",
            sep="\t")
```

#### Model 1.3e : Do different kinds of activities differ in emotion by projects?

Now adding projects into the mix to understand how the previous analysis
varies across projects.

```{r model-gratitude-by-type-and-author-and-project}

# do posts and comments materially differ in gratitude by projects?
creators_v_commenters_gratitude_by_project = lm(
  log(grateful_count + 1) ~ 0 + project:type:author_group,
  data = sentiment_frame)

```

Run *t*-tests among levels and prepare for the Model 1.3 table later.

```{r clean-up-model-1.3e-output}

# convert Model 1.3e output to dataframe
coefficients_and_se = data.frame(
  summary(creators_v_commenters_gratitude_by_project)$coefficients)

# get comparison names as rownames
row_names = gsub(
  "project", "", gsub(
    "author_group", "", gsub(
      "type", "", row.names(coefficients_and_se))))

# replace hyphens in project names with periods
row_names = gsub(
  "scikit-", "scikit.", gsub(
    "sphinx-", "sphinx.", row_names))

# convert model estimates to a dataframe
means = coefficients_and_se$Estimate
names(means) = row_names

# convert standard error to dataframe
se = coefficients_and_se$Std..Error
names(se) = row_names

# compute t-statistics and p-values for desired contrasts
# (note: ordering of contrasts within each project is identical to Model 1.3c)
contrasts = c(
  
  # scikit-learn
  "scikit.learn:issue_post:member-scikit.learn:issue_post:nonmember",
  "scikit.learn:issue_reply:member-scikit.learn:issue_reply:nonmember",
  "scikit.learn:pr_post:member-scikit.learn:pr_post:nonmember",
  "scikit.learn:pr_reply:member-scikit.learn:pr_reply:nonmember",
  "scikit.learn:issue_post:member-scikit.learn:issue_reply:member",
  "scikit.learn:issue_post:nonmember-scikit.learn:issue_reply:nonmember",
  "scikit.learn:pr_post:member-scikit.learn:pr_reply:member",
  "scikit.learn:pr_post:nonmember-scikit.learn:pr_reply:nonmember",
  "scikit.learn:issue_post:member-scikit.learn:pr_post:member",
  "scikit.learn:issue_post:nonmember-scikit.learn:pr_post:nonmember",
  "scikit.learn:issue_reply:member-scikit.learn:pr_reply:member",
  "scikit.learn:issue_reply:nonmember-scikit.learn:pr_reply:nonmember",
  
  # scikit-image
  "scikit.image:issue_post:member-scikit.image:issue_post:nonmember",
  "scikit.image:issue_reply:member-scikit.image:issue_reply:nonmember",
  "scikit.image:pr_post:member-scikit.image:pr_post:nonmember",
  "scikit.image:pr_reply:member-scikit.image:pr_reply:nonmember",
  "scikit.image:issue_post:member-scikit.image:issue_reply:member",
  "scikit.image:issue_post:nonmember-scikit.image:issue_reply:nonmember",
  "scikit.image:pr_post:member-scikit.image:pr_reply:member",
  "scikit.image:pr_post:nonmember-scikit.image:pr_reply:nonmember",
  "scikit.image:issue_post:member-scikit.image:pr_post:member",
  "scikit.image:issue_post:nonmember-scikit.image:pr_post:nonmember",
  "scikit.image:issue_reply:member-scikit.image:pr_reply:member",
  "scikit.image:issue_reply:nonmember-scikit.image:pr_reply:nonmember",
  
  # matplotlib
  "matplotlib:issue_post:member-matplotlib:issue_post:nonmember",
  "matplotlib:issue_reply:member-matplotlib:issue_reply:nonmember",
  "matplotlib:pr_post:member-matplotlib:pr_post:nonmember",
  "matplotlib:pr_reply:member-matplotlib:pr_reply:nonmember",
  "matplotlib:issue_post:member-matplotlib:issue_reply:member",
  "matplotlib:issue_post:nonmember-matplotlib:issue_reply:nonmember",
  "matplotlib:pr_post:member-matplotlib:pr_reply:member",
  "matplotlib:pr_post:nonmember-matplotlib:pr_reply:nonmember",
  "matplotlib:issue_post:member-matplotlib:pr_post:member",
  "matplotlib:issue_post:nonmember-matplotlib:pr_post:nonmember",
  "matplotlib:issue_reply:member-matplotlib:pr_reply:member",
  "matplotlib:issue_reply:nonmember-matplotlib:pr_reply:nonmember",
  
  # mayavi
  "mayavi:issue_post:member-mayavi:issue_post:nonmember",
  "mayavi:issue_reply:member-mayavi:issue_reply:nonmember",
  "mayavi:pr_post:member-mayavi:pr_post:nonmember",
  "mayavi:pr_reply:member-mayavi:pr_reply:nonmember",
  "mayavi:issue_post:member-mayavi:issue_reply:member",
  "mayavi:issue_post:nonmember-mayavi:issue_reply:nonmember",
  "mayavi:pr_post:member-mayavi:pr_reply:member",
  "mayavi:pr_post:nonmember-mayavi:pr_reply:nonmember",
  "mayavi:issue_post:member-mayavi:pr_post:member",
  "mayavi:issue_post:nonmember-mayavi:pr_post:nonmember",
  "mayavi:issue_reply:member-mayavi:pr_reply:member",
  "mayavi:issue_reply:nonmember-mayavi:pr_reply:nonmember",
  
  # pandas
  "pandas:issue_post:member-pandas:issue_post:nonmember",
  "pandas:issue_reply:member-pandas:issue_reply:nonmember",
  "pandas:pr_post:member-pandas:pr_post:nonmember",
  "pandas:pr_reply:member-pandas:pr_reply:nonmember",
  "pandas:issue_post:member-pandas:issue_reply:member",
  "pandas:issue_post:nonmember-pandas:issue_reply:nonmember",
  "pandas:pr_post:member-pandas:pr_reply:member",
  "pandas:pr_post:nonmember-pandas:pr_reply:nonmember",
  "pandas:issue_post:member-pandas:pr_post:member",
  "pandas:issue_post:nonmember-pandas:pr_post:nonmember",
  "pandas:issue_reply:member-pandas:pr_reply:member",
  "pandas:issue_reply:nonmember-pandas:pr_reply:nonmember",
  
  # scipy
  "scipy:issue_post:member-scipy:issue_post:nonmember",
  "scipy:issue_reply:member-scipy:issue_reply:nonmember",
  "scipy:pr_post:member-scipy:pr_post:nonmember",
  "scipy:pr_reply:member-scipy:pr_reply:nonmember",
  "scipy:issue_post:member-scipy:issue_reply:member",
  "scipy:issue_post:nonmember-scipy:issue_reply:nonmember",
  "scipy:pr_post:member-scipy:pr_reply:member",
  "scipy:pr_post:nonmember-scipy:pr_reply:nonmember",
  "scipy:issue_post:member-scipy:pr_post:member",
  "scipy:issue_post:nonmember-scipy:pr_post:nonmember",
  "scipy:issue_reply:member-scipy:pr_reply:member",
  "scipy:issue_reply:nonmember-scipy:pr_reply:nonmember",
  
  # numpy
  "numpy:issue_post:member-numpy:issue_post:nonmember",
  "numpy:issue_reply:member-numpy:issue_reply:nonmember",
  "numpy:pr_post:member-numpy:pr_post:nonmember",
  "numpy:pr_reply:member-numpy:pr_reply:nonmember",
  "numpy:issue_post:member-numpy:issue_reply:member",
  "numpy:issue_post:nonmember-numpy:issue_reply:nonmember",
  "numpy:pr_post:member-numpy:pr_reply:member",
  "numpy:pr_post:nonmember-numpy:pr_reply:nonmember",
  "numpy:issue_post:member-numpy:pr_post:member",
  "numpy:issue_post:nonmember-numpy:pr_post:nonmember",
  "numpy:issue_reply:member-numpy:pr_reply:member",
  "numpy:issue_reply:nonmember-numpy:pr_reply:nonmember",
  
  # sphinx-gallery
  "sphinx.gallery:issue_post:member-sphinx.gallery:issue_post:nonmember",
  "sphinx.gallery:issue_reply:member-sphinx.gallery:issue_reply:nonmember",
  "sphinx.gallery:pr_post:member-sphinx.gallery:pr_post:nonmember",
  "sphinx.gallery:pr_reply:member-sphinx.gallery:pr_reply:nonmember",
  "sphinx.gallery:issue_post:member-sphinx.gallery:issue_reply:member",
  "sphinx.gallery:issue_post:nonmember-sphinx.gallery:issue_reply:nonmember",
  "sphinx.gallery:pr_post:member-sphinx.gallery:pr_reply:member",
  "sphinx.gallery:pr_post:nonmember-sphinx.gallery:pr_reply:nonmember",
  "sphinx.gallery:issue_post:member-sphinx.gallery:pr_post:member",
  "sphinx.gallery:issue_post:nonmember-sphinx.gallery:pr_post:nonmember",
  "sphinx.gallery:issue_reply:member-sphinx.gallery:pr_reply:member",
  "sphinx.gallery:issue_reply:nonmember-sphinx.gallery:pr_reply:nonmember"
)
project_types_author_group_tests = compute_t_statistics(
  means, se,
  contrasts)
project_types_author_group_tests[, "p_value"] = compute_p_value_from_t_stats(
  project_types_author_group_tests$t_stats)

```

```{r saving_results-model-1.3e}
write.table(coefficients_and_se,
            file="results/models/model-1.3e.tsv",
            sep="\t")
```

#### Overall results

Now we bring together all analyses from Model 1.3.

```{r output-model1.3-results-table}

# specify main terms
author_groups_tests["contrast"] = row.names(author_groups_tests)
types_tests["contrast"] = row.names(types_tests)
all_tests = merge(author_groups_tests, types_tests, all=TRUE, sort=FALSE)
all_tests["model"] = "Main Terms"

# specify 2-way interactions
types_author_groups_tests["contrast"] = row.names(types_author_groups_tests)
types_author_groups_tests["model"] = "2W: Types x Author Groups"
all_tests = merge(all_tests, types_author_groups_tests, all=TRUE, sort=FALSE)

# specify 3-way interactions
project_types_author_group_tests["contrast"] = row.names(project_types_author_group_tests)
project_types_author_group_tests["model"] = "3W: Types x Author Groups x Project"
all_tests = merge(all_tests, project_types_author_group_tests, all=TRUE,
                  sort=FALSE)

```

Let's correct all tests at once for multiple comparisons.

```{r corect-and-display-all-model-1.3-tests}

# specify all contrasts
row.names(all_tests) = all_tests$contrast
all_tests = subset(all_tests, select=-c(contrast))

# print the table (reordering columns for readibility)
all_tests = all_tests[c("model", "t_stats", "p_value")]
pander_clean_anova(all_tests, rename_columns=FALSE)

```

```{r gratitude_write_all_results}
all_tests$p_val_adjusted = p.adjust(all_tests$p_value, method="BH")
write.table(all_tests, file="results/models/model-1.3b_final_pvalues.tsv")
```

***

### Model 1.4: Time-course analysis for gratitude

The time-course analysis has been moved in a separate file.

***

## Model Series 2: Retention

Our second set of models investigates what aspects of the response to a 
newcomer's first activity (including aspects of the community's response
to their contribution) might predict their likelihood to come back to 
contribute a second time.

***

### Data preparation

Because each ticket has multiple comments, we cannot use the standard long-form
format for the dataset, or we would lead to (uneven) duplication of posts
based on the varying numbers of comments. As a result, we pull metrics of the
whole comment chain and use them as our measures of the community's response
to the newcomer's contribution.

```{r aggregate-comments-frame}

# aggregate ticket-level metrics for comments
aggregated_comments = comments_frame %>% ungroup() %>%
  
  # convert author group to numeric
  mutate(author_group_numeric = dplyr::if_else(author_group=='member',
                                               1,
                                               0)) %>%
  
  # create metrics for each unique ticket in each project
  dplyr::group_by(project, ticket_id) %>%
  dplyr::summarise(number_of_comments = n(),
                   comment_sentiment_mean = mean(compound_emotion, na.rm=TRUE),
                   comment_sentiment_variance = var(compound_emotion),
                   comment_sentiment_max_negative = max(negative_emotion),
                   comment_sentiment_max_positive = max(positive_emotion),
                   comment_grateful_cumulative = sum(grateful_count),
                   comment_first_response = min(date),
                   comment_member_ratio = sum(author_group_numeric)/n())

```

After we've summarized the comment threads, we next join those metrics with the
posts dataframe in preparation for our models.

```{r prep-for-retention-analysis}

# create joint dataframe
retention_frame = tickets_frame %>%
  dplyr::left_join(., aggregated_comments,
                   by=c('project', 'ticket_id')) %>%
  
  # keep only newcomers
  dplyr::filter(first_ticket == TRUE) %>%
  
  # keep only select variables
  dplyr::select(project,
                date,
                contains('author'),
                first_ticket,
                contains('num_'),
                contains('ticket'),
                contains('type'),
                contains('grateful_count'),
                contains('emotion'),
                open_time,
                contains('comment_'),
                number_of_comments,
                -contains('stamp'),
                -contains('last_comment')) %>%
  
  # read appropriate variables as logical
  mutate_at(vars(first_ticket,
                 ticket_author_last_ticket),
            as.logical) %>%
  
  # recode and rename retention variable so that it reflects continued engagement
  dplyr::rename(retained_newcomer = ticket_author_last_ticket) %>%
  mutate(retained_newcomer = dplyr::if_else(retained_newcomer==TRUE,
                                            FALSE,
                                            TRUE)) %>%
  
  # recode ticket group as two-level numeric factor
  mutate(ticket_family_numeric = dplyr::if_else(ticket_family=='issue',
                                                -.5,
                                                .5)) %>%
  
  #convert to factors (as needed) for proper modeling
  mutate_at(vars(project,
                 author_name,
                 author_group,
                 author_association,
                 type,
                 type_family,
                 ticket_family,
                 ticket_family_numeric,
                 retained_newcomer),
            as.factor)
```

```{r write_data_newcomer_retention}
write.table(retention_frame, "results/data/newcomer_retention.tsv", sep="\t")
```

***

### Summary statistics

What do these newcomers look like?

```{r newcomer-proportion-stats, include=FALSE, eval=TRUE}

# how many newcomers return?
proportion_of_newcomer = (
  sum(as.integer(retention_frame$retained_newcomer) - 1) / dim(retention_frame)[1] * 100)

# what proportion of newcomers post issues (vs. pull requests)?
newcomer_issue_post = retention_frame %>%
  dplyr::filter(ticket_family == "issue")
newcomer_proportion_issues = (dim(newcomer_issue_post)[1] / dim(retention_frame)[1]) * 100

```

`r proportion_of_newcomer`% of first-time contributors come back for a second
contribution.

`r newcomer_proportion_issues`% of first-time contributors post issues (compared
with pull requests).

***

### Model 2.1: How does a community's response to newcomers predict the newcomer's decision to return?

```{r plot-predicting-retention-aggregated, include=FALSE, eval=TRUE}

# create the plot of newcomer retention across all projects
retention_plot_aggregated = ggplot(data=retention_frame,
                                   aes(x=open_time/(60*60*24),
                                       color=comment_member_ratio,
                                       y=comment_sentiment_mean)) +
  geom_jitter(alpha=0.3, size=.1) +
  facet_grid(cols = c(vars(ticket_family),
                      vars(retained_newcomer)),
             labeller = labeller(
               ticket_family = c(issue = "Issue", 
                                 pr = "PR"),
               retained_newcomer = c('TRUE'="Retained",
                                     'FALSE'="Lost"))) +
  ggtitle("Newcomer retention by community response\nand community attentiveness") +
  xlab('Time open (in days)') +
  ylab('Mean sentiment of comments') +
  scale_color_viridis() + 
  labs(color='Ratio of comments\nmade by members') +
  theme(legend.position = "bottom")

# save full version
ggsave(plot = retention_plot_aggregated,
       height = 5,
       width = 6,
       filename = '../../figures/sentiment_analysis/ossc-retention_emotion-aggregated.jpg')

# save smaller version for knitr
ggsave(plot = retention_plot_aggregated,
       height = 5,
       width = 6,
       dpi = 150,
       filename = '../../figures/sentiment_analysis/ossc-retention_emotion-aggregated-knitr.jpg')

```

```{r plot-predicting-retention-by-project, echo=FALSE, include=FALSE, eval=TRUE}

# create the plot of newcomer retention by each project
retention_plot_by_project = ggplot(data=retention_frame,
                                   aes(x=open_time/(60*60*24),
                                       color=comment_member_ratio,
                                       y=comment_sentiment_mean)) +
  geom_jitter(alpha=0.3, size=.1) +
  facet_grid(rows = vars(project),
             cols = c(vars(ticket_family),
                      vars(retained_newcomer)
             ),
             labeller = labeller(
               ticket_family = c(issue = "Issue", 
                                 pr = "PR"),
               retained_newcomer = c('TRUE'="Retained",
                                     'FALSE'="Lost"))) +
  ggtitle("Newcomer retention by community response\nand community attentiveness (by project)") +
  xlab('Time open (in days)') +
  ylab('Mean sentiment of comments') +
  scale_color_viridis() + 
  labs(color='Ratio of comments\nmade by members') +
  theme(legend.position = "bottom")

# save full version
ggsave(plot = retention_plot_by_project,
       height = 10,
       width = 6,
       filename = '../../figures/sentiment_analysis/ossc-retention_emotion-by_project.jpg')

# save smaller version for knitr
ggsave(plot = retention_plot_by_project,
       height = 10,
       width = 6,
       dpi = 150,
       filename = '../../figures/sentiment_analysis/ossc-retention_emotion-by_project-knitr.jpg')

```

![**Figure**. Whether a first-time ticket creator will open a second ticket by commenters' expressions of gratitude and responsiveness.](../../figures/sentiment_analysis/ossc-retention_emotion-by_project-knitr.jpg)

```{r retention_contribution_type}
retention_predictors = glmer(retained_newcomer ~ 0 + ticket_family + (1 | project),
                             data=retention_frame, family=binomial)
coefficients_and_se = data.frame(
  summary(retention_predictors)$coefficients)

# get comparison names as rownames
row_names = gsub("ticket_family", "", row.names(coefficients_and_se))
# convert model estimates to a dataframe
means = coefficients_and_se$Estimate
names(means) = row_names

# convert standard error to dataframe
se = coefficients_and_se$Std..Error
names(se) = row_names

# compute t-statistics and p-values for desired contrasts
contrasts = c("pr-issue")
retention_tests = compute_t_statistics(
  means, se,
  contrasts)
retention_tests[, "p_value"] = compute_p_value_from_t_stats(
  retention_tests$t_stats)


# Keep coefficient + sde for plotting purposes
all_coefs_and_se = coefficients_and_se[, c("Estimate", "Std..Error")]
```

```{r retention_open_time}
retention_predictor = glmer(retained_newcomer ~ open_time + (1 | project),
                            data=retention_frame, family=binomial, nAGQ=0)
retention_tests_continuous = as.data.frame(summary(
  retention_predictor)$coefficients)
new_coefs = retention_tests_continuous[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
  all_coefs_and_se, new_coefs)
retention_tests_continuous[, "row_names"] = row.names(
  retention_tests_continuous)

retention_predictor = glmer(retained_newcomer ~ comment_grateful_cumulative + (1 | project),
                            data=retention_frame, family=binomial, nAGQ=0)
retention_grateful =  as.data.frame(summary(retention_predictor)$coefficients)
new_coefs = retention_grateful[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
  all_coefs_and_se, new_coefs)
retention_grateful[, "row_names"] = row.names(
  retention_grateful)
retention_tests_continuous = merge(
  retention_tests_continuous,
  retention_grateful, all=TRUE, sort=FALSE)

retention_predictor = glmer(retained_newcomer ~ comment_sentiment_max_negative + (1 | project),
                            data=retention_frame, family=binomial, nAGQ=0)
retention_comment_sentiment_max_negative = as.data.frame(
  summary(retention_predictor)$coefficients)
new_coefs = retention_comment_sentiment_max_negative[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
  all_coefs_and_se, new_coefs)
retention_comment_sentiment_max_negative[, "row_names"] = row.names(
  retention_comment_sentiment_max_negative)
retention_tests_continuous = merge(
  retention_tests_continuous,
  retention_comment_sentiment_max_negative,
  all=TRUE, sort=FALSE)


retention_predictor = glmer(retained_newcomer ~ comment_sentiment_max_positive + (1 | project),
                            data=retention_frame, family=binomial, nAGQ=0)
retention_comment_sentiment_max_positive = as.data.frame(
  summary(retention_predictor)$coefficients)
new_coefs = retention_comment_sentiment_max_positive[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
  all_coefs_and_se, new_coefs)
retention_comment_sentiment_max_positive[, "row_names"] = row.names(
  retention_comment_sentiment_max_positive)
retention_tests_continuous = merge(
  retention_tests_continuous,
  retention_comment_sentiment_max_positive,
  all=TRUE, sort=FALSE)


retention_predictor = glmer(retained_newcomer ~ number_of_comments + (1 | project),
                            data=retention_frame, family=binomial, nAGQ=0)
retention_number_of_comment = as.data.frame(
  summary(retention_predictor)$coefficients)
new_coefs = retention_number_of_comment[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
  all_coefs_and_se,
  new_coefs)
retention_number_of_comment[, "row_names"] = row.names(
  retention_number_of_comment)
retention_tests_continuous = merge(
  retention_tests_continuous,
  retention_number_of_comment,
  all=TRUE, sort=FALSE)


retention_predictor = glmer(retained_newcomer ~ comment_member_ratio + (1 | project),
                            data=retention_frame, family=binomial, nAGQ=0)

retention_comment_member_ratio = as.data.frame(
  summary(retention_predictor)$coefficients)
new_coefs = retention_comment_member_ratio[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
  all_coefs_and_se,
  new_coefs)

retention_comment_member_ratio[, "row_names"] = row.names(
  retention_comment_member_ratio)
retention_tests_continuous = merge(
  retention_tests_continuous,
  retention_comment_member_ratio,
  all=TRUE, sort=FALSE)


retention_predictor = glmer(retained_newcomer ~ comment_sentiment_mean + (1 | project),
                            data=retention_frame, family=binomial, nAGQ=0)
retention_comment_sentiment_mean = as.data.frame(
  summary(retention_predictor)$coefficients)
new_coefs = retention_comment_sentiment_mean[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
  all_coefs_and_se,
  new_coefs)
retention_comment_sentiment_mean[, "row_names"] = row.names(
  retention_comment_sentiment_mean)
retention_tests_continuous = rbind(
  retention_tests_continuous,
  retention_comment_sentiment_mean)
```

Now let's do interaction terms between contribution types and everything else.

```{r interaction_terms}
retention_predictor = glmer(
  retained_newcomer ~ 0 + ticket_family + ticket_family:open_time + (1 | project),
  data=retention_frame, family=binomial, nAGQ=0)
retention_open_time = as.data.frame(
  summary(retention_predictor)$coefficients)
new_coefs = retention_open_time[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
  all_coefs_and_se,
  new_coefs)
retention_open_time[, "row_names"] = row.names(
  retention_open_time)
retention_tests_continuous = rbind(
  retention_tests_continuous,
  retention_open_time)

retention_predictor = glmer(
  retained_newcomer ~ 0 + ticket_family + ticket_family:comment_sentiment_max_negative + (1 | project),
  data=retention_frame, family=binomial, nAGQ=0)
retention_comment_sentiment_max_negative = as.data.frame(
  summary(retention_predictor)$coefficients)
new_coefs = retention_comment_sentiment_max_negative[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
  all_coefs_and_se,
  new_coefs)
retention_comment_sentiment_max_negative[, "row_names"] = row.names(
  retention_comment_sentiment_max_negative)
retention_tests_continuous = merge(
  retention_tests_continuous,
  retention_comment_sentiment_max_negative,
  all=TRUE, sort=FALSE)

retention_predictor = glmer(
  retained_newcomer ~ 0 + ticket_family + ticket_family:comment_sentiment_max_positive + (1 | project),
  data=retention_frame, family=binomial, nAGQ=0)
retention_comment_sentiment_max_positive = as.data.frame(
  summary(retention_predictor)$coefficients)
new_coefs = retention_comment_sentiment_max_positive[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
  all_coefs_and_se,
  new_coefs)
retention_comment_sentiment_max_positive[, "row_names"] = row.names(
  retention_comment_sentiment_max_positive)
retention_tests_continuous = merge(
  retention_tests_continuous,
  retention_comment_sentiment_max_positive,
  all=TRUE, sort=FALSE)


retention_predictor = glmer(
  retained_newcomer ~ 0 + ticket_family + ticket_family:number_of_comments + (1 | project),
  data=retention_frame, family=binomial, nAGQ=0)
retention_number_of_comments = as.data.frame(
  summary(retention_predictor)$coefficients)
new_coefs = retention_number_of_comments[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
  all_coefs_and_se,
  new_coefs)
retention_number_of_comments[, "row_names"] = row.names(
  retention_number_of_comments)
retention_tests_continuous = merge(
  retention_tests_continuous,
  retention_number_of_comments,
  all=TRUE, sort=FALSE)

retention_predictor = glmer(
  retained_newcomer ~ 0 + ticket_family + ticket_family:comment_member_ratio + (1 | project),
  data=retention_frame, family=binomial, nAGQ=0)
retention_comment_member_ratio = as.data.frame(
  summary(retention_predictor)$coefficients)
new_coefs = retention_comment_member_ratio[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
  all_coefs_and_se,
  new_coefs)
retention_comment_member_ratio[, "row_names"] = row.names(
  retention_comment_member_ratio)
retention_tests_continuous = rbind(
  retention_tests_continuous,
  retention_comment_member_ratio)

retention_predictor = glmer(
  retained_newcomer ~ 0 + ticket_family + ticket_family:comment_sentiment_mean + (1 | project),
  data=retention_frame, family=binomial, nAGQ=0)
retention_comment_sentiment_mean = as.data.frame(
  summary(retention_predictor)$coefficients)
new_coefs = retention_comment_sentiment_mean[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
  all_coefs_and_se,
  new_coefs)
retention_comment_sentiment_mean[, "row_names"] = row.names(
  retention_comment_sentiment_mean)
retention_tests_continuous = rbind(
  retention_tests_continuous,
  retention_comment_sentiment_mean)

retention_predictor = glmer(
  retained_newcomer ~ 0 + ticket_family + ticket_family:comment_grateful_cumulative + (1 | project),
  data=retention_frame, family=binomial, nAGQ=0)
retention_comment_grateful_cumulative = as.data.frame(
  summary(retention_predictor)$coefficients)
new_coefs = retention_comment_grateful_cumulative[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
  all_coefs_and_se,
  new_coefs)
retention_comment_grateful_cumulative[, "row_names"] = row.names(
  retention_comment_grateful_cumulative)
retention_tests_continuous = rbind(
  retention_tests_continuous,
  retention_comment_grateful_cumulative)


```

```{r cleaning_up_table}
mask = (
  retention_tests_continuous$row_names != "(Intercept)" &
    retention_tests_continuous$row_names != "ticket_familyissue" &
    retention_tests_continuous$row_names != "ticket_familypr")
retention_tests_continuous = retention_tests_continuous[mask, ]
row.names(retention_tests_continuous) = retention_tests_continuous[,
                                                                   "row_names"] 

columns_of_interest = c("z value", "Pr(>|z|)")
retention_tests_continuous = retention_tests_continuous[, columns_of_interest]
retention_tests_continuous["model"] = row.names(retention_tests_continuous)
colnames(retention_tests_continuous) = c("stat", "p_value", "model")
retention_tests["model"] = row.names(retention_tests)
colnames(retention_tests) = c("stat", "p_value", "model")

retention_tests = rbind(retention_tests, retention_tests_continuous)
```

```{r display_model2_results}
pander_clean_anova(retention_tests[c("model", "stat", "p_value")],
                   rename_columns=FALSE)
```

```{r write_results-2.1}
write.table(all_coefs_and_se,
            file="results/models/model-2.1.tsv", sep="\t")
```

```{r write_all_results-2.1}
retention_tests$p_val_adjusted = p.adjust(retention_tests$p_value, method="BH")
write.table(retention_tests, file="results/models/model-2.1.tsv")
```

***

### Model 2.2: Hints of different newcomer goals

Both mean sentiment and max negative sentiment are predictive of newcomer
retention. We hypothesize that this might be driven by feedback from the
community, consistent with previous findings that volunteers in software
developer communities are often looking for learning experiences.

We thus now look at whether comment sentiment variance is predictive of
newcomer retention.

```{r sentiment_variance}

retention_predictor = glmer(
  retained_newcomer ~ 0 + ticket_family + ticket_family:comment_sentiment_variance + (1 | project),
  data=retention_frame, family=binomial, nAGQ=0)
retention_comment_sentiment_variance = as.data.frame(
  summary(retention_predictor)$coefficients)

new_coefs = retention_comment_sentiment_variance[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se_2.1 = rbind(
  all_coefs_and_se,
  new_coefs)

colnames(retention_comment_sentiment_variance) = c("Estimate", "Std Error", "Z value", "p_value")
pander_clean_anova(retention_comment_sentiment_variance, rename_columns=FALSE)

```

```{r add-sentiment-variance-and-recalculate-ps}

retention_comment_sentiment_variance[, "row_names"] = row.names(
  retention_comment_sentiment_variance)

mask = (
  retention_comment_sentiment_variance$row_names != "(Intercept)" &
    retention_comment_sentiment_variance$row_names != "ticket_familyissue" &
    retention_comment_sentiment_variance$row_names != "ticket_familypr")
retention_comment_sentiment_variance = retention_comment_sentiment_variance[mask, ]
row.names(retention_comment_sentiment_variance) = retention_comment_sentiment_variance[,
                                                                                       "row_names"] 

columns_of_interest = c("Z value", "p_value")
retention_comment_sentiment_variance = select(retention_comment_sentiment_variance, 
                                              one_of(columns_of_interest))
retention_comment_sentiment_variance["model"] = row.names(retention_comment_sentiment_variance)
colnames(retention_comment_sentiment_variance) = c("stat", "p_value", "model")
retention_tests_2.1 = rbind(select(retention_tests, -p_val_adjusted), 
                            retention_comment_sentiment_variance)

```

```{r write_results-2.2}
write.table(all_coefs_and_se_2.1,
            file="results/models/model-2.2.tsv", sep="\t")
```

```{r write_all_results-2.2}
retention_tests_2.1$p_val_adjusted = p.adjust(retention_tests_2.1$p_value, method="BH")
write.table(retention_tests, file="results/models/model-2.2.tsv")
```

```{r}

pander_clean_anova(retention_tests_2.1[c("model", "stat", "p_value")],
                   rename_columns=FALSE)

```

***

# Future directions

Ideas:

* Do comments, generally, get more friendly or more hostile over time?
* Does the emotional valence of a contributor's first ticket predict whether
they'll come back to make a second one?
* Are requesters more or less polite?
* Does friendliness bring people back?
* Does the number and intensity of negative and positive comments on a
first-time contributor's ticket change whether they come back to make another
ticket?
