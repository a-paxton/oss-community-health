---
title: "Communication dynamics in OSS communities"
output:
  html_document:
    keep_md: yes
    number_sections: yes
    toc: true
---

This R markdown provides the data preparation for our forthcoming manuscript
(Paxton, Varoquaux, Geiger, & Holdgraf, *in preparation*).

To run this from scratch, you will need the following files:

* `../../data/analysis_data/sentiment_frame_tickets-for_r.csv`: Contains cleaned
**tickets**-related data and derived variables from scraped GitHub data.
* `../../data/analysis_data/sentiment_frame_comments-for_r.csv`: Contains
cleaned **comments**-related data and derived variables from scraped GitHub
data.
* `./utils/ossc-libraries_and_functions.r`: Loads in necessary libraries and
creates new functions for our analyses.
* `./utils/data-loading.R`: loads functions related to data loading and
  preprocessing.

**Code written by**: A. Paxton (University of Connecticut) & N. Varoquaux
(CNRS)

**Date last compiled**:  `r Sys.time()`

```{r silent-preparations, include=FALSE}
library(knitr)
knitr::opts_chunk$set(cache=TRUE, autodep=TRUE, cache.lazy=FALSE)
```

***

# Preliminaries

```{r prelim, warning = FALSE, error = FALSE, message = FALSE}

# clear everything
rm(list=ls())

# load libraries and add new functions
source('./utils/ossc-libraries_and_functions.r')
source("./utils/data-loading.R")
```

```{r choosing_dataset}

# We are now going to select the dataset we'll be working on.
library(dplyr)
tickets_frame = loading_tickets_data(dataset="original")
comments_frame = loading_comments_data(dataset="original")

```


## Basic summary stats

The data has been largely cleaned. Let's take a look at some basic
patterns.

```{r user-stats, include=FALSE, eval=TRUE}

# get unique values
unique_commenters = as.character(unique(comments_frame$author_name))
unique_ticketers = as.character(unique(tickets_frame$author_name))
unique_users = as.character(unique(append(unique_commenters, unique_ticketers)))

```

```{r activity-stats, echo=FALSE, eval=TRUE}

# get counts of ticket activity per project
ticket_counts = tickets_frame %>% ungroup() %>%
  dplyr::select(project, id) %>%
  distinct() %>%
  group_by(project) %>%
  summarize(unique_tickets = n())

# get counts of comment activity per project
comment_counts = comments_frame %>% ungroup() %>%
  dplyr::select(project, id, ticket_id) %>%
  distinct() %>%
  group_by(project) %>%
  summarize(unique_comments = n())

# bind the two
contribution_counts = dplyr::full_join(ticket_counts, comment_counts,
                                       by='project')

# print the table and then clean up a bit
pander(contribution_counts, style = 'rmarkdown')
rm(ticket_counts, comment_counts)

```

Our dataset includes `r dim(contribution_counts)[1]` unique projects with a
total of `r sum(contribution_counts$unique_tickets)` unique tickets, with a
mean of `r mean(contribution_counts$unique_tickets)` tickets per project.

On these tickets, the dataset includes
`r sum(contribution_counts$unique_comments)` unique comments, with
`r mean(contribution_counts$unique_comments)` average comments per project.

In total, we have `r length(unique_commenters)` unique commenters,
`r length(unique_ticketers)` unique ticket-creators, and
`r length(unique_users)` overall unique users.

***

# Data analysis

***

## Model Series 1: Sentiment analysis

### Data preparation

Before we can run Model Series 1, we need to combine `tickets_frame` and
`comments_frame` into a single dataframe. We do this using the
`combine_tickets_and_comments` function, `defined in utils/data-loading.R`

```{r prepare-data-for-sentiment-analysis}
sentiment_frame = combine_tickets_and_comments(tickets_frame, comments_frame)
```

```{r save-sentiment-frame, echo=FALSE}
# For plotting purposes

dir.create("results/data", showWarnings=FALSE, recursive=TRUE)
write.table(sentiment_frame,
	    file="results/data/sentiment_frame_original.tsv",
	    sep="\t")
```


### Model 1.1: Do different kinds of user contributions materially differ in emotion?

Now we begin the actual modeling. Our first general question is whether users'
patterns of sentiment differ materially by whether they are a member of the
community versus a nonmember of the community and by their different kinds of
possible contributions (i.e., a posted pull request, a reply to a pull request,
a posted issue, or a reply to an issue).

#### Model 1.1a: Overall effects with linear mixed-effects models

This model presents the analyses in a way that is typical of psychological
analyses. We predict the changes in emotion by community membership and 
contribution type, including random effects for project and for author. This
allows us to explore the general patterns of the main and interaction terms,
rather than focusing in on the project-specific variability.

```{r model-emotion-by-type-and-author}

# do tickets and comments materially differ in emotion?
creators_v_commenters_emotion_by_project = lmer(compound_emotion ~ type * author_group  +
                                                  (1 | project) + (1 | author_name),
                                                data = sentiment_frame,
                                                REML = FALSE)

```

```{r print-model-emotion-by-type-and-author, eval=TRUE, echo=FALSE}

# print results
pander_lme(creators_v_commenters_emotion_by_project)

```

While we see significant differences in the model, interpreting the results is
difficult because of the way that `lmer` handles factor comparisons. All 
factors are compared against a "reference level," the first level in the model.
This makes intepreting models with factors that include more than two levels
incredibly difficult, because the intercept is essentially an interaction term
among all reference levels of all factors.

As a result, we turn to the biostatistics approach of multiple *t*-tests 
(corrected for comparisons) of the model estimates to better understand the 
effects.

#### Model 1.1b: In-depth investigation through *t*-tests of model estimates

First, we build a series of linear mixed-effects models with one term included
in each model (either main term or interaction term). We then use the estimates
from those models to perform *t*-tests to investigate how different levels of
the effects differ from one another (and not just from the model-level 
intercept).

Projects here are random effects, but the rest of the model is the same as 
before. This allows us to do pairwise testing of main and interaction terms,
along with better exploring inter-project variability.

##### Model 1.1b.1: Does sentiment vary significantly by community membership?

First, look at whether there are differences in sentiment between author 
groups.

```{r model-emotion-by-author-group}

# do members and nonmembers materially differ in emotion?
fixed_creators_v_commenters_emotion = lmer(
  compound_emotion ~ 0 + author_group + (1 | author_name) + (1 | project),
  data=sentiment_frame,
  REML=FALSE)

```

Run *t*-tests among levels and prepare for the Model 1.1b table later.

```{r clean-up-model-1.1b1-output}

# convert Model 1.1b1 output to dataframe
coefficients_and_se = data.frame(
  summary(fixed_creators_v_commenters_emotion)$coefficients)

# get comparison names as rownames
row_names = gsub("author_group", "", 
                 gsub("type", "", row.names(coefficients_and_se)))

# convert model estimates to a dataframe
means = coefficients_and_se$Estimate
names(means) = row_names

# convert standard error to dataframe
se = coefficients_and_se$Std..Error
names(se) = row_names

# compute t-statistics and p-values for desired contrasts
contrasts = c("member-nonmember")
author_groups_tests = compute_t_statistics(
  means, se,
  contrasts)
author_groups_tests[, "p_value"] = compute_p_value_from_t_stats(
  author_groups_tests$t_stats)
```

```{r saving_results-model-1.1b1}
dir.create("results/models", showWarnings=FALSE)
write.table(coefficients_and_se,
	    file="results/models/model-1.1b1.tsv",
	    sep="\t")

```

##### Model 1.1b.2: Does sentiment vary significantly across contribution types?

Now, look at whether there are differences in sentiment between contribution
types.

```{r model-emotion-by-type}

# do tickets and comments materially differ in emotion?
fixed_types_emotion = lmer(
  compound_emotion ~ 0 + type + (1 | author_name) + (1 | project),
  data=sentiment_frame,
  REML=FALSE)

```

Run *t*-tests among levels and prepare for the Model 1.1b table later.

```{r clean-up-model-1.1b2-output}

# convert Model 1.1b2 output to dataframe
coefficients_and_se = data.frame(
  summary(fixed_types_emotion)$coefficients)

# get comparison names as rownames
row_names = gsub("author_group", "", 
                 gsub("type", "", row.names(coefficients_and_se)))

# convert model estimates to a dataframe
means = coefficients_and_se$Estimate
names(means) = row_names

# convert standard error to dataframe
se = coefficients_and_se$Std..Error
names(se) = row_names

# compute t-statistics and p-values for desired contrasts
contrasts = c("issue_post-issue_reply", # issues: posts vs. replies
              "pr_post-pr_reply",       # PRs: posts vs. replies
              "issue_post-pr_post",     # posts: issues vs. PRs
              "issue_reply-pr_reply")   # replies: issues vs. PRs
types_tests = compute_t_statistics(
  means, se,
  contrasts)
types_tests[, "p_value"] = compute_p_value_from_t_stats(types_tests$t_stats)

```

```{r saving_results-model-1.1b2}
write.table(coefficients_and_se,
	    file="results/models/model-1.1b2.tsv",
	    sep="\t")
```


##### Model 1.1b.3: Does sentiment vary significantly across community memberships and contribution types?

Finally, let's look at the interaction between membership and contribution.

```{r model-emotion-by-type-and-author-interaction-only}

# does emotion differ by the interaction between contribution and authorship group?
community_contribution_emotion = lmer(
  compound_emotion ~ 0 + type:author_group + (1 | author_name) + (1 | project),
  data=sentiment_frame,
  REML=FALSE)

```

Run *t*-tests among levels and prepare for the Model 1.1b table later.

```{r clean-up-model-1.1b3-output}

# convert Model 1.1b3 output to dataframe
coefficients_and_se = data.frame(
  summary(community_contribution_emotion)$coefficients)

# get comparison names as rownames
row_names = gsub("author_group", "", gsub("type", "", row.names(coefficients_and_se)))

# convert model estimates to a dataframe
means = coefficients_and_se$Estimate
names(means) = row_names

# convert standard error to dataframe
se = coefficients_and_se$Std..Error
names(se) = row_names

# compute t-statistics and p-values for desired contrasts
contrasts = c(
  "issue_post:member-issue_post:nonmember",     # contribution static (issue posts); membership varies (members v. nonmembers)
  "issue_reply:member-issue_reply:nonmember",   # contribution static (issue replies); membership varies (members v. nonmembers)
  "pr_post:member-pr_post:nonmember",           # contribution static (PR posts); membership varies (members v. nonmembers)
  "pr_reply:member-pr_reply:nonmember",         # contribution static (PR replies); membership varies (members v. nonmembers)
  "issue_post:member-issue_reply:member",       # contribution varies (issue posts vs. issue replies); membership static (members)
  "issue_post:nonmember-issue_reply:nonmember", # contribution varies (issue posts vs. issue replies); membership static (nonmembers)
  "pr_post:member-pr_reply:member",             # contribution varies (PR posts vs. PR replies); membership static (members)
  "pr_post:nonmember-pr_reply:nonmember",       # contribution varies (PR posts vs. PR replies); membership static (nonmembers)
  "issue_post:member-pr_post:member",           # contribution varies (issue posts vs. PR posts); membership static (members)
  "issue_post:nonmember-pr_post:nonmember",     # contribution varies (issue posts vs. PR posts); membership static (nonmembers)
  "issue_reply:member-pr_reply:member",         # contribution varies (issue replies vs. PR replies); membership static (members)
  "issue_reply:nonmember-pr_reply:nonmember")   # contribution varies (issue replies vs. PR replies); membership static (nonmembers)
types_author_groups_tests = compute_t_statistics(
  means, se,
  contrasts)
types_author_groups_tests[, "p_value"] = compute_p_value_from_t_stats(
  types_author_groups_tests$"t_stats")

```

```{r saving_results-model-1.1b3}
write.table(coefficients_and_se,
	    file="results/models/model-1.1b3.tsv",
	    sep="\t")
```


##### Model 1.1b.4 : Do different kinds of user contributions differ in emotion by projects?

Now adding projects into the mix to understand how the previous analysis
varies across projects.

```{r model-emotion-by-type-and-author-and-project}

# do tickets and comments materially differ in emotion by projects?
creators_v_commenters_emotion_by_project = lmer(
  compound_emotion ~ 0 + project:type:author_group + (1 | author_name),
  data = sentiment_frame,
  REML = FALSE)

```

Run *t*-tests among levels and prepare for the Model 1.1b table later.

```{r clean-up-model-1.1c-output}

# convert Model 1.1c output to dataframe
coefficients_and_se = data.frame(
  summary(creators_v_commenters_emotion_by_project)$coefficients)

# get comparison names as rownames
row_names = gsub(
  "project", "", gsub(
    "author_group", "", gsub(
      "type", "", row.names(coefficients_and_se))))

# replace hyphens in project names with periods
row_names = gsub(
  "scikit-", "scikit.", gsub(
    "sphinx-", "sphinx.", row_names))

# convert model estimates to a dataframe
means = coefficients_and_se$Estimate
names(means) = row_names

# convert standard error to dataframe
se = coefficients_and_se$Std..Error
names(se) = row_names

# compute t-statistics and p-values for desired contrasts
# (note: ordering of contrasts within each project is identical to Model 1.1b.3)
contrasts = c(
  
  # scikit-learn
  "scikit.learn:issue_post:member-scikit.learn:issue_post:nonmember",   
  "scikit.learn:issue_reply:member-scikit.learn:issue_reply:nonmember",
  "scikit.learn:pr_post:member-scikit.learn:pr_post:nonmember",
  "scikit.learn:pr_reply:member-scikit.learn:pr_reply:nonmember",
  "scikit.learn:issue_post:member-scikit.learn:issue_reply:member",
  "scikit.learn:issue_post:nonmember-scikit.learn:issue_reply:nonmember",
  "scikit.learn:pr_post:member-scikit.learn:pr_reply:member",
  "scikit.learn:pr_post:nonmember-scikit.learn:pr_reply:nonmember",
  "scikit.learn:issue_post:member-scikit.learn:pr_post:member",
  "scikit.learn:issue_post:nonmember-scikit.learn:pr_post:nonmember",    
  "scikit.learn:issue_reply:member-scikit.learn:pr_reply:member",  
  "scikit.learn:issue_reply:nonmember-scikit.learn:pr_reply:nonmember",
  
  # scikit-image
  "scikit.image:issue_post:member-scikit.image:issue_post:nonmember", 
  "scikit.image:issue_reply:member-scikit.image:issue_reply:nonmember",
  "scikit.image:pr_post:member-scikit.image:pr_post:nonmember",       
  "scikit.image:pr_reply:member-scikit.image:pr_reply:nonmember",     
  "scikit.image:issue_post:member-scikit.image:issue_reply:member",
  "scikit.image:issue_post:nonmember-scikit.image:issue_reply:nonmember",
  "scikit.image:pr_post:member-scikit.image:pr_reply:member",     
  "scikit.image:pr_post:nonmember-scikit.image:pr_reply:nonmember",    
  "scikit.image:issue_post:member-scikit.image:pr_post:member",   
  "scikit.image:issue_post:nonmember-scikit.image:pr_post:nonmember",    
  "scikit.image:issue_reply:member-scikit.image:pr_reply:member",  
  "scikit.image:issue_reply:nonmember-scikit.image:pr_reply:nonmember",
  
  # matplotlib
  "matplotlib:issue_post:member-matplotlib:issue_post:nonmember", 
  "matplotlib:issue_reply:member-matplotlib:issue_reply:nonmember",
  "matplotlib:pr_post:member-matplotlib:pr_post:nonmember",       
  "matplotlib:pr_reply:member-matplotlib:pr_reply:nonmember",     
  "matplotlib:issue_post:member-matplotlib:issue_reply:member",
  "matplotlib:issue_post:nonmember-matplotlib:issue_reply:nonmember",
  "matplotlib:pr_post:member-matplotlib:pr_reply:member",     
  "matplotlib:pr_post:nonmember-matplotlib:pr_reply:nonmember",    
  "matplotlib:issue_post:member-matplotlib:pr_post:member",   
  "matplotlib:issue_post:nonmember-matplotlib:pr_post:nonmember",    
  "matplotlib:issue_reply:member-matplotlib:pr_reply:member",  
  "matplotlib:issue_reply:nonmember-matplotlib:pr_reply:nonmember",
  
  # mayavi
  "mayavi:issue_post:member-mayavi:issue_post:nonmember", 
  "mayavi:issue_reply:member-mayavi:issue_reply:nonmember",
  "mayavi:pr_post:member-mayavi:pr_post:nonmember",       
  "mayavi:pr_reply:member-mayavi:pr_reply:nonmember",     
  "mayavi:issue_post:member-mayavi:issue_reply:member",
  "mayavi:issue_post:nonmember-mayavi:issue_reply:nonmember",
  "mayavi:pr_post:member-mayavi:pr_reply:member",     
  "mayavi:pr_post:nonmember-mayavi:pr_reply:nonmember",    
  "mayavi:issue_post:member-mayavi:pr_post:member",   
  "mayavi:issue_post:nonmember-mayavi:pr_post:nonmember",    
  "mayavi:issue_reply:member-mayavi:pr_reply:member",  
  "mayavi:issue_reply:nonmember-mayavi:pr_reply:nonmember",
  
  # pandas
  "pandas:issue_post:member-pandas:issue_post:nonmember", 
  "pandas:issue_reply:member-pandas:issue_reply:nonmember",
  "pandas:pr_post:member-pandas:pr_post:nonmember",       
  "pandas:pr_reply:member-pandas:pr_reply:nonmember",     
  "pandas:issue_post:member-pandas:issue_reply:member",
  "pandas:issue_post:nonmember-pandas:issue_reply:nonmember",
  "pandas:pr_post:member-pandas:pr_reply:member",     
  "pandas:pr_post:nonmember-pandas:pr_reply:nonmember",    
  "pandas:issue_post:member-pandas:pr_post:member",   
  "pandas:issue_post:nonmember-pandas:pr_post:nonmember",    
  "pandas:issue_reply:member-pandas:pr_reply:member",  
  "pandas:issue_reply:nonmember-pandas:pr_reply:nonmember",
  
  # scipy
  "scipy:issue_post:member-scipy:issue_post:nonmember", 
  "scipy:issue_reply:member-scipy:issue_reply:nonmember",
  "scipy:pr_post:member-scipy:pr_post:nonmember",       
  "scipy:pr_reply:member-scipy:pr_reply:nonmember",     
  "scipy:issue_post:member-scipy:issue_reply:member",
  "scipy:issue_post:nonmember-scipy:issue_reply:nonmember",
  "scipy:pr_post:member-scipy:pr_reply:member",     
  "scipy:pr_post:nonmember-scipy:pr_reply:nonmember",    
  "scipy:issue_post:member-scipy:pr_post:member",   
  "scipy:issue_post:nonmember-scipy:pr_post:nonmember",    
  "scipy:issue_reply:member-scipy:pr_reply:member",  
  "scipy:issue_reply:nonmember-scipy:pr_reply:nonmember",
  
  # numpy
  "numpy:issue_post:member-numpy:issue_post:nonmember", 
  "numpy:issue_reply:member-numpy:issue_reply:nonmember",
  "numpy:pr_post:member-numpy:pr_post:nonmember",       
  "numpy:pr_reply:member-numpy:pr_reply:nonmember",     
  "numpy:issue_post:member-numpy:issue_reply:member",
  "numpy:issue_post:nonmember-numpy:issue_reply:nonmember",
  "numpy:pr_post:member-numpy:pr_reply:member",     
  "numpy:pr_post:nonmember-numpy:pr_reply:nonmember",    
  "numpy:issue_post:member-numpy:pr_post:member",   
  "numpy:issue_post:nonmember-numpy:pr_post:nonmember",    
  "numpy:issue_reply:member-numpy:pr_reply:member",  
  "numpy:issue_reply:nonmember-numpy:pr_reply:nonmember",
  
  # sphinx-gallery
  "sphinx.gallery:issue_post:member-sphinx.gallery:issue_post:nonmember", 
  "sphinx.gallery:issue_reply:member-sphinx.gallery:issue_reply:nonmember",
  "sphinx.gallery:pr_post:member-sphinx.gallery:pr_post:nonmember",       
  "sphinx.gallery:pr_reply:member-sphinx.gallery:pr_reply:nonmember",     
  "sphinx.gallery:issue_post:member-sphinx.gallery:issue_reply:member",
  "sphinx.gallery:issue_post:nonmember-sphinx.gallery:issue_reply:nonmember",
  "sphinx.gallery:pr_post:member-sphinx.gallery:pr_reply:member",     
  "sphinx.gallery:pr_post:nonmember-sphinx.gallery:pr_reply:nonmember",    
  "sphinx.gallery:issue_post:member-sphinx.gallery:pr_post:member",   
  "sphinx.gallery:issue_post:nonmember-sphinx.gallery:pr_post:nonmember",    
  "sphinx.gallery:issue_reply:member-sphinx.gallery:pr_reply:member",  
  "sphinx.gallery:issue_reply:nonmember-sphinx.gallery:pr_reply:nonmember"
)
project_types_author_group_tests = compute_t_statistics(
  means, se,
  contrasts)
project_types_author_group_tests[, "p_value"] = compute_p_value_from_t_stats(
  project_types_author_group_tests$t_stats) 

```

```{r saving_results-model-1.1c}
write.table(coefficients_and_se,
	    file="results/models/model-1.1c.tsv",
	    sep="\t")
```


#### Model 1.1b: Overall results

Now we bring together all analyses from Model 1.1b.

```{r output-model1.1b-results-table}

# specify main terms
author_groups_tests["contrast"] = row.names(author_groups_tests)
types_tests["contrast"] = row.names(types_tests)
all_tests = merge(author_groups_tests, types_tests, all=TRUE, sort=FALSE)
all_tests["model"] = "Main Terms"

# specify 2-way interactions
types_author_groups_tests["contrast"] = row.names(types_author_groups_tests)
types_author_groups_tests["model"] = "2W: Types x Author Groups"
all_tests = merge(all_tests, types_author_groups_tests, all=TRUE, sort=FALSE)

# specify 3-way interactions
project_types_author_group_tests["contrast"] = row.names(project_types_author_group_tests)
project_types_author_group_tests["model"] = "3W: Types x Author Groups x Project"
all_tests = merge(all_tests, project_types_author_group_tests, all=TRUE,
                  sort=FALSE)

```

Let's correct all tests at once for multiple comparisons.

```{r correct-and-display-all-model-1.1b-tests}

# specify all contrasts
row.names(all_tests) = all_tests$contrast
all_tests = subset(all_tests, select=-c(contrast))

# print the table (reordering columns for readibility)
all_tests = all_tests[c("model", "t_stats", "p_value")]
pander_clean_anova(all_tests, rename_columns=FALSE)

```

```{r emotion_write_all_results}
all_tests$p_val_adjusted = p.adjust(all_tests$p_value, method="BH")
write.table(all_tests, file="results/models/model-1.1b_final_pvalues.tsv")
```

Finally, let's plot these effects.


```{r plot-model-emotion-by-type, echo=FALSE, eval=TRUE}
# aggregate sentiment over all projects
sentiment_plot_aggregated = ggplot(data=sentiment_frame,
                                   aes(x=type,
                                       y=compound_emotion,
                                       colour=type)) +
  stat_summary(fun.y=mean, geom="point", size=2) +
  stat_summary(fun.data = mean_se, geom = "errorbar") +
  #coord_cartesian(ylim=c(0,.5)) +
  facet_grid(cols=vars(ticket_family)) +
  ggtitle('Message sentiment by contribution\nand community membership') +
  ylab('Sentiment score') +
  xlab('Community membership') +
  labs(color='Contribution type') +
  scale_color_manual(labels = c("Issue: Post",
                                "Issue: Reply",
                                "PR: Post",
                                "PR: Reply"),
                     values = c("#e66101", # issue: post (darker)
                                "#fdb863", # issue: reply (lighter)
                                "#5e3c99", # PR: post (darker)
                                "#b2abd2")) # PR: reply (lighter)

```

```{r plot-model-emotion-by-type-and-membership, echo=FALSE, eval=TRUE}

# aggregate sentiment over all projects
sentiment_plot_aggregated = ggplot(data=sentiment_frame,
                                   aes(x=author_group,
                                       y=compound_emotion,
                                       colour=type)) +
  stat_summary(fun.y=mean, geom="point", size=2) +
  stat_summary(fun.data = mean_se, geom = "errorbar") +
  #coord_cartesian(ylim=c(0,.5)) +
  facet_grid(cols=vars(ticket_family)) +
  ggtitle('Message sentiment by contribution\nand community membership') +
  ylab('Sentiment score') +
  xlab('Community membership') +
  labs(color='Contribution type') +
  scale_color_manual(labels = c("Issue: Post",
                                "Issue: Reply",
                                "PR: Post",
                                "PR: Reply"),
                     values = c("#e66101", # issue: post (darker)
                                "#fdb863", # issue: reply (lighter)
                                "#5e3c99", # PR: post (darker)
                                "#b2abd2")) # PR: reply (lighter)

# plot a full-size version
ggsave(plot = sentiment_plot_aggregated,
       height = 4,
       width = 5,
       filename = '../../figures/sentiment_analysis/ossc-sentiment_membership_contribution-aggregated.jpg')

# plot a smaller one for knitr
ggsave(plot = sentiment_plot_aggregated,
       height = 4,
       width = 5,
       dpi = 150,
       filename = '../../figures/sentiment_analysis/ossc-sentiment_membership_contribution-aggregated-knitr.jpg')

```

![**Figure**. Sentiment by contribution type (ticket vs. comment) and community membership at the time of posting (member vs. nonmember).](../../figures/sentiment_analysis/ossc-sentiment_membership_contribution-aggregated-knitr.jpg)

```{r plot-model-emotion-by-type-and-membership-and-project, echo=FALSE, eval=TRUE}

# separate across each project
sentiment_plot_by_project = ggplot(data=sentiment_frame,
                                   aes(x=author_group,
                                       y=compound_emotion,
                                       colour=type)) +
  stat_summary(fun.y=mean, geom="point", size=2) +
  stat_summary(fun.data = mean_se, geom = "errorbar") +
  #coord_cartesian(ylim=c(0,.5)) +
  facet_grid(cols=vars(ticket_family),
             rows=vars(project)) +
  ggtitle('Message sentiment by contribution\nand community membership') +
  ylab('Sentiment score') +
  xlab('Community membership') +
  labs(color='Contribution type') +
  scale_color_manual(labels = c("Issue: Post",
                                "Issue: Reply",
                                "PR: Post",
                                "PR: Reply"),
                     values = c("#e66101", # issue: post (darker)
                                "#fdb863", # issue: reply (lighter)
                                "#5e3c99", # PR: post (darker)
                                "#b2abd2")) # PR: reply (lighter)

# another possible color scheme: #ca0020, #f4a582, #92c5de, #0571b0 (red to blue)

# plot a full-size version
ggsave(plot = sentiment_plot_by_project,
       height = 10,
       width = 4,
       filename = '../../figures/sentiment_analysis/ossc-sentiment_membership_contribution-by_project.jpg')

# plot a smaller one for knitr
ggsave(plot = sentiment_plot_by_project,
       height = 10,
       width = 4,
       dpi = 150,
       filename = '../../figures/sentiment_analysis/ossc-sentiment_membership_contribution-by_project-knitr.jpg')

```

![**Figure**. Sentiment by contribution type (ticket vs. comment) and community membership at the time of posting (member vs. nonmember) for each project.](../../figures/sentiment_analysis/ossc-sentiment_membership_contribution-by_project-knitr.jpg)

#### Model 1.2b: More plots, this time using means and std estimated from model-fit

Here, we are going to test whether projects differ from the mean.

```{r eval=TRUE, echo=TRUE}
coefficients_and_se = data.frame(
  summary(creators_v_commenters_emotion_by_project)$coefficients)

# get comparison names as rownames
row_names = gsub(
  "project", "", gsub(
    "author_group", "", gsub(
      "type", "", row.names(coefficients_and_se))))

# replace hyphens in project names with periods
row_names = gsub(
  "scikit-", "scikit.", gsub(
    "sphinx-", "sphinx.", row_names))

# convert model estimates to a dataframe
means = coefficients_and_se$Estimate
names(means) = row_names

# convert standard error to dataframe
se = coefficients_and_se$Std..Error
names(se) = row_names
```

```{r}
projects = c("Matplotlib", "Mayavi", "numpy", "pandas",
	     "scikit-image", "scikit-learn", "scipy", "sphinx-gallery")
```

```{r plot_pr_post_members, fig.width=8}
group_of_interest = "pr_post:member"
rows_to_plot = grep(group_of_interest, names(means))

bar_centers = barplot(means[rows_to_plot], names.arg=projects,
		      main=group_of_interest,    
		      cex.names=0.8)
arrows(bar_centers,
       means[rows_to_plot] - se[rows_to_plot] ** 2, 
       bar_centers,
       means[rows_to_plot] + se[rows_to_plot] ** 2,
       angle=90,
       code=3)
```

```{r plot_pr_post_nonmembers, fig.width=8}
group_of_interest = "pr_post:nonmember"
rows_to_plot = grep(group_of_interest, names(means))

bar_centers = barplot(means[rows_to_plot], names.arg=projects,
		      main=group_of_interest,
		      cex.names=0.8)

arrows(bar_centers,
       means[rows_to_plot] - se[rows_to_plot] ** 2, 
       bar_centers,
       means[rows_to_plot] + se[rows_to_plot] ** 2,
       angle=90,
       code=3)
```


```{r plot_issue_post_members, fig.width=8}
group_of_interest = "issue_post:member"
rows_to_plot = grep(group_of_interest, names(means))

bar_centers = barplot(means[rows_to_plot], names.arg=projects,
		      main=group_of_interest,
		      cex.names=0.8
		      )
arrows(bar_centers,
       means[rows_to_plot] - se[rows_to_plot] ** 2, 
       bar_centers,
       means[rows_to_plot] + se[rows_to_plot] ** 2,
       angle=90,
       code=3)
```

```{r plot_issue_post_nonmembers, fig.width=8}
group_of_interest = "issue_post:nonmember"
rows_to_plot = grep(group_of_interest, names(means))

bar_centers = barplot(means[rows_to_plot], names.arg=projects,
		      main=group_of_interest,
		      cex.names=0.8
		      )
arrows(bar_centers,
       means[rows_to_plot] - se[rows_to_plot] ** 2, 
       bar_centers,
       means[rows_to_plot] + se[rows_to_plot] ** 2,
       angle=90,
       code=3)
```


```{r plot_pr_reply_members, fig.width=8}
group_of_interest = "pr_reply:member"
rows_to_plot = grep(group_of_interest, names(means))

bar_centers = barplot(means[rows_to_plot], names.arg=projects,
		      main=group_of_interest,
		      cex.names=0.8)
arrows(bar_centers,
       means[rows_to_plot] - se[rows_to_plot] ** 2, 
       bar_centers,
       means[rows_to_plot] + se[rows_to_plot] ** 2,
       angle=90,
       code=3)
```

```{r plot_pr_reply_nonmembers, fig.width=8}
group_of_interest = "pr_reply:nonmember"
rows_to_plot = grep(group_of_interest, names(means))

bar_centers = barplot(means[rows_to_plot], names.arg=projects,
		      main=group_of_interest,
		      cex.names=0.8)
arrows(bar_centers,
       means[rows_to_plot] - se[rows_to_plot] ** 2, 
       bar_centers,
       means[rows_to_plot] + se[rows_to_plot] ** 2,
       angle=90,
       code=3)
```


```{r plot_issue_reply_members, fig.width=8}
group_of_interest = "issue_reply:member"
rows_to_plot = grep(group_of_interest, names(means))

bar_centers = barplot(means[rows_to_plot], names.arg=projects,
		      main=group_of_interest,
		      cex.names=0.8)
arrows(bar_centers,
       means[rows_to_plot] - se[rows_to_plot] ** 2, 
       bar_centers,
       means[rows_to_plot] + se[rows_to_plot] ** 2,
       angle=90,
       code=3)
```

```{r plot_issue_reply_nonmembers, fig.width=8}
group_of_interest = "issue_reply:nonmember"
rows_to_plot = grep(group_of_interest, names(means))

bar_centers = barplot(means[rows_to_plot], names.arg=projects,
		      main=group_of_interest,
		      cex.names=0.8)
arrows(bar_centers,
       means[rows_to_plot] - se[rows_to_plot] ** 2, 
       bar_centers,
       means[rows_to_plot] + se[rows_to_plot] ** 2,
       angle=90,
       code=3)
```

### Model 1.1c Do projects differ in emotion between one another?

One versus all minus one type of approach.

```{r compound_emotion_all_vs_one}
all_project_tests = NA
all_projects = unique(sentiment_frame$project)

# We're going to fit the model for each projects, and concatenate the results
# in a dataframe. Then, we'll apply multiple correction and display the
# results
for(project in all_projects){
    sentiment_frame$test_group = sentiment_frame$project == project
    one_versus_all_emotion = lmer(
	compound_emotion ~ 0 + type:author_group:test_group + (1|author_name),
	data=sentiment_frame,
	REML=FALSE)

    # Clean up mode
    coefficients_and_se = data.frame(
	summary(one_versus_all_emotion)$coefficients)
    row_names = gsub(
	"author_group", "", 
	    gsub("type", "",
		gsub("project", "", row.names(coefficients_and_se))))

    means = coefficients_and_se$Estimate
    names(means) = row_names
    se = coefficients_and_se$Std..Error
    names(se) = row_names

    contrasts = c(
	"issue_post:member:test_groupTRUE-issue_post:member:test_groupFALSE",
	"pr_post:member:test_groupTRUE-pr_post:member:test_groupFALSE",
	"issue_reply:member:test_groupTRUE-issue_reply:member:test_groupFALSE",
	"pr_reply:member:test_groupTRUE-pr_reply:member:test_groupFALSE",
	"issue_post:nonmember:test_groupTRUE-issue_post:nonmember:test_groupFALSE",
	"pr_post:nonmember:test_groupTRUE-pr_post:nonmember:test_groupFALSE",
	"issue_reply:nonmember:test_groupTRUE-issue_reply:nonmember:test_groupFALSE",
	"pr_reply:nonmember:test_groupTRUE-pr_reply:nonmember:test_groupFALSE"
	)

    one_versus_all_emotion_tests = compute_t_statistics(
	means, se,
	contrasts)
    one_versus_all_emotion_tests[, "p_value"] = compute_p_value_from_t_stats(
	one_versus_all_emotion_tests$t_stats)

    # Add unique identifier based on the project of interest in the table.
    row.names(one_versus_all_emotion_tests) = gsub(
	"test_group", project,
	row.names(one_versus_all_emotion_tests))

    if(is.null(dim(all_project_tests))){
	all_project_tests = one_versus_all_emotion_tests
    }else{
	all_project_tests = rbind(
	    all_project_tests, one_versus_all_emotion_tests)
    }
}
```

Now apply multiple correction and display the results of the analysis.

```{r one_versus_all_display_results}
pander_clean_anova(all_project_tests, rename_columns=FALSE)
```

### Model 1.2 time-course analysis

The time-course analysis has been moved in a separate file.

### Model 1.3: Do tickets and comments materially differ in gratitude?

First, let's take a look at a summary table of expressions of gratitude by
membership status and contribution type.

```{r gratitude-summary-stats, eval=TRUE, echo=TRUE}

# create a summary table of gratitude by type and author association
gratitude_summary_stats = sentiment_frame %>% ungroup() %>%
  group_by(author_group, type, grateful_count) %>%
  summarise(n = n())
pander(gratitude_summary_stats, style = 'rmarkdown')

```

Now that we have a better idea of how the underlying data look, let's go ahead
and build our model.

```{r model-gratitude-by-type-and-author-and-project-v1, eval = TRUE}

# do users tend to express appreciation and gratitude differently by group and content?
creators_v_commenters_gratitude_by_project = lmer(log(grateful_count + 1) ~ project * author_group * type +
                                                    (1 | author_name),
                                                  data=sentiment_frame)

# print results
pander_lme(creators_v_commenters_gratitude_by_project)

```

```{r plot-gratitude-predictors-by-project, include=FALSE, eval=TRUE}
grateful_plot = ggplot(data=sentiment_frame,
                       aes(colour=type,
                           y=grateful_count,
                           x=author_group)) +
  stat_summary(fun.y=mean, geom="point", size=2) +
  stat_summary(fun.data = mean_se, geom = "errorbar") +
  facet_grid(cols = vars(ticket_family),
             rows = vars(project)) +
  ggtitle('Expressions of gratitude by contribution\nand community membership') +
  ylab('Gratitude') +
  xlab('Community membership') +
  labs(color='Contribution type') +
  scale_color_manual(labels = c("Issue: Post",
                                "Issue: Reply",
                                "PR: Post",
                                "PR: Reply"),
                     values = c("#e66101", # issue: post (darker)
                                "#fdb863", # issue: reply (lighter)
                                "#5e3c99", # PR: post (darker)
                                "#b2abd2")) # PR: reply (lighter)

# save full version
ggsave(plot = grateful_plot,
       height = 5,
       width = 6,
       filename = '../../figures/sentiment_analysis/ossc-grateful_membership_contribution.jpg')

# save smaller version for knitr
ggsave(plot = grateful_plot,
       height = 5,
       width = 6,
       dpi = 150,
       filename = '../../figures/sentiment_analysis/ossc-grateful_membership_contribution-knitr.jpg')

```

![**Figure**. Expressions of gratitude by contribution type (ticket vs. comment) and community membership (member vs. nonmember) at the time of posting.](../../figures/sentiment_analysis/ossc-grateful_membership_contribution-knitr.jpg)

### Testing Model 1.3 using Model 1.1 methods

#### Model 1.3a: Overall effects with linear mixed-effects models

This model presents the analyses in a way that is typical of psychological
analyses. We predict the changes in emotion by community membership and 
contribution type, including random effects for project and for author. This
allows us to explore the general patterns of the main and interaction terms,
rather than focusing in on the project-specific variability.

```{r retrying-model-1.3}

# do users tend to express appreciation and gratitude differently by group and content?
retrying_model_1.3 = lmer(log(grateful_count + 1) ~ author_group * type +
                            (1 | project),
                          data=sentiment_frame)

```

```{r print-retrying-model-1.3, eval=TRUE, echo=FALSE}

# print results
pander_lme(retrying_model_1.3)

```

While we see significant differences in the model, interpreting the results is
difficult because of the way that `lmer` handles factor comparisons. All 
factors are compared against a "reference level," the first level in the model.
This makes intepreting models with factors that include more than two levels
incredibly difficult, because the intercept is essentially an interaction term
among all reference levels of all factors.

As a result, we turn to the biostatistics approach of multiple *t*-tests 
(corrected for comparisons) of the model estimates to better understand the 
effects.

#### Model 1.3b: In-depth investigation through *t*-tests of model estimates

First, we build a series of linear mixed-effects models with one term included
in each model (either main term or interaction term). We then use the estimates
from those models to perform *t*-tests to investigate how different levels of
the effects differ from one another (and not just from the model-level
intercept).

Projects here are random effects, but the rest of the model is the same as
before. This allows us to do pairwise testing of main and interaction terms,
along with better exploring inter-project variability.

##### Model 1.3b.1: Does sentiment vary significantly by community membership?

First, look at whether there are differences in sentiment between author
groups.

```{r model-gratitude-by-author-group}

# do members and nonmembers materially differ in emotion?
fixed_authors_gratitude = lmer(
  log(grateful_count + 1) ~ 0 + author_group + (1 | project),
  data=sentiment_frame,
  REML=FALSE)

```

Run *t*-tests among levels and prepare for the Model 1.1b table later.

```{r clean-up-model-1.3b1-output}

# convert Model 1.1b1 output to dataframe
coefficients_and_se = data.frame(
  summary(fixed_authors_gratitude)$coefficients)

# get comparison names as rownames
row_names = gsub("author_group", "",
                 gsub("type", "", row.names(coefficients_and_se)))

# convert model estimates to a dataframe
means = coefficients_and_se$Estimate
names(means) = row_names

# convert standard error to dataframe
se = coefficients_and_se$Std..Error
names(se) = row_names

# compute t-statistics and p-values for desired contrasts
contrasts = c("member-nonmember")
author_groups_tests = compute_t_statistics(
  means, se,
  contrasts)
author_groups_tests[, "p_value"] = compute_p_value_from_t_stats(
  author_groups_tests$t_stats)

```

```{r saving_results-model-1.3b1}
write.table(coefficients_and_se,
	    file="results/models/model-1.3b1.tsv",
	    sep="\t")
```


##### Model 1.3b.2: Does sentiment vary significantly across contribution types?

Now, look at whether there are differences in sentiment between contribution
types.

```{r model-gratitude-by-type}

# do tickets and comments materially differ in emotion?
fixed_types_gratitude = lmer(
  log(grateful_count + 1) ~ 0 + type + (1 | project),
  data=sentiment_frame,
  REML=FALSE)

```

Run *t*-tests among levels and prepare for the Model 1.1b table later.

```{r clean-up-model-1.3b2-output}

# convert Model 1.1b2 output to dataframe
coefficients_and_se = data.frame(
  summary(fixed_types_gratitude)$coefficients)

# get comparison names as rownames
row_names = gsub("author_group", "",
                 gsub("type", "", row.names(coefficients_and_se)))

# convert model estimates to a dataframe
means = coefficients_and_se$Estimate
names(means) = row_names

# convert standard error to dataframe
se = coefficients_and_se$Std..Error
names(se) = row_names

# compute t-statistics and p-values for desired contrasts
contrasts = c("issue_post-issue_reply", # issues: posts vs. replies
              "pr_post-pr_reply",       # PRs: posts vs. replies
              "issue_post-pr_post",     # posts: issues vs. PRs
              "issue_reply-pr_reply")   # replies: issues vs. PRs
types_tests = compute_t_statistics(
  means, se,
  contrasts)
types_tests[, "p_value"] = compute_p_value_from_t_stats(types_tests$t_stats)

```

```{r saving_results-model-1.3b2}
write.table(coefficients_and_se,
	    file="results/models/model-1.3b2.tsv",
	    sep="\t")
```


##### Model 1.3b.3: Does sentiment vary significantly across community memberships and contribution types?

Finally, let's look at the interaction between membership and contribution.

```{r model-gratitude-by-type-and-author-interaction-only}

# does emotion differ by the interaction between contribution and authorship group?
community_contribution_gratitude = lmer(
  log(grateful_count + 1) ~ 0 + type:author_group + (1 | project),
  data=sentiment_frame,
  REML=FALSE)

```

Run *t*-tests among levels and prepare for the Model 1.1b table later.

```{r clean-up-model-1.3b3-output}

# convert Model 1.1b3 output to dataframe
coefficients_and_se = data.frame(
  summary(community_contribution_gratitude)$coefficients)

# get comparison names as rownames
row_names = gsub("author_group", "", gsub("type", "", row.names(coefficients_and_se)))

# convert model estimates to a dataframe
means = coefficients_and_se$Estimate
names(means) = row_names

# convert standard error to dataframe
se = coefficients_and_se$Std..Error
names(se) = row_names

# compute t-statistics and p-values for desired contrasts
contrasts = c(
  "issue_post:member-issue_post:nonmember",     # contribution static (issue posts); membership varies (members v. nonmembers)
  "issue_reply:member-issue_reply:nonmember",   # contribution static (issue replies); membership varies (members v. nonmembers)
  "pr_post:member-pr_post:nonmember",           # contribution static (PR posts); membership varies (members v. nonmembers)
  "pr_reply:member-pr_reply:nonmember",         # contribution static (PR replies); membership varies (members v. nonmembers)
  "issue_post:member-issue_reply:member",       # contribution varies (issue posts vs. issue replies); membership static (members)
  "issue_post:nonmember-issue_reply:nonmember", # contribution varies (issue posts vs. issue replies); membership static (nonmembers)
  "pr_post:member-pr_reply:member",             # contribution varies (PR posts vs. PR replies); membership static (members)
  "pr_post:nonmember-pr_reply:nonmember",       # contribution varies (PR posts vs. PR replies); membership static (nonmembers)
  "issue_post:member-pr_post:member",           # contribution varies (issue posts vs. PR posts); membership static (members)
  "issue_post:nonmember-pr_post:nonmember",     # contribution varies (issue posts vs. PR posts); membership static (nonmembers)
  "issue_reply:member-pr_reply:member",         # contribution varies (issue replies vs. PR replies); membership static (members)
  "issue_reply:nonmember-pr_reply:nonmember")   # contribution varies (issue replies vs. PR replies); membership static (nonmembers)
types_author_groups_tests = compute_t_statistics(
  means, se,
  contrasts)
types_author_groups_tests[, "p_value"] = compute_p_value_from_t_stats(
  types_author_groups_tests$"t_stats")

```

```{r saving_results-model-1.3b3}
write.table(coefficients_and_se,
	    file="results/models/model-1.3b3.tsv",
	    sep="\t")
```


##### Model 1.3b.4 : Do different kinds of user contributions differ in emotion by projects?

Now adding projects into the mix to understand how the previous analysis
varies across projects.

```{r model-gratitude-by-type-and-author-and-project}

# do tickets and comments materially differ in gratitude by projects?
creators_v_commenters_gratitude_by_project = lm(
  log(grateful_count + 1) ~ 0 + project:type:author_group,
  data = sentiment_frame)

```

Run *t*-tests among levels and prepare for the Model 1.1b table later.

```{r clean-up-model-1.3c-output}

# convert Model 1.1c output to dataframe
coefficients_and_se = data.frame(
  summary(creators_v_commenters_gratitude_by_project)$coefficients)

# get comparison names as rownames
row_names = gsub(
  "project", "", gsub(
    "author_group", "", gsub(
      "type", "", row.names(coefficients_and_se))))

# replace hyphens in project names with periods
row_names = gsub(
  "scikit-", "scikit.", gsub(
    "sphinx-", "sphinx.", row_names))

# convert model estimates to a dataframe
means = coefficients_and_se$Estimate
names(means) = row_names

# convert standard error to dataframe
se = coefficients_and_se$Std..Error
names(se) = row_names

# compute t-statistics and p-values for desired contrasts
# (note: ordering of contrasts within each project is identical to Model 1.3b.3)
contrasts = c(
  
  # scikit-learn
  "scikit.learn:issue_post:member-scikit.learn:issue_post:nonmember",
  "scikit.learn:issue_reply:member-scikit.learn:issue_reply:nonmember",
  "scikit.learn:pr_post:member-scikit.learn:pr_post:nonmember",
  "scikit.learn:pr_reply:member-scikit.learn:pr_reply:nonmember",
  "scikit.learn:issue_post:member-scikit.learn:issue_reply:member",
  "scikit.learn:issue_post:nonmember-scikit.learn:issue_reply:nonmember",
  "scikit.learn:pr_post:member-scikit.learn:pr_reply:member",
  "scikit.learn:pr_post:nonmember-scikit.learn:pr_reply:nonmember",
  "scikit.learn:issue_post:member-scikit.learn:pr_post:member",
  "scikit.learn:issue_post:nonmember-scikit.learn:pr_post:nonmember",
  "scikit.learn:issue_reply:member-scikit.learn:pr_reply:member",
  "scikit.learn:issue_reply:nonmember-scikit.learn:pr_reply:nonmember",
  
  # scikit-image
  "scikit.image:issue_post:member-scikit.image:issue_post:nonmember",
  "scikit.image:issue_reply:member-scikit.image:issue_reply:nonmember",
  "scikit.image:pr_post:member-scikit.image:pr_post:nonmember",
  "scikit.image:pr_reply:member-scikit.image:pr_reply:nonmember",
  "scikit.image:issue_post:member-scikit.image:issue_reply:member",
  "scikit.image:issue_post:nonmember-scikit.image:issue_reply:nonmember",
  "scikit.image:pr_post:member-scikit.image:pr_reply:member",
  "scikit.image:pr_post:nonmember-scikit.image:pr_reply:nonmember",
  "scikit.image:issue_post:member-scikit.image:pr_post:member",
  "scikit.image:issue_post:nonmember-scikit.image:pr_post:nonmember",
  "scikit.image:issue_reply:member-scikit.image:pr_reply:member",
  "scikit.image:issue_reply:nonmember-scikit.image:pr_reply:nonmember",
  
  # matplotlib
  "matplotlib:issue_post:member-matplotlib:issue_post:nonmember",
  "matplotlib:issue_reply:member-matplotlib:issue_reply:nonmember",
  "matplotlib:pr_post:member-matplotlib:pr_post:nonmember",
  "matplotlib:pr_reply:member-matplotlib:pr_reply:nonmember",
  "matplotlib:issue_post:member-matplotlib:issue_reply:member",
  "matplotlib:issue_post:nonmember-matplotlib:issue_reply:nonmember",
  "matplotlib:pr_post:member-matplotlib:pr_reply:member",
  "matplotlib:pr_post:nonmember-matplotlib:pr_reply:nonmember",
  "matplotlib:issue_post:member-matplotlib:pr_post:member",
  "matplotlib:issue_post:nonmember-matplotlib:pr_post:nonmember",
  "matplotlib:issue_reply:member-matplotlib:pr_reply:member",
  "matplotlib:issue_reply:nonmember-matplotlib:pr_reply:nonmember",
  
  # mayavi
  "mayavi:issue_post:member-mayavi:issue_post:nonmember",
  "mayavi:issue_reply:member-mayavi:issue_reply:nonmember",
  "mayavi:pr_post:member-mayavi:pr_post:nonmember",
  "mayavi:pr_reply:member-mayavi:pr_reply:nonmember",
  "mayavi:issue_post:member-mayavi:issue_reply:member",
  "mayavi:issue_post:nonmember-mayavi:issue_reply:nonmember",
  "mayavi:pr_post:member-mayavi:pr_reply:member",
  "mayavi:pr_post:nonmember-mayavi:pr_reply:nonmember",
  "mayavi:issue_post:member-mayavi:pr_post:member",
  "mayavi:issue_post:nonmember-mayavi:pr_post:nonmember",
  "mayavi:issue_reply:member-mayavi:pr_reply:member",
  "mayavi:issue_reply:nonmember-mayavi:pr_reply:nonmember",
  
  # pandas
  "pandas:issue_post:member-pandas:issue_post:nonmember",
  "pandas:issue_reply:member-pandas:issue_reply:nonmember",
  "pandas:pr_post:member-pandas:pr_post:nonmember",
  "pandas:pr_reply:member-pandas:pr_reply:nonmember",
  "pandas:issue_post:member-pandas:issue_reply:member",
  "pandas:issue_post:nonmember-pandas:issue_reply:nonmember",
  "pandas:pr_post:member-pandas:pr_reply:member",
  "pandas:pr_post:nonmember-pandas:pr_reply:nonmember",
  "pandas:issue_post:member-pandas:pr_post:member",
  "pandas:issue_post:nonmember-pandas:pr_post:nonmember",
  "pandas:issue_reply:member-pandas:pr_reply:member",
  "pandas:issue_reply:nonmember-pandas:pr_reply:nonmember",
  
  # scipy
  "scipy:issue_post:member-scipy:issue_post:nonmember",
  "scipy:issue_reply:member-scipy:issue_reply:nonmember",
  "scipy:pr_post:member-scipy:pr_post:nonmember",
  "scipy:pr_reply:member-scipy:pr_reply:nonmember",
  "scipy:issue_post:member-scipy:issue_reply:member",
  "scipy:issue_post:nonmember-scipy:issue_reply:nonmember",
  "scipy:pr_post:member-scipy:pr_reply:member",
  "scipy:pr_post:nonmember-scipy:pr_reply:nonmember",
  "scipy:issue_post:member-scipy:pr_post:member",
  "scipy:issue_post:nonmember-scipy:pr_post:nonmember",
  "scipy:issue_reply:member-scipy:pr_reply:member",
  "scipy:issue_reply:nonmember-scipy:pr_reply:nonmember",
  
  # numpy
  "numpy:issue_post:member-numpy:issue_post:nonmember",
  "numpy:issue_reply:member-numpy:issue_reply:nonmember",
  "numpy:pr_post:member-numpy:pr_post:nonmember",
  "numpy:pr_reply:member-numpy:pr_reply:nonmember",
  "numpy:issue_post:member-numpy:issue_reply:member",
  "numpy:issue_post:nonmember-numpy:issue_reply:nonmember",
  "numpy:pr_post:member-numpy:pr_reply:member",
  "numpy:pr_post:nonmember-numpy:pr_reply:nonmember",
  "numpy:issue_post:member-numpy:pr_post:member",
  "numpy:issue_post:nonmember-numpy:pr_post:nonmember",
  "numpy:issue_reply:member-numpy:pr_reply:member",
  "numpy:issue_reply:nonmember-numpy:pr_reply:nonmember",
  
  # sphinx-gallery
  "sphinx.gallery:issue_post:member-sphinx.gallery:issue_post:nonmember",
  "sphinx.gallery:issue_reply:member-sphinx.gallery:issue_reply:nonmember",
  "sphinx.gallery:pr_post:member-sphinx.gallery:pr_post:nonmember",
  "sphinx.gallery:pr_reply:member-sphinx.gallery:pr_reply:nonmember",
  "sphinx.gallery:issue_post:member-sphinx.gallery:issue_reply:member",
  "sphinx.gallery:issue_post:nonmember-sphinx.gallery:issue_reply:nonmember",
  "sphinx.gallery:pr_post:member-sphinx.gallery:pr_reply:member",
  "sphinx.gallery:pr_post:nonmember-sphinx.gallery:pr_reply:nonmember",
  "sphinx.gallery:issue_post:member-sphinx.gallery:pr_post:member",
  "sphinx.gallery:issue_post:nonmember-sphinx.gallery:pr_post:nonmember",
  "sphinx.gallery:issue_reply:member-sphinx.gallery:pr_reply:member",
  "sphinx.gallery:issue_reply:nonmember-sphinx.gallery:pr_reply:nonmember"
)
project_types_author_group_tests = compute_t_statistics(
  means, se,
  contrasts)
project_types_author_group_tests[, "p_value"] = compute_p_value_from_t_stats(
  project_types_author_group_tests$t_stats)

```

```{r saving_results-model-1.3b4}
write.table(coefficients_and_se,
	    file="results/models/model-1.3b4.tsv",
	    sep="\t")
```


#### Model 1.3b: Overall results

Now we bring together all analyses from Model 1.3b.

```{r output-model1.3b-results-table}

# specify main terms
author_groups_tests["contrast"] = row.names(author_groups_tests)
types_tests["contrast"] = row.names(types_tests)
all_tests = merge(author_groups_tests, types_tests, all=TRUE, sort=FALSE)
all_tests["model"] = "Main Terms"

# specify 2-way interactions
types_author_groups_tests["contrast"] = row.names(types_author_groups_tests)
types_author_groups_tests["model"] = "2W: Types x Author Groups"
all_tests = merge(all_tests, types_author_groups_tests, all=TRUE, sort=FALSE)

# specify 3-way interactions
project_types_author_group_tests["contrast"] = row.names(project_types_author_group_tests)
project_types_author_group_tests["model"] = "3W: Types x Author Groups x Project"
all_tests = merge(all_tests, project_types_author_group_tests, all=TRUE,
                  sort=FALSE)

```

Let's correct all tests at once for multiple comparisons.

```{r corect-and-display-all-model-1.3b-tests}

# specify all contrasts
row.names(all_tests) = all_tests$contrast
all_tests = subset(all_tests, select=-c(contrast))

# print the table (reordering columns for readibility)
all_tests = all_tests[c("model", "t_stats", "p_value")]
pander_clean_anova(all_tests, rename_columns=FALSE)

```

```{r gratitude_write_all_results}
all_tests$p_val_adjusted = p.adjust(all_tests$p_value, method="BH")
write.table(all_tests, file="results/models/model-1.3b_final_pvalues.tsv")
```


## Model Series 2: Retention
Our second set of models investigates what aspects of the response to a 
newcomer's first contribution might predict their likelihood to come back
to contribute a second time.

### Data preparation

Because each ticket has multiple comments, we cannot use the standard long-form
format for the dataset, or we would lead to (uneven) duplication of tickets
based on the varying numbers of comments. As a result, we pull metrics of the
whole comment chain and use them as our measures of the community's response
to the newcomer's contribution.

```{r aggregate-comments-frame}

# aggregate ticket-level metrics for comments
aggregated_comments = comments_frame %>% ungroup() %>%
  
  # convert author group to numeric
  mutate(author_group_numeric = dplyr::if_else(author_group=='member',
                                               1,
                                               0)) %>%
  
  # create metrics for each unique ticket in each project
  dplyr::group_by(project, ticket_id) %>%
  dplyr::summarise(number_of_comments = n(),
                   comment_sentiment_mean = mean(compound_emotion, na.rm=TRUE),
                   comment_sentiment_variance = var(compound_emotion),
                   comment_sentiment_max_negative = max(negative_emotion),
                   comment_sentiment_max_positive = max(positive_emotion),
                   comment_grateful_cumulative = sum(grateful_count),
                   comment_first_response = min(date),
                   comment_member_ratio = sum(author_group_numeric)/n())

```

After we've summarized the comment threads, we next join those metrics with the
tickets dataframe in preparation for our models.



```{r prep-for-retention-analysis}

# create joint dataframe
retention_frame = tickets_frame %>%
  dplyr::left_join(., aggregated_comments,
                   by=c('project', 'ticket_id')) %>%
  
  # keep only newcomers
  dplyr::filter(first_ticket == TRUE) %>%
  
  # keep only select variables
  dplyr::select(project,
                date,
                contains('author'),
                first_ticket,
                contains('num_'),
                contains('ticket'),
                contains('type'),
                contains('grateful_count'),
                contains('emotion'),
                open_time,
                contains('comment_'),
                number_of_comments,
                -contains('stamp'),
                -contains('last_comment')) %>%
  
  # read appropriate variables as logical
  mutate_at(vars(first_ticket,
                 ticket_author_last_ticket),
            as.logical) %>%
  
  # recode and rename retention variable so that it reflects continued engagement
  dplyr::rename(retained_newcomer = ticket_author_last_ticket) %>%
  mutate(retained_newcomer = dplyr::if_else(retained_newcomer==TRUE,
                                            FALSE,
                                            TRUE)) %>%
  
  # recode ticket group as two-level numeric factor
  mutate(ticket_family_numeric = dplyr::if_else(ticket_family=='issue',
                                                -.5,
                                                .5)) %>%
  
  #convert to factors (as needed) for proper modeling
  mutate_at(vars(project,
                 author_name,
                 author_group,
                 author_association,
                 type,
                 type_family,
                 ticket_family,
                 ticket_family_numeric,
                 retained_newcomer),
            as.factor)
```

```{r write_data_newcomer_retention}
write.table(retention_frame, "results/data/newcomer_retention.tsv", sep="\t")
```

### Model 2.1: How does a community's response to newcomers predict the newcomer's decision to return?

```{r plot-predicting-retention-aggregated, include=FALSE, eval=TRUE}

# create the plot of newcomer retention across all projects
retention_plot_aggregated = ggplot(data=retention_frame,
                                   aes(x=open_time/(60*60*24),
                                       color=comment_member_ratio,
                                       y=comment_sentiment_mean)) +
  geom_jitter(alpha=0.3, size=.1) +
  facet_grid(cols = c(vars(ticket_family),
                      vars(retained_newcomer)),
             labeller = labeller(
               ticket_family = c(issue = "Issue", 
                                 pr = "PR"),
               retained_newcomer = c('TRUE'="Retained",
                                     'FALSE'="Lost"))) +
  ggtitle("Newcomer retention by community response\nand community attentiveness") +
  xlab('Time open (in days)') +
  ylab('Mean sentiment of comments') +
  scale_color_viridis() + 
  labs(color='Ratio of comments\nmade by members') +
  theme(legend.position = "bottom")

# save full version
ggsave(plot = retention_plot_aggregated,
       height = 5,
       width = 6,
       filename = '../../figures/sentiment_analysis/ossc-retention_emotion-aggregated.jpg')

# save smaller version for knitr
ggsave(plot = retention_plot_aggregated,
       height = 5,
       width = 6,
       dpi = 150,
       filename = '../../figures/sentiment_analysis/ossc-retention_emotion-aggregated-knitr.jpg')

```

```{r plot-predicting-retention-by-project, echo=FALSE, include=FALSE, eval=TRUE}

# create the plot of newcomer retention by each project
retention_plot_by_project = ggplot(data=retention_frame,
                                   aes(x=open_time/(60*60*24),
                                       color=comment_member_ratio,
                                       y=comment_sentiment_mean)) +
  geom_jitter(alpha=0.3, size=.1) +
  facet_grid(rows = vars(project),
             cols = c(vars(ticket_family),
                      vars(retained_newcomer)
             ),
             labeller = labeller(
               ticket_family = c(issue = "Issue", 
                                 pr = "PR"),
               retained_newcomer = c('TRUE'="Retained",
                                     'FALSE'="Lost"))) +
  ggtitle("Newcomer retention by community response\nand community attentiveness (by project)") +
  xlab('Time open (in days)') +
  ylab('Mean sentiment of comments') +
  scale_color_viridis() + 
  labs(color='Ratio of comments\nmade by members') +
  theme(legend.position = "bottom")

# save full version
ggsave(plot = retention_plot_by_project,
       height = 10,
       width = 6,
       filename = '../../figures/sentiment_analysis/ossc-retention_emotion-by_project.jpg')

# save smaller version for knitr
ggsave(plot = retention_plot_by_project,
       height = 10,
       width = 6,
       dpi = 150,
       filename = '../../figures/sentiment_analysis/ossc-retention_emotion-by_project-knitr.jpg')

```

![**Figure**. Whether a first-time ticket creator will open a second ticket by commenters' expressions of gratitude and responsiveness.](../../figures/sentiment_analysis/ossc-retention_emotion-by_project-knitr.jpg)

```{r retention_contribution_type}
retention_predictors = glmer(retained_newcomer ~ 0 + ticket_family + (1 | project),
			   data=retention_frame, family=binomial)
coefficients_and_se = data.frame(
  summary(retention_predictors)$coefficients)

# get comparison names as rownames
row_names = gsub("ticket_family", "", row.names(coefficients_and_se))
# convert model estimates to a dataframe
means = coefficients_and_se$Estimate
names(means) = row_names

# convert standard error to dataframe
se = coefficients_and_se$Std..Error
names(se) = row_names

# compute t-statistics and p-values for desired contrasts
contrasts = c("pr-issue")
retention_tests = compute_t_statistics(
  means, se,
  contrasts)
retention_tests[, "p_value"] = compute_p_value_from_t_stats(
  retention_tests$t_stats)


# Keep coefficient + sde for plotting purposes
all_coefs_and_se = coefficients_and_se[, c("Estimate", "Std..Error")]
```

```{r retention_open_time}
retention_predictor = glmer(retained_newcomer ~ open_time + (1 | project),
			  data=retention_frame, family=binomial, nAGQ=0)
retention_tests_continuous = as.data.frame(summary(
    retention_predictor)$coefficients)
new_coefs = retention_tests_continuous[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
    all_coefs_and_se, new_coefs)
retention_tests_continuous[, "row_names"] = row.names(
    retention_tests_continuous)

retention_predictor = glmer(retained_newcomer ~ comment_grateful_cumulative + (1 | project),
			  data=retention_frame, family=binomial, nAGQ=0)
retention_grateful =  as.data.frame(summary(retention_predictor)$coefficients)
new_coefs = retention_grateful[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
    all_coefs_and_se, new_coefs)
retention_grateful[, "row_names"] = row.names(
    retention_grateful)
retention_tests_continuous = merge(
    retention_tests_continuous,
    retention_grateful, all=TRUE, sort=FALSE)

retention_predictor = glmer(retained_newcomer ~ comment_sentiment_max_negative + (1 | project),
			  data=retention_frame, family=binomial, nAGQ=0)
retention_comment_sentiment_max_negative = as.data.frame(
    summary(retention_predictor)$coefficients)
new_coefs = retention_comment_sentiment_max_negative[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
    all_coefs_and_se, new_coefs)
retention_comment_sentiment_max_negative[, "row_names"] = row.names(
    retention_comment_sentiment_max_negative)
retention_tests_continuous = merge(
    retention_tests_continuous,
    retention_comment_sentiment_max_negative,
    all=TRUE, sort=FALSE)


retention_predictor = glmer(retained_newcomer ~ comment_sentiment_max_positive + (1 | project),
			  data=retention_frame, family=binomial, nAGQ=0)
retention_comment_sentiment_max_positive = as.data.frame(
    summary(retention_predictor)$coefficients)
new_coefs = retention_comment_sentiment_max_positive[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
    all_coefs_and_se, new_coefs)
retention_comment_sentiment_max_positive[, "row_names"] = row.names(
    retention_comment_sentiment_max_positive)
retention_tests_continuous = merge(
    retention_tests_continuous,
    retention_comment_sentiment_max_positive,
    all=TRUE, sort=FALSE)


retention_predictor = glmer(retained_newcomer ~ number_of_comments + (1 | project),
			  data=retention_frame, family=binomial, nAGQ=0)
retention_number_of_comment = as.data.frame(
    summary(retention_predictor)$coefficients)
new_coefs = retention_number_of_comment[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
    all_coefs_and_se,
    new_coefs)
retention_number_of_comment[, "row_names"] = row.names(
    retention_number_of_comment)
retention_tests_continuous = merge(
    retention_tests_continuous,
    retention_number_of_comment,
    all=TRUE, sort=FALSE)


retention_predictor = glmer(retained_newcomer ~ comment_member_ratio + (1 | project),
			  data=retention_frame, family=binomial, nAGQ=0)

retention_comment_member_ratio = as.data.frame(
    summary(retention_predictor)$coefficients)
new_coefs = retention_comment_member_ratio[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
    all_coefs_and_se,
    new_coefs)

retention_comment_member_ratio[, "row_names"] = row.names(
    retention_comment_member_ratio)
retention_tests_continuous = merge(
    retention_tests_continuous,
    retention_comment_member_ratio,
    all=TRUE, sort=FALSE)


retention_predictor = glmer(retained_newcomer ~ comment_sentiment_mean + (1 | project),
			  data=retention_frame, family=binomial, nAGQ=0)
retention_comment_sentiment_mean = as.data.frame(
    summary(retention_predictor)$coefficients)
new_coefs = retention_comment_sentiment_mean[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
    all_coefs_and_se,
    new_coefs)
retention_comment_sentiment_mean[, "row_names"] = row.names(
    retention_comment_sentiment_mean)
retention_tests_continuous = rbind(
    retention_tests_continuous,
    retention_comment_sentiment_mean)
```

Now let's do interaction terms between contribution types and everything else.

```{r interaction_terms}
retention_predictor = glmer(
    retained_newcomer ~ 0 + ticket_family + ticket_family:open_time + (1 | project),
    data=retention_frame, family=binomial, nAGQ=0)
retention_open_time = as.data.frame(
    summary(retention_predictor)$coefficients)
new_coefs = retention_open_time[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
    all_coefs_and_se,
    new_coefs)
retention_open_time[, "row_names"] = row.names(
    retention_open_time)
retention_tests_continuous = rbind(
    retention_tests_continuous,
    retention_open_time)

retention_predictor = glmer(
    retained_newcomer ~ 0 + ticket_family + ticket_family:comment_sentiment_max_negative + (1 | project),
    data=retention_frame, family=binomial, nAGQ=0)
retention_comment_sentiment_max_negative = as.data.frame(
    summary(retention_predictor)$coefficients)
new_coefs = retention_comment_sentiment_max_negative[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
    all_coefs_and_se,
    new_coefs)
retention_comment_sentiment_max_negative[, "row_names"] = row.names(
    retention_comment_sentiment_max_negative)
retention_tests_continuous = merge(
    retention_tests_continuous,
    retention_comment_sentiment_max_negative,
    all=TRUE, sort=FALSE)

retention_predictor = glmer(
    retained_newcomer ~ 0 + ticket_family + ticket_family:comment_sentiment_max_positive + (1 | project),
    data=retention_frame, family=binomial, nAGQ=0)
retention_comment_sentiment_max_positive = as.data.frame(
    summary(retention_predictor)$coefficients)
new_coefs = retention_comment_sentiment_max_positive[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
    all_coefs_and_se,
    new_coefs)
retention_comment_sentiment_max_positive[, "row_names"] = row.names(
    retention_comment_sentiment_max_positive)
retention_tests_continuous = merge(
    retention_tests_continuous,
    retention_comment_sentiment_max_positive,
    all=TRUE, sort=FALSE)


retention_predictor = glmer(
    retained_newcomer ~ 0 + ticket_family + ticket_family:number_of_comments + (1 | project),
    data=retention_frame, family=binomial, nAGQ=0)
retention_number_of_comments = as.data.frame(
    summary(retention_predictor)$coefficients)
new_coefs = retention_number_of_comments[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
    all_coefs_and_se,
    new_coefs)
retention_number_of_comments[, "row_names"] = row.names(
    retention_number_of_comments)
retention_tests_continuous = merge(
    retention_tests_continuous,
    retention_number_of_comments,
    all=TRUE, sort=FALSE)

retention_predictor = glmer(
    retained_newcomer ~ 0 + ticket_family + ticket_family:comment_member_ratio + (1 | project),
    data=retention_frame, family=binomial, nAGQ=0)
retention_comment_member_ratio = as.data.frame(
    summary(retention_predictor)$coefficients)
new_coefs = retention_comment_member_ratio[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
    all_coefs_and_se,
    new_coefs)
retention_comment_member_ratio[, "row_names"] = row.names(
    retention_comment_member_ratio)
retention_tests_continuous = rbind(
    retention_tests_continuous,
    retention_comment_member_ratio)

retention_predictor = glmer(
    retained_newcomer ~ 0 + ticket_family + ticket_family:comment_sentiment_mean + (1 | project),
    data=retention_frame, family=binomial, nAGQ=0)
retention_comment_sentiment_mean = as.data.frame(
    summary(retention_predictor)$coefficients)
new_coefs = retention_comment_sentiment_mean[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
    all_coefs_and_se,
    new_coefs)
retention_comment_sentiment_mean[, "row_names"] = row.names(
    retention_comment_sentiment_mean)
retention_tests_continuous = rbind(
    retention_tests_continuous,
    retention_comment_sentiment_mean)

retention_predictor = glmer(
    retained_newcomer ~ 0 + ticket_family + ticket_family:comment_grateful_cumulative + (1 | project),
    data=retention_frame, family=binomial, nAGQ=0)
retention_comment_grateful_cumulative = as.data.frame(
    summary(retention_predictor)$coefficients)
new_coefs = retention_comment_grateful_cumulative[, c("Estimate", "Std. Error")]
colnames(new_coefs) = colnames(all_coefs_and_se)
all_coefs_and_se = rbind(
    all_coefs_and_se,
    new_coefs)
retention_comment_grateful_cumulative[, "row_names"] = row.names(
    retention_comment_grateful_cumulative)
retention_tests_continuous = rbind(
    retention_tests_continuous,
    retention_comment_grateful_cumulative)


```

```{r cleaning_up_table}
mask = (
    retention_tests_continuous$row_names != "(Intercept)" &
    retention_tests_continuous$row_names != "ticket_familyissue" &
    retention_tests_continuous$row_names != "ticket_familypr")
retention_tests_continuous = retention_tests_continuous[mask, ]
row.names(retention_tests_continuous) = retention_tests_continuous[,
    "row_names"] 

columns_of_interest = c("z value", "Pr(>|z|)")
retention_tests_continuous = retention_tests_continuous[, columns_of_interest]
retention_tests_continuous["model"] = row.names(retention_tests_continuous)
colnames(retention_tests_continuous) = c("stat", "p_value", "model")
retention_tests["model"] = row.names(retention_tests)
colnames(retention_tests) = c("stat", "p_value", "model")

retention_tests = rbind(retention_tests, retention_tests_continuous)
```

```{r display_model2_results}
pander_clean_anova(retention_tests[c("model", "stat", "p_value")],
		   rename_columns=FALSE)
```

Both mean sentiment and max negative sentiment are predictive of newcomer
retention. We hypothesise that this might be due to giving a lot of feedback,
both positive and negative.

We thus now look at whether comment sentiment variance is predictive of
newcomer retension.

```{r sentiment_variance}
retention_predictor = glmer(
    retained_newcomer ~ 0 + ticket_family + ticket_family:comment_sentiment_variance + (1 | project),
    data=retention_frame, family=binomial, nAGQ=0)
retention_comment_sentiment_variance = as.data.frame(
    summary(retention_predictor)$coefficients)
colnames(retention_comment_sentiment_variance) = c("Estimate", "Std Error", "Z value", "p_value")
pander_clean_anova(retention_comment_sentiment_variance, rename_columns=FALSE)
```


```{r write_results}
write.table(all_coefs_and_se,
	    file="results/models/model_2.1.tsv", sep="\t")
```


***

# Future directions

Ideas:

* Do comments, generally, get more friendly or more hostile over time?
* Does the emotional valence of a contributor's first ticket predict whether
they'll come back to make a second one?
* Are requesters more or less polite?
* Does friendliness bring people back?
* Does the number and intensity of negative and positive comments on a
first-time contributor's ticket change whether they come back to make another
ticket?
