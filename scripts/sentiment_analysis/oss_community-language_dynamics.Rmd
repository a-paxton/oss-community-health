---
title: "Communication dynamics in OSS communities"
output:
  html_document:
    keep_md: yes
    number_sections: yes
---

This R markdown provides the data preparation for our forthcoming manuscript
(Paxton, Varoquaux, Geiger, & Holdgraf, *in preparation*). 

To run this from scratch, you will need the following files:

* `../../data/analysis_data/all-sentiment_frame.csv`: Contains cleaned data and
  derived variables from scraped GitHub data.
* `./utils/ossc-libraries_and_functions.r`: Loads in necessary libraries and 
  creates new functions for our analyses.

**Code written by**: A. Paxton (University of Connecticut) & N. Varoquaux 
(University of California, Berkeley)

**Date last modified**: 30 May 2019

```{r silent-preparations, echo=FALSE, include=FALSE}
library(knitr)
knitr::opts_chunk$set(cache=TRUE, autodep=TRUE)
```

***

# Preliminaries

```{r prelim, warning = FALSE, error = FALSE, message = FALSE}

# clear everything
rm(list=ls())

# load libraries and add new functions
source('./utils/ossc-libraries_and_functions.r')

# load data
joined_frame = read.table('../../data/analysis_data/all-sentiment_frame-for_r.csv', 
                          sep = ',', header=TRUE, fill=TRUE)
bot_names = read.table('../bot_names.txt') %>% .$V1 %>% as.character(.)

```

***

## Identify potential remaining bots

**Note**: This is useful to run if more data are collected. The results should 
be manually inspected, and any additional bots detected should be added to the
`../bot_names.txt` file. Otherwise, it does not need to be run.

```{r identify-bots, eval=FALSE}

# # identify potential bots based on who uses "bot" in their names
# potential_bot_df = joined_frame %>% ungroup() %>%
#   filter(grepl("bot",author_name_issue)) %>% 
#   filter(grepl("bot",author_name_comment)) %>%
#   select(author_name_issue, author_name_comment)
# 
# # find all unique instances
# bot_issues = as.character(unique(potential_bot_df$author_name_issue))
# bot_comments = as.character(unique(potential_bot_df$author_name_comment))
# potential_bots = unique(c(bot_issues,bot_comments))
# potential_bots = potential_bots[grepl("bot",potential_bots)]
# 
# # save to file
# write.table(potential_bots, file="ossc-potential_bots.csv",
#           col.names=FALSE, row.names=FALSE)

```

***

## Remove bots and clean up dates

Here, we ensure that all the users identified to be bots have been removed 
and convert the dates to a more interpretable format.

```{r dates-and-bots}

# fix time
joined_frame = joined_frame %>% ungroup() %>%
  
  # filter out bots
  filter(!author_name_issue %in% bot_names) %>%
  filter(!author_name_comment %in% bot_names) %>%
  
  # get time in days
  mutate(open_time_comment = strsplit(as.character(open_duration), ' ') %>%
           sapply(magrittr::extract2, 1) %>%
           as.numeric()) %>%
  mutate(open_time_issue = open_time_comment) %>%
  
  # get the year and month it was created 
  mutate(year_comment = as.numeric(format(as.Date(created_at_comment), "%Y"))) %>%
  mutate(year_issue = as.numeric(format(as.Date(created_at_issue), "%Y"))) %>%
  mutate(month_comment = as.numeric(format(as.Date(created_at_comment), "%m"))) %>%
  mutate(month_issue = as.numeric(format(as.Date(created_at_issue), "%m"))) %>%
  mutate(date_comment = as.numeric(as.Date(created_at_comment))) %>%
  mutate(date_issue = as.numeric(as.Date(created_at_issue))) %>%
  
  # drop old columns
  select(-ends_with('_at'), -contains('_at_'),
         -contains('month'), -contains('year'),
         -open_duration)
```

***

## Basic summary stats

Now that our data have been largely cleaned, let's take a look at some basic
patterns.

```{r user-stats, include=FALSE, echo=FALSE, eval=TRUE}

# get unique values
unique_commenters = as.character(unique(joined_frame$author_name_comment))
unique_issuers = as.character(unique(joined_frame$author_name_issue))
unique_users = as.character(unique(append(unique_commenters, unique_issuers)))

```

```{r activity-stats, include=FALSE, echo=FALSE, eval=TRUE}

# get counts of issue activity per project
activity_counts = joined_frame %>% ungroup() %>%
  dplyr::select(project, id_issue) %>%
  distinct() %>%
  group_by(project) %>%
  summarize(unique_issues = n())

# get counts of comment activity per project
comment_counts = joined_frame %>% ungroup() %>%
  dplyr::select(project, id_issue, id_comment) %>%
  distinct() %>%
  group_by(project, id_issue) %>%
  summarize(unique_comments = n())

```

Our dataset includes `r dim(activity_counts)[1]` unique projects with a total 
of `r sum(activity_counts$unique_issues)` unique issues, with a mean of 
`r mean(activity_counts$unique_issues)` issues per project.

On these issues, the dataset includes `r sum(comment_counts$unique_comments)` 
unique comments, with `r mean(comment_counts$unique_comments)` average comments
per issue.

In total, we have `r length(unique_commenters)` unique commenters, 
`r length(unique_issuers)` unique issue-creators, and `r length(unique_users)` 
overall unique users.

***

# Data analysis

***

## Model Series 1: Sentiment analysis

### Data preparation

Before we can run our models, we need to transform some our data into a
proper long-form format, with one unit (comment or issue) per line. However, 
because `joined_frame` includes unique lines by *comment*, it necessarily 
includes repeated instances of *issues* if multiple comments have been made on
the same issue. As a result, we must de-duplicate the dataframe after we 
disentangle the comments and issues.

```{r prepare-data-for-sentiment-analysis}

# mutate wide-form into long-form data
body_sentiment_df = joined_frame %>% ungroup() %>%
  select(contains('author'), 
         contains('grateful_count'),
         contains('emotion'),
         contains('id_'),
         contains('date_'),
         contains('open_'),
         contains('num_PR_'),
         contains('type_'),
         -contains('ticket_id'))

# separate out comments, issues, and last activity counters
comment_sentiment_df = body_sentiment_df %>% ungroup() %>%
  select(ends_with('_comment')) %>%
  rename_all(funs(gsub('_comment','',.)))
issue_sentiment_df = body_sentiment_df %>% ungroup() %>%
  select(ends_with('_issue')) %>%
  rename_all(funs(gsub('_issue','',.)))
last_counters = joined_frame %>% ungroup() %>%
  select(id_issue, id_comment, project, bus_factor,
         issue_author_last_issue, issue_author_last_comment)

# merge issues and comments separately with last comments
comment_sentiment_df = full_join(comment_sentiment_df,
                                 last_counters,
                                 by=c('id' = 'id_comment')) %>%
  select(-id_issue) %>%
  mutate(ticket_family = type,
         type = paste0(type,"_reply"),
         type_family = 'reply') %>%
  distinct()
issue_sentiment_df = full_join(issue_sentiment_df,
                               distinct(select(last_counters,
                                               -id_comment)),
                               by=c('id' = 'id_issue')) %>%
  mutate(ticket_family = type,
         type = paste0(type,"_post"),
         type_family = 'post') %>%
  distinct()

# append the dataframes
sentiment_frame = rbind.data.frame(comment_sentiment_df, issue_sentiment_df)

# concatenate association groups
sentiment_frame = sentiment_frame %>% ungroup() %>%
  mutate(author_group = dplyr::if_else(author_association=='MEMBER',
                               'member',
                               ifelse(author_association=='CONTRIBUTOR',
                                      'member',
                                      ifelse(author_association=='OWNER',
                                             'member',
                                             'nonmember')))) %>%
  
  # convert to factors (as needed) for proper modeling
  mutate(author_group = as.factor(author_group),
         type = as.factor(type),
         type_family = as.factor(type_family),
         ticket_family = as.factor(ticket_family))

```

#### Rationale for simplifying associations

Although we are eventually interested in studying first-time contributors,
we group everyone only into one of two categories for Model Series 1---either
`member` or `nonmember`. 

This is partly because the "first" tags are only applied in very specific
circumstances related to pull requests and issues. As a result, if we were 
going to keep original author associations, we would have to remove first-time
contributors and first-timers from the dataset when we're analyzing `type` 
as a covariate, since both types of users only ever submitted issues. However, 
because we are grouping simply by members and non-members, we can retain them 
in the dataset.

Here, we just confirm that this is the case.

```{r rationale-for-dropping-firsters, eval=TRUE}

# first time contributors
first_time_contrib_df = sentiment_frame %>%
  filter(author_association=='FIRST_TIME_CONTRIBUTOR')

# first time contributors
first_timers_df = sentiment_frame %>%
  filter(author_association=='FIRST_TIMER')

```

```{r print-rationale-for-droping-firsters, eval=TRUE, echo=FALSE, include=FALSE}

# print the output
print(paste0("Unique contribution types for first-timers: ",
             unique(first_timers_df$type)))
print(paste0("Unique contribution types for first-time contributors: ",
             unique(first_time_contrib_df$type)))

```

### Model 1.1: Do different kinds of user contributions materially differ in emotion?

Now we begin the actual modeling. Our first general question is whether users'
patterns of sentiment differ materially by whether they are a member of the
community versus a nonmember of the community and by their different kinds of
possible contributions (i.e., a posted pull request, a reply to a pull request,
a posted issue, or a reply to an issue).

```{r model-emotion-by-type-and-author-and-project}

# do issues and comments materially differ in emotion?
creators_v_commenters_emotion = lmer(compound_emotion ~ type * author_group +
                                       (1 | project) +
                                       (1 | author_name),
                                     data = sentiment_frame,
                                     REML=FALSE)

# print results
pander_lme(creators_v_commenters_emotion)

```

These results are quite different from our results conducted over a smaller
dataset last year. One potential reason is that these effects may be 
time-dependent. Our next model explores this possibility by adding a time term.

```{r plot-model-emotion-by-type-and-author, echo=FALSE, include=FALSE, eval=TRUE}

sentiment_plot = ggplot(data=sentiment_frame,
       aes(x=author_group,
           y=compound_emotion,
           colour=type)) +
  stat_summary(fun.y=mean, geom="point", size=2) + 
  stat_summary(fun.data = mean_se, geom = "errorbar") +
  coord_cartesian(ylim=c(0,.4)) +
  ggtitle('Message sentiment by contribution\nand community membership') +
  ylab('Sentiment score') +
  xlab('Community membership') +
  labs(color='Contribution type') +
  scale_color_manual(labels = c("Comment", "Issue"), 
                     values = c("darkgreen", "orange")) +
  facet_grid(. ~ project)

# plot a full-size version
ggsave(plot = sentiment_plot,
       height = 4,
       width = 10,
       filename = '../../figures/sentiment_analysis/ossc-sentiment_membership_contribution.jpg')

# plot a smaller one for knitr
ggsave(plot = sentiment_plot,
       height = 4,
       width = 10,
       dpi = 150,
       filename = '../../figures/sentiment_analysis/ossc-sentiment_membership_contribution-knitr.jpg')

```

![**Figure**. Sentiment by contribution type (issue vs. comment) and community membership (member vs. nonmember) at the time of posting.](../../figures/sentiment_analysis/ossc-sentiment_membership_contribution-knitr.jpg)

### Model 1.2: Do issues and comments materially differ in emotion over time?

```{r model-emotion-by-type-author-project-time}

# do issues and comments materially differ in emotion over time?
creators_v_commenters_emotion_time = lmer(compound_emotion ~ type * author_group * ns(date) +
                                            (1 | project) +
                                            (1 | author_name),
                                          data = sentiment_frame,
                                          REML=FALSE)

# print results
pander_lme(creators_v_commenters_emotion_time)

```

Interestingly, we see much more volatility here in the emotion dynamics
of community members relative to the community nonmembers over time, even
when we collapse across all projects.

Perhaps more interestingly, we see a difference in the affect dynamics
only in the last year: Members' issues are becoming more positive, while
nonmembers' issues are becoming more negative.

We'll need to do an analysis to follow up on this.

```{r plot-model-emotion-by-type-author-time, include=FALSE, echo=FALSE, eval=TRUE}

# split by membership type
member_frame = sentiment_frame %>% filter(author_group == 'member')
nonmember_frame = sentiment_frame %>% filter(author_group == 'nonmember')

# membership plot
sentiment_time_member_plot = ggplot(data=member_frame,
                                    aes(x=date,
                                        y=compound_emotion,
                                        colour=type)) +
  stat_smooth() +
  # stat_summary(alpha=0.5, size=.1) +
  coord_cartesian(ylim=c(-.6,1.0)) +
  theme(legend.position = "none") +
  ggtitle('For members') +
  ylab('Sentiment score') +
  scale_x_continuous(name = 'Date',
                     breaks = c(as.numeric(as.Date("2010-01-01")),
				as.numeric(as.Date("2012-01-01")),
				as.numeric(as.Date("2014-01-01")),
				as.numeric(as.Date("2016-01-01")),
				as.numeric(as.Date("2018-01-01"))),
		     labels = c("2010", "2012",
				"2014", "2016",
				"2018")) +
  labs(color='Contribution type') +
  scale_color_manual(labels = c("Comment", "Issue"), 
                     values = c("darkgreen", "orange")) +
  facet_grid(. ~ project)

# nonmembership plot
sentiment_time_nonmember_plot = ggplot(data=nonmember_frame,
                                       aes(x=date,
                                           y=compound_emotion,
                                           colour=type)) +
  stat_smooth() +
  # stat_summary(alpha=0.5, size=.1) +
  coord_cartesian(ylim=c(-.6,1.0)) +
  ggtitle('For nonmembers') +
  theme(legend.position = "none") +
  ylab('Sentiment score') +
  scale_x_continuous(name = 'Date',
                     breaks = c(as.numeric(as.Date("2010-01-01")),
				as.numeric(as.Date("2012-01-01")),
				as.numeric(as.Date("2014-01-01")),
				as.numeric(as.Date("2016-01-01")),
				as.numeric(as.Date("2018-01-01"))),
		     labels = c("2010", "2012",
				"2014", "2016",
				"2018")) +
  labs(color='Contribution type') +
  scale_color_manual(labels = c("Comment", "Issue"), 
                     values = c("darkgreen", "orange")) +
  facet_grid(. ~ project)

# create another nonmember plot just for the legend
sentiment_time_nonmember_legend = ggplot(data=nonmember_frame,
                                       aes(x=date,
                                           y=compound_emotion,
                                           colour=type)) +
  stat_smooth() +
  # stat_summary(alpha=0.5, size=.1) +
  coord_cartesian(ylim=c(-.6,1.0)) +
  ggtitle('For nonmembers') +
  ylab('') +
  xlab('Date') +
  labs(color='Contribution type') +
  scale_color_manual(labels = c("Comment", "Issue"), 
                     values = c("darkgreen", "orange")) +
  facet_grid(. ~ project)

# create a master legend
master_legend = gtable_filter(ggplot_gtable(
  ggplot_build(sentiment_time_nonmember_legend + 
                 theme(legend.position="bottom"))),
  "guide-box")

# save full version
ggsave(filename = '../../figures/sentiment_analysis/ossc-sentiment_membership_contribution_time.jpg',
       units = "in", height = 8, width = 12,
       grid.arrange(
         top=grid::textGrob("Message sentiment by contribution\nand community membership",
                      gp=grid::gpar(fontsize=14)),
         sentiment_time_member_plot,
         sentiment_time_nonmember_plot,
         bottom=master_legend,
         ncol = 1,
         nrow = 2
       ))

# save smaller version for knitr
ggsave(filename = '../../figures/sentiment_analysis/ossc-sentiment_membership_contribution_time-knitr.jpg',
       dpi = 150, height = 8, width = 12,
       grid.arrange(
         top=grid::textGrob("Message sentiment by contribution\nand community membership",
                      gp=grid::gpar(fontsize=14)),
         sentiment_time_member_plot,
         sentiment_time_nonmember_plot,
         bottom=master_legend,
         ncol = 1,
         nrow = 2
       ))

```
![**Figure**. Sentiment over time by contribution type (issue vs. comment) and community membership (member vs. nonmember) at the time of posting.](../../figures/sentiment_analysis/ossc-sentiment_membership_contribution_time-knitr.jpg)

### Model 1.3: Do issues and comments materially differ in gratitude?

```{r gratitude-summary-stats}

# create a summary table of gratitude by type and author association
gratitude_summary_stats = sentiment_frame %>% ungroup() %>%
  group_by(author_group, type, grateful_count) %>%
  summarise(n = n())
pander(gratitude_summary_stats)

```

```{r gratitude-predictors}

# do users tend to express appreciation and gratitude differently by group and content?
creators_v_commenters_gratitude = glmer(grateful_count ~ author_group * type +
                                          (1 | project) +
                                          (1 | author_name),
                                        data=sentiment_frame,
                                        family=poisson)

# print results
summary(creators_v_commenters_gratitude)

```

```{r plot-gratitude-predictors, include=FALSE, echo=FALSE, eval=TRUE}

grateful_plot = ggplot(data=sentiment_frame,
       aes(colour=type,
           y=grateful_count,
           x=author_group)) +
  stat_summary(fun.y=mean, geom="point", size=2) + 
  stat_summary(fun.data = mean_se, geom = "errorbar") +
  ggtitle('Expressions of gratitude by contribution\nand community membership') +
  ylab('Gratitude') +
  xlab('Community membership') +
  labs(color='Contribution type') +
  scale_color_manual(labels = c("Comment", "Issue"), 
                     values = c("darkgreen", "orange")) +
  facet_grid(. ~ project)

# save full version
ggsave(plot = grateful_plot,
       height = 4,
       width = 10,
       filename = '../../figures/sentiment_analysis/ossc-grateful_membership_contribution.jpg')

# save smaller version for knitr
ggsave(plot = grateful_plot,
       height = 4,
       width = 10,
       dpi = 150,
       filename = '../../figures/sentiment_analysis/ossc-grateful_membership_contribution-knitr.jpg')

```

![**Figure**. Expressions of gratitude by contribution type (issue vs. comment) and community membership (member vs. nonmember) at the time of posting.](../../figures/sentiment_analysis/ossc-grateful_membership_contribution-knitr.jpg)

### Model 1.4: Do issues and comments materially differ in gratitude over time?

**Note**: Having difficulty getting this to converge.

```{r gratitude-predictors-time}

# do users tend to express appreciation and gratitude differently by group and content?
creators_v_commenters_gratitude_time = glmer(grateful_count ~ (author_group + type) * ns(date) +
                                               (1 | project),
                                             data=sentiment_frame,
                                             family=poisson)

# print results
summary(creators_v_commenters_gratitude_time)

```

```{r plot-gratitude-predictors-time, echo=FALSE, eval=TRUE}

# split by membership type
member_frame = sentiment_frame %>% filter(author_group == 'member')
nonmember_frame = sentiment_frame %>% filter(author_group == 'nonmember')

# membership plot
gratitude_time_member_plot = ggplot(data=member_frame,
                                    aes(x=date,
                                        y=grateful_count,
                                        colour=type)) +
  stat_smooth() +
  # stat_summary(alpha=0.5, size=.1) +
  coord_cartesian(ylim=c(0,1.0)) +
  theme(legend.position = "none") +
  ggtitle('For members') +
  ylab('Mean expressions of gratitude') +
  scale_x_continuous(name = 'Date',
                     breaks = c(as.numeric(as.Date("2010-01-01")),
				as.numeric(as.Date("2012-01-01")),
				as.numeric(as.Date("2014-01-01")),
				as.numeric(as.Date("2016-01-01")),
				as.numeric(as.Date("2018-01-01"))),
		     labels = c("2010", "2012",
				"2014", "2016",
				"2018")) +
  labs(color='Contribution type') +
  scale_color_manual(labels = c("Comment", "Issue"), 
                     values = c("darkgreen", "orange")) +
  facet_grid(. ~ project)

# nonmembership plot
gratitude_time_nonmember_plot = ggplot(data=nonmember_frame,
                                       aes(x=date,
                                           y=grateful_count,
                                           colour=type)) +
  stat_smooth() +
  # stat_summary(alpha=0.5, size=.1) +
  coord_cartesian(ylim=c(0,1.0)) +
  ggtitle('For nonmembers') +
  theme(legend.position = "none") +
  ylab('Mean expressions of gratitude') +
  scale_x_continuous(name = 'Date',
                     breaks = c(as.numeric(as.Date("2010-01-01")),
				as.numeric(as.Date("2012-01-01")),
				as.numeric(as.Date("2014-01-01")),
				as.numeric(as.Date("2016-01-01")),
				as.numeric(as.Date("2018-01-01"))),
		     labels = c("2010", "2012",
				"2014", "2016",
				"2018")) +
  labs(color='Contribution type') +
  scale_color_manual(labels = c("Comment", "Issue"), 
                     values = c("darkgreen", "orange")) +
  facet_grid(. ~ project)

# create another nonmember plot just for the legend
gratitude_time_nonmember_legend = ggplot(data=nonmember_frame,
                                       aes(x=date,
                                           y=grateful_count,
                                           colour=type)) +
  stat_smooth() +
  # stat_summary(alpha=0.5, size=.1) +
  # coord_cartesian(ylim=c(-.6,1.0)) +
  ggtitle('For nonmembers') +
  ylab('Sentiment score') +
  xlab('Date') +
  labs(color='Contribution type') +
  scale_color_manual(labels = c("Comment", "Issue"), 
                     values = c("darkgreen", "orange")) +
  facet_grid(. ~ project)

# create a master legend
gratitude_master_legend = gtable_filter(ggplot_gtable(
  ggplot_build(gratitude_time_nonmember_legend + 
                 theme(legend.position="bottom"))),
  "guide-box")

# save full version
ggsave(filename = '../../figures/sentiment_analysis/ossc-gratitude_membership_contribution_time.jpg',
       units = "in", height = 8, width = 12,
       grid.arrange(
         top=grid::textGrob("Gratitude by contribution\nand community membership",
                      gp=grid::gpar(fontsize=14)),
         gratitude_time_member_plot,
         gratitude_time_nonmember_plot,
         bottom=gratitude_master_legend,
         ncol = 1,
         nrow = 2
       ))

# save smaller version for knitr
ggsave(filename = '../../figures/sentiment_analysis/ossc-gratitude_membership_contribution_time-knitr.jpg',
       dpi = 150, height = 8, width = 12,
       grid.arrange(
         top=grid::textGrob("Gratitude by contribution\nand community membership",
                      gp=grid::gpar(fontsize=14)),
         gratitude_time_member_plot,
         gratitude_time_nonmember_plot,
         bottom=gratitude_master_legend,
         ncol = 1,
         nrow = 2
       ))

```

![**Figure**. Expressions of gratitude over time by contribution type (issue vs. comment) and community membership (member vs. nonmember) at the time of posting.](../../figures/sentiment_analysis/ossc-gratitude_membership_contribution_time-knitr.jpg)

## Model Series 2: Retention

- **FIXME** we're using several times the same predictor observations, which
  means they are not IID. Here, we'll probably have to pull together all
  comments associated to one ticket.

### Data preparation

```{r prep-analysis}

# combine information by issue
retention_frame = joined_frame %>% ungroup() %>%
  group_by(project, id_issue) %>%
  summarize_if(is.numeric, mean, na.rm=TRUE) %>%
  ungroup() %>%
  left_join(., issue_sentiment_df,
            by=c('project', 'bus_factor',
                 'id_issue' = 'id'))

# normalize
retention_frame_st = retention_frame %>%
  mutate_all(funs(as.numeric(scale(as.numeric(.))))) %>%
  mutate(issue_author_last_issue = as.factor(issue_author_last_issue)) %>%
  mutate(project = as.factor(project))

```

```{r predicting-retention}

# what predicts continuing retention?
dropout_predictors = glmer(issue_author_last_issue ~ compound_emotion + grateful_count_comment + open_time +
                             (1 + grateful_count_comment | project),
                           data=retention_frame_st,
                           family=binomial)

# print it
summary(dropout_predictors)

```

**Note**. Need to fix this. Not really sure how best to demonstrate this given the limits of the linear fit...

```{r plot-predicting-retention, echo=FALSE, include=FALSE, eval=TRUE}

retention_plot = ggplot(data=retention_frame,
       aes(y=open_time,
           x=grateful_count_comment,
           color=issue_author_last_issue)) +
  stat_smooth(alpha=.5, geom='line', method=lm, formula = y ~ splines::bs(x, 3), se=TRUE) +
  geom_point(alpha=0.3, size=.1) +
  stat_smooth(method=lm) +
  ggtitle("Newcomer retention by gratitude\nand community attentiveness") +
  ylab('Time open (in days)') +
  xlab('Expressions of gratitude in comments') +
  labs(color='Newcomer') +
  scale_color_manual(labels = c("Retained", "Lost"), 
                     values = c("blue", "red"))

# save full version
ggsave(plot = retention_plot,
       height = 4,
       width = 5,
       filename = '../../figures/sentiment_analysis/ossc-retention_emotion.jpg')

# save smaller version for knitr
ggsave(plot = retention_plot,
       height = 4,
       width = 5,
       dpi = 150,
       filename = '../../figures/sentiment_analysis/ossc-retention_emotion-knitr.jpg')

```

![**Figure**. Whether a first-time issue creator will open a second issue by commenters' expressions of gratitude and responsiveness.](../../figures/sentiment_analysis/ossc-retention_emotion-knitr.jpg)

***

# Future directions

Ideas:

* Do comments, generally, get more friendly or more hostile over time?
* Does the emotional valence of a contributor's first ticket predict whether 
  they'll come back to make a second one?
* Are requesters more or less polite?
* Does friendliness bring people back?
* Does the number and intensity of negative and positive comments on a 
  first-time contributor's issue change whether they come back to make another 
  ticket?