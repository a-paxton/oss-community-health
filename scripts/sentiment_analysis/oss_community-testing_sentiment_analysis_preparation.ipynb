{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing ground: Sentiment analysis of open-source software communities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook includes the data preparation and analysis\n",
    "for our project exploring open-source software communities, along\n",
    "with space for testing and debugging the pipeline as we're working."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The code here is preserved for development purposes; the final\n",
    "version is available in `oss_community-sentiment_analysis_preparation.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this notebook, you will need the following files and directories:\n",
    "\n",
    "* `../../data/processed_data/`: Directory of files produced by `./extract_features.py`\n",
    "* `../bot_names.txt`: File of usernames identified as being bots\n",
    "* `./utils/gratitude.txt`: List of words identified as gratitude-related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most significant output of this notebook \n",
    "(`../../data/analysis_data/all-sentiment_frame-for_r.csv`) will be imported\n",
    "into `./oss_community-language_dynamics.Rmd` for data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code last updated**: 30 May 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code written by**: A. Paxton (University of Connecticut) & N. Varoquaux\n",
    "(University of California, Berkeley)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO for Nelle\n",
    "\n",
    "Extract bus_factor_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Preliminaries](#Preliminaries)\n",
    "* [Data preparation](#Data-preparation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import annotate, project_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial file cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cycle through all GitHub project files to clean data and prepare datasets as needed for analysis. \n",
    "For complete list of downloaded variables and new variables created, see `metadata.md` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all projects' raw data\n",
    "project_list = os.listdir('../../data/processed_data/dataset_upto2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the lists needed\n",
    "bot_list = pd.read_csv('../bot_names.txt')['bot_name']\n",
    "gratitude_list = set(pd.read_csv('./utils/gratitude.txt')['expressions_of_gratitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a container for the bus factor ratings\n",
    "# bus_factor_df = pd.DataFrame()\n",
    "\n",
    "# cycle through all raw data projects\n",
    "for project in project_list:\n",
    "    \n",
    "    # read in the next project's prepared files\n",
    "    issues_filename = os.path.join(\n",
    "        \"../../data/processed_data/dataset_upto2019\", project, \"processed-issues.csv\")\n",
    "    comments_filename = os.path.join(\n",
    "        \"../../data/processed_data/dataset_upto2019\", project, \"processed-comments.csv\")\n",
    "\n",
    "    temp_issues = pd.read_csv(issues_filename, sep=\",\").sort_index()\n",
    "    temp_comments = pd.read_csv(comments_filename, sep=\",\").sort_index()\n",
    "    \n",
    "    # use identical bins sizes for all histograms\n",
    "    bin_number = 50    \n",
    "    fig_dpi = 150\n",
    "    y_label_text = 'Density'\n",
    "    density_choice = True\n",
    "    alpha_level = .5\n",
    "    \n",
    "    # create overlapping histograms for emotion in comment text\n",
    "    plt.figure()\n",
    "    plt.hist(temp_comments['negative_emotion'], \n",
    "             bin_number, density=density_choice, facecolor='r', alpha=alpha_level)\n",
    "    plt.hist(temp_comments['positive_emotion'], \n",
    "             bin_number, density=density_choice, facecolor='g', alpha=alpha_level)\n",
    "    plt.hist(temp_comments['neutral_emotion'], \n",
    "             bin_number, density=density_choice, facecolor='grey', alpha=alpha_level)\n",
    "    plt.title('Histogram of emotion proportions in comment bodies\\nfor '+project)\n",
    "    plt.xlabel('Proportion of emotion words to total words')\n",
    "    plt.ylabel(y_label_text)\n",
    "    plt.grid(True)\n",
    "\n",
    "    # plot comment emotion hisogram\n",
    "    plt.savefig('../../figures/emotion_histograms/'+project+'-comment_body.png',\n",
    "               dpi=fig_dpi)\n",
    "    plt.close()\n",
    "    \n",
    "    # create overlapping histograms for emotion in issue text\n",
    "    plt.figure()\n",
    "    plt.hist(temp_issues['negative_emotion'], \n",
    "             bin_number, density=density_choice, facecolor='r', alpha=alpha_level)\n",
    "    plt.hist(temp_issues['positive_emotion'], \n",
    "             bin_number, density=density_choice, facecolor='g', alpha=alpha_level)\n",
    "    plt.hist(temp_issues['neutral_emotion'], \n",
    "             bin_number, density=density_choice, facecolor='grey', alpha=alpha_level)\n",
    "    plt.title('Histogram of emotion proportions in issue bodies\\nfor '+project)\n",
    "    plt.xlabel('Proportion of emotion words to total words')\n",
    "    plt.ylabel(y_label_text)\n",
    "    plt.grid(True)\n",
    "\n",
    "    # plot comment text\n",
    "    plt.savefig('../../figures/emotion_histograms/'+project+'-issue_body.png',\n",
    "               dpi=fig_dpi)\n",
    "    plt.close()\n",
    "    \n",
    "# save bus factor file\n",
    "# bus_factor_df.to_csv('../../data/processed_data/all-bus_factor.csv',\n",
    "#                         index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get project names again\n",
    "project_list = os.listdir('../../data/processed_data/dataset_upto2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create empty frame\n",
    "joined_issues = pd.DataFrame()\n",
    "joined_comments = pd.DataFrame()\n",
    "\n",
    "# read in joined frames for all projects\n",
    "for project in project_list:\n",
    "    # read in the next project's prepared\n",
    "    issues_filename = os.path.join(\n",
    "        \"../../data/processed_data/dataset_upto2019\", project, \"processed-issues.csv\")\n",
    "    comments_filename = os.path.join(\n",
    "        \"../../data/processed_data/dataset_upto2019\", project, \"processed-comments.csv\")\n",
    "    \n",
    "    temp_issues = pd.read_csv(issues_filename)\n",
    "    temp_comments = pd.read_csv(comments_filename)\n",
    "    joined_issues = joined_issues.append(temp_issues).reset_index(drop=True)\n",
    "    joined_comments = joined_comments.append(temp_comments).reset_index(drop=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the timestamp of the author's most recent issue and comment in this group\n",
    "most_recent_comment = (joined_comments.groupby(['project',\n",
    "                                                'author_name'])\n",
    "                                   .max()[['created_at', 'ticket_id']])\n",
    "most_recent_issue = (joined_issues.groupby(['project','author_name'])\n",
    "                                 .max()[['created_at', 'ticket_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the most recent timestamps to dataframe\n",
    "joined_comments = (joined_comments.join(most_recent_comment, on=['project', 'author_name'], rsuffix='_last')\n",
    "                               .rename(columns={\"created_at_last\": \"issue_author_last_comment_stamp\",\n",
    "                                                \"ticket_id_last\": \"issue_author_last_comment_ticket\"})\n",
    "                               .join(most_recent_issue, on=['project', 'author_name'], rsuffix='_last')\n",
    "                               .rename(columns={\"created_at_last\": \"issue_author_last_issue_stamp\",\n",
    "                                                \"ticket_id_last\": \"issue_author_last_issue_ticket\"}))\n",
    "\n",
    "joined_issues = (joined_issues.join(most_recent_comment, on=['project', 'author_name'], rsuffix='_last')\n",
    "                               .rename(columns={\"created_at_last\": \"issue_author_last_comment_stamp\",\n",
    "                                                \"ticket_id_last\": \"issue_author_last_comment_ticket\"})\n",
    "                               .join(most_recent_issue, on=['project', 'author_name'], rsuffix='_last')\n",
    "                               .rename(columns={\"created_at_last\": \"issue_author_last_issue_stamp\",\n",
    "                                                \"ticket_id_last\": \"issue_author_last_issue_ticket\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this the first ticket that the ticket author submitted?\n",
    "joined_issues['first_ticket'] = ((joined_issues['num_PR_created']==0) &\n",
    "                                 (joined_issues['num_issue_created']==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this issue the last one that the issue author submitted?\n",
    "joined_issues['issue_author_last_issue'] = (\n",
    "    joined_issues['ticket_id'] == joined_issues['issue_author_last_issue_ticket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this issue the last thing that the author worked on?\n",
    "joined_issues['issue_author_last_comment'] = (\n",
    "    joined_issues['ticket_id'] == joined_issues['issue_author_last_comment_ticket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if they've never commented, make sure we note that the issue was their last activity\n",
    "joined_issues.loc[\n",
    "    joined_issues['issue_author_last_comment_ticket'].isnull() == True, 'issue_author_last_comment'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "try:\n",
    "    os.makedirs(\"../../data/analysis_data/\")\n",
    "except OSError:\n",
    "    pass\n",
    "joined_issues.to_csv('../../data/analysis_data/sentiment_frame_tickets.csv',\n",
    "                         index=False, header=True)\n",
    "joined_comments.to_csv('../../data/analysis_data/sentiment_frame_comments.csv',\n",
    "                         index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_comments.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save one without the comment/ticket bodies for analysis in R\n",
    "joined_issues_for_r = joined_issues.drop(columns=['body', 'title', 'labels'])\n",
    "joined_issues_for_r.to_csv('../../data/analysis_data/sentiment_frame_issues-for_r.csv',\n",
    "                         index=False, header=True)\n",
    "joined_comments_for_r = joined_comments.drop(columns=['body'])\n",
    "joined_comments_for_r.to_csv('../../data/analysis_data/sentiment_frame_comments-for_r.csv',\n",
    "                         index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_issues_for_r.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_comments_for_r.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Currently porting to R for speed. Will later move back to Python.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code testing ground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'mayavi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_factor = pd.read_csv('../../data/processed_data/all-bus_factor.csv',\n",
    "                         sep=',').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_comments = pd.read_csv('../../data/raw_data/dataset_upto2019/'+project+'/comments.tsv',\n",
    "                          sep='\\t', index_col=0).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_issues = pd.read_csv('../../data/raw_data/dataset_upto2019/'+project+'/issues.tsv',\n",
    "                          sep='\\t', index_col=0).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_commits = pd.read_csv('../../data/raw_data/dataset_upto2019/'+project+'/commits.tsv',\n",
    "                               sep='\\t', index_col=0).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate the files with new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_comments, temp_issues = annotate.annotate_logs(temp_comments,temp_issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_comments = temp_comments.drop(columns=['node_id','updated_at','author_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_issues = temp_issues.drop(columns=['node_id','organization','author_id','locked'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_list = pd.read_csv('../bot_names.txt')['bot_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_comments = annotate.body_cleanup(temp_comments, bot_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_issues = annotate.body_cleanup(temp_issues, bot_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_comments = annotate.add_sentiment(temp_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_issues = annotate.add_sentiment(temp_issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agreement (+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to add this to the pipeline..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_comments['plus_1'] = temp_comments['body'].str.count('\\+1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_issues['plus_1'] = temp_issues['body'].str.count('\\+1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gratitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gratitude_list = set(pd.read_csv('./utils/gratitude.txt')['expressions_of_gratitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_comments = annotate.add_gratitude(temp_comments, gratitude_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_issues = annotate.add_gratitude(temp_issues, gratitude_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use identical bins sizes for all histograms\n",
    "bin_number = 50    \n",
    "fig_dpi = 150\n",
    "y_label_text = 'Density'\n",
    "density_choice = True\n",
    "alpha_level = .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create overlapping histograms for emotion in comment text\n",
    "plt.figure()\n",
    "plt.hist(temp_comments['negative_emotion'], \n",
    "         bin_number, density=density_choice, facecolor='r', alpha=alpha_level)\n",
    "plt.hist(temp_comments['positive_emotion'], \n",
    "         bin_number, density=density_choice, facecolor='g', alpha=alpha_level)\n",
    "plt.hist(temp_comments['neutral_emotion'], \n",
    "         bin_number, density=density_choice, facecolor='grey', alpha=alpha_level)\n",
    "plt.title('Histogram of emotion proportions in comment bodies\\nfor '+project)\n",
    "plt.xlabel('Proportion of emotion words to total words')\n",
    "plt.ylabel(y_label_text)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create overlapping histograms for emotion in issue text\n",
    "plt.figure()\n",
    "plt.hist(temp_issues['negative_emotion'], \n",
    "         bin_number, density=density_choice, facecolor='r', alpha=alpha_level)\n",
    "plt.hist(temp_issues['positive_emotion'], \n",
    "         bin_number, density=density_choice, facecolor='g', alpha=alpha_level)\n",
    "plt.hist(temp_issues['neutral_emotion'], \n",
    "         bin_number, density=density_choice, facecolor='grey', alpha=alpha_level)\n",
    "plt.title('Histogram of emotion proportions in issue bodies\\nfor '+project)\n",
    "plt.xlabel('Proportion of emotion words to total words')\n",
    "plt.ylabel(y_label_text)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = temp_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_df = temp_issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the dataframes\n",
    "joined_frame = (comments_df.join(issues_df, \n",
    "                                lsuffix='_comment',\n",
    "                                rsuffix='_issue',\n",
    "                                on='ticket_id')\n",
    "                            .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any bots and the bot columns\n",
    "joined_frame = (joined_frame.loc[(joined_frame['bot_flag_comment']==False) &\n",
    "                                   (joined_frame['bot_flag_issue']==False)]\n",
    "                            .reset_index(drop=True)\n",
    "                            .drop(columns=['bot_flag_comment','bot_flag_issue']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the timestamp of the author's most recent issue and comment in this group\n",
    "most_recent_comment = (joined_frame.groupby('author_name_comment')\n",
    "                                   .max()[['created_at_comment', 'ticket_id_issue']])\n",
    "most_recent_issue = (joined_frame.groupby('author_name_issue')\n",
    "                                 .max()[['created_at_issue', 'ticket_id_issue']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the most recent timestamps to dataframe\n",
    "joined_frame = (joined_frame.join(most_recent_comment, on='author_name_issue', rsuffix='_last')\n",
    "                               .rename(columns={\"created_at_comment_last\": \"issue_author_last_comment_stamp\",\n",
    "                                                \"ticket_id_issue_last\": \"issue_author_last_comment_ticket\"})\n",
    "                               .join(most_recent_issue, on='author_name_issue', rsuffix='_last')\n",
    "                               .rename(columns={\"created_at_issue_last\": \"issue_author_last_issue_stamp\",\n",
    "                                                \"ticket_id_issue_last\": \"issue_author_last_issue_ticket\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this the first ticket that the ticket author submitted?\n",
    "joined_frame['first_ticket'] = (joined_frame['num_PR_created_issue']==0) & (joined_frame['num_issue_created_issue']==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this issue the last one that the issue author submitted?\n",
    "joined_frame['issue_author_last_issue'] = joined_frame['ticket_id_issue']==joined_frame['issue_author_last_issue_ticket']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this issue the last thing that the author worked on?\n",
    "joined_frame['issue_author_last_comment'] = joined_frame['ticket_id_issue']==joined_frame['issue_author_last_comment_ticket']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if they've never commented, make sure we note that the issue was their last activity\n",
    "joined_frame.loc[joined_frame['issue_author_last_comment_ticket'].isnull()==True, 'issue_author_last_comment'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_frame.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason, we're getting an error for trying to join `object` and\n",
    "`int64` when we try to use `pd.DataFrame.join` on the `project` variable,\n",
    "so this is what we're doing for now instead.\n",
    "\n",
    "**Edit**: Still unsure why this is happening, but it happens whenever you\n",
    "load back in the edited dataframe files and then try to merge them. I've \n",
    "circumvented this issue for now by simply joining the dataframes as soon as \n",
    "they've been edited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_frame['bus_factor'] = (bus_factor[bus_factor['project']==project]\n",
    "                                      .reset_index()['bus_factor'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Survivor curves by emotional tenor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do comments, generally, get more friendly or more hostile over time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the emotional valence of a contributor's first ticket predict whether they'll come back to make a second one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are requesters more or less polite?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does friendliness bring people back?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the number and intensity of negative and positive comments on a first-time contributor's issue \n",
    "change whether they come back to make another ticket?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the trajectories of conversations (in each community) change over time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
