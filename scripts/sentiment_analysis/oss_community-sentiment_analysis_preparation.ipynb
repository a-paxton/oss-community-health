{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis of open-source software communities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook includes the data preparation and analysis\n",
    "for our project exploring open-source software communities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this notebook, you will need the following files and directories:\n",
    "\n",
    "* `../../data/processed_data/`: Directory of files produced by `./extract_features.py`\n",
    "* `../bot_names.txt`: File of usernames identified as being bots\n",
    "* `./utils/gratitude.txt`: List of words identified as gratitude-related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most significant output of this notebook \n",
    "(`../../data/analysis_data/all-sentiment_frame-for_r.csv`) will be imported\n",
    "into `./oss_community-language_dynamics.Rmd` for data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code last updated**: 30 May 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code written by**: A. Paxton (University of Connecticut) & N. Varoquaux\n",
    "(University of California, Berkeley)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO for Nelle\n",
    "\n",
    "Extract bus_factor_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Preliminaries](#Preliminaries)\n",
    "* [Data preparation](#Data-preparation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import annotate, project_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial file cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cycle through all GitHub project files to clean data and prepare datasets as needed for analysis. \n",
    "For complete list of downloaded variables and new variables created, see `metadata.md` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all projects' raw data\n",
    "project_list = os.listdir('../../data/processed_data/dataset_upto2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the lists needed\n",
    "bot_list = pd.read_csv('../bot_names.txt')['bot_name']\n",
    "gratitude_list = set(pd.read_csv('./utils/gratitude.txt')['expressions_of_gratitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a container for the bus factor ratings\n",
    "# bus_factor_df = pd.DataFrame()\n",
    "\n",
    "# cycle through all raw data projects\n",
    "for project in project_list:\n",
    "    \n",
    "    # automatically build paths for issues and comments\n",
    "    issues_filename = os.path.join(\n",
    "        \"../../data/processed_data/dataset_upto2019\", project, \"processed-issues.csv\")\n",
    "    comments_filename = os.path.join(\n",
    "        \"../../data/processed_data/dataset_upto2019\", project, \"processed-comments.csv\")\n",
    "    \n",
    "    # read in the next project's prepared files\n",
    "    temp_issues = pd.read_csv(issues_filename, sep=\",\").sort_index()\n",
    "    temp_comments = pd.read_csv(comments_filename, sep=\",\").sort_index()\n",
    "    \n",
    "    # use identical bins sizes for all histograms\n",
    "    bin_number = 50    \n",
    "    fig_dpi = 150\n",
    "    y_label_text = 'Density'\n",
    "    density_choice = True\n",
    "    alpha_level = .5\n",
    "    \n",
    "    # create overlapping histograms for emotion in comment text\n",
    "    plt.figure()\n",
    "    plt.hist(temp_comments['negative_emotion'], \n",
    "             bin_number, density=density_choice, facecolor='r', alpha=alpha_level)\n",
    "    plt.hist(temp_comments['positive_emotion'], \n",
    "             bin_number, density=density_choice, facecolor='g', alpha=alpha_level)\n",
    "    plt.hist(temp_comments['neutral_emotion'], \n",
    "             bin_number, density=density_choice, facecolor='grey', alpha=alpha_level)\n",
    "    plt.title('Histogram of emotion proportions in comment bodies\\nfor '+project)\n",
    "    plt.xlabel('Proportion of emotion words to total words')\n",
    "    plt.ylabel(y_label_text)\n",
    "    plt.grid(True)\n",
    "\n",
    "    # plot comment emotion hisogram\n",
    "    plt.savefig('../../figures/emotion_histograms/'+project+'-comment_body.png',\n",
    "               dpi=fig_dpi)\n",
    "    plt.close()\n",
    "    \n",
    "    # create overlapping histograms for emotion in issue text\n",
    "    plt.figure()\n",
    "    plt.hist(temp_issues['negative_emotion'], \n",
    "             bin_number, density=density_choice, facecolor='r', alpha=alpha_level)\n",
    "    plt.hist(temp_issues['positive_emotion'], \n",
    "             bin_number, density=density_choice, facecolor='g', alpha=alpha_level)\n",
    "    plt.hist(temp_issues['neutral_emotion'], \n",
    "             bin_number, density=density_choice, facecolor='grey', alpha=alpha_level)\n",
    "    plt.title('Histogram of emotion proportions in issue bodies\\nfor '+project)\n",
    "    plt.xlabel('Proportion of emotion words to total words')\n",
    "    plt.ylabel(y_label_text)\n",
    "    plt.grid(True)\n",
    "\n",
    "    # plot comment text\n",
    "    plt.savefig('../../figures/emotion_histograms/'+project+'-issue_body.png',\n",
    "               dpi=fig_dpi)\n",
    "    plt.close()\n",
    "    \n",
    "# save bus factor file\n",
    "# bus_factor_df.to_csv('../../data/processed_data/all-bus_factor.csv',\n",
    "#                         index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get project names again\n",
    "project_list = os.listdir('../../data/processed_data/dataset_upto2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create empty frame\n",
    "joined_issues = pd.DataFrame()\n",
    "joined_comments = pd.DataFrame()\n",
    "\n",
    "# read in joined frames for all projects\n",
    "for project in project_list:\n",
    "    # read in the next project's prepared\n",
    "    issues_filename = os.path.join(\n",
    "        \"../../data/processed_data/dataset_upto2019\", project, \"processed-issues.csv\")\n",
    "    comments_filename = os.path.join(\n",
    "        \"../../data/processed_data/dataset_upto2019\", project, \"processed-comments.csv\")\n",
    "    \n",
    "    temp_issues = pd.read_csv(issues_filename)\n",
    "    temp_comments = pd.read_csv(comments_filename)\n",
    "    joined_issues = joined_issues.append(temp_issues).reset_index(drop=True)\n",
    "    joined_comments = joined_comments.append(temp_comments).reset_index(drop=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the timestamp of the author's most recent issue and comment in this group\n",
    "most_recent_comment = (joined_comments.groupby(['project',\n",
    "                                                'author_name'])\n",
    "                                   .max()[['created_at', 'ticket_id']])\n",
    "most_recent_issue = (joined_issues.groupby(['project','author_name'])\n",
    "                                 .max()[['created_at', 'ticket_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the most recent timestamps to dataframe\n",
    "joined_comments = (joined_comments.join(most_recent_comment, on=['project', 'author_name'], rsuffix='_last')\n",
    "                               .rename(columns={\"created_at_last\": \"issue_author_last_comment_stamp\",\n",
    "                                                \"ticket_id_last\": \"issue_author_last_comment_ticket\"})\n",
    "                               .join(most_recent_issue, on=['project', 'author_name'], rsuffix='_last')\n",
    "                               .rename(columns={\"created_at_last\": \"issue_author_last_issue_stamp\",\n",
    "                                                \"ticket_id_last\": \"issue_author_last_issue_ticket\"}))\n",
    "\n",
    "joined_issues = (joined_issues.join(most_recent_comment, on=['project', 'author_name'], rsuffix='_last')\n",
    "                               .rename(columns={\"created_at_last\": \"issue_author_last_comment_stamp\",\n",
    "                                                \"ticket_id_last\": \"issue_author_last_comment_ticket\"})\n",
    "                               .join(most_recent_issue, on=['project', 'author_name'], rsuffix='_last')\n",
    "                               .rename(columns={\"created_at_last\": \"issue_author_last_issue_stamp\",\n",
    "                                                \"ticket_id_last\": \"issue_author_last_issue_ticket\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this the first ticket that the ticket author submitted?\n",
    "joined_issues['first_ticket'] = ((joined_issues['num_PR_created']==0) &\n",
    "                                 (joined_issues['num_issue_created']==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this issue the last one that the issue author submitted?\n",
    "joined_issues['issue_author_last_issue'] = (\n",
    "    joined_issues['ticket_id'] == joined_issues['issue_author_last_issue_ticket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this issue the last thing that the author worked on?\n",
    "joined_issues['issue_author_last_comment'] = (\n",
    "    joined_issues['ticket_id'] == joined_issues['issue_author_last_comment_ticket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if they've never commented, make sure we note that the issue was their last activity\n",
    "joined_issues.loc[\n",
    "    joined_issues['issue_author_last_comment_ticket'].isnull() == True, 'issue_author_last_comment'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "try:\n",
    "    os.makedirs(\"../../data/analysis_data/\")\n",
    "except OSError:\n",
    "    pass\n",
    "joined_issues.to_csv('../../data/analysis_data/sentiment_frame_tickets.csv',\n",
    "                         index=False, header=True)\n",
    "joined_comments.to_csv('../../data/analysis_data/sentiment_frame_comments.csv',\n",
    "                         index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save one without the comment/ticket bodies for analysis in R\n",
    "joined_issues_for_r = joined_issues.drop(columns=['body', 'title', 'labels'])\n",
    "joined_issues_for_r.to_csv('../../data/analysis_data/sentiment_frame_issues-for_r.csv',\n",
    "                         index=False, header=True)\n",
    "joined_comments_for_r = joined_comments.drop(columns=['body'])\n",
    "joined_comments_for_r.to_csv('../../data/analysis_data/sentiment_frame_comments-for_r.csv',\n",
    "                         index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_issues_for_r.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_comments_for_r.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Currently porting to R for speed. Will later move back to Python.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do comments, generally, get more friendly or more hostile over time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the emotional valence of a contributor's first ticket predict whether they'll come back to make a second one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are requesters more or less polite?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does friendliness bring people back?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the number and intensity of negative and positive comments on a first-time contributor's issue \n",
    "change whether they come back to make another ticket?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the trajectories of conversations (in each community) change over time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
