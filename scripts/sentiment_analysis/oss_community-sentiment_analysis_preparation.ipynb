{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis of open-source software communities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook includes the data preparation and analysis\n",
    "for our project exploring open-source software communities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code last updated**: 6 November 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Preliminaries](#Preliminaries)\n",
    "* [Data preparation](#Data-preparation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import annotate, project_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cycle through all GitHub project files to clean data and prepare datasets as needed for analysis. \n",
    "For complete list of downloaded variables and new variables created, see `metadata.md` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all projects' raw data\n",
    "project_list = os.listdir('../../data/raw_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the lists needed\n",
    "bot_list = pd.read_csv('../bot_names.txt')['bot_name']\n",
    "gratitude_list = set(pd.read_csv('./utils/gratitude.txt')['expressions_of_gratitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a container for the bus factor ratings\n",
    "bus_factor_df = pd.DataFrame()\n",
    "\n",
    "# cycle through all raw data projects\n",
    "for project in project_list:\n",
    "    \n",
    "    # read in the next project's files\n",
    "    temp_comments = pd.read_csv('../../data/raw_data/'+project+'/comments.tsv',\n",
    "                                sep='\\t', index_col=0).sort_index()\n",
    "    temp_issues = pd.read_csv('../../data/raw_data/'+project+'/issues.tsv',\n",
    "                              sep='\\t', index_col=0).sort_index()\n",
    "    temp_commits = pd.read_csv('../../data/raw_data/'+project+'/commits.tsv',\n",
    "                              sep='\\t', index_col=0).sort_index()\n",
    "    \n",
    "    # append the current project to each\n",
    "    temp_comments['project'] = project\n",
    "    temp_issues['project'] = project\n",
    "    temp_commits['project'] = project\n",
    "    \n",
    "    # annotate each file\n",
    "    temp_comments, temp_issues = annotate.annotate_logs(temp_comments,\n",
    "                                                        temp_issues)\n",
    "    \n",
    "    # drop columns we don't need\n",
    "    temp_comments = temp_comments.drop(columns=['node_id','updated_at','author_id'])\n",
    "    temp_issues = temp_issues.drop(columns=['node_id','organization','author_id','locked'])\n",
    "#     temp_commits = temp_commits.drop(columns=['author_id','sha'])\n",
    "    \n",
    "    # clean up the text body\n",
    "    temp_comments = annotate.body_cleanup(temp_comments, bot_list)\n",
    "    temp_issues = annotate.body_cleanup(temp_issues, bot_list)\n",
    "#     temp_commits = annotate.body_cleanup(temp_commits, bot_list)\n",
    "    \n",
    "    # run sentiment analysis\n",
    "    temp_comments = annotate.add_sentiment(temp_comments)\n",
    "    temp_issues = annotate.add_sentiment(temp_issues)\n",
    "#     temp_commits = annotate.add_sentiment(temp_commits)\n",
    "    \n",
    "    # add gratitude info\n",
    "    temp_comments = annotate.add_gratitude(temp_comments, gratitude_list)\n",
    "    temp_issues = annotate.add_gratitude(temp_issues, gratitude_list)\n",
    "#     temp_commits = annotate.add_gratitude(temp_commits, gratitude_list)\n",
    "\n",
    "    # join the dataframes\n",
    "    temp_joined_frame = (temp_comments.join(temp_issues, \n",
    "                                            lsuffix='_comment',\n",
    "                                            rsuffix='_issue',\n",
    "                                            on='ticket_id')\n",
    "                                       .reset_index(drop=True)\n",
    "                                       .drop(columns='project_comment')\n",
    "                                       .rename(columns={'project_issue': 'project'}))\n",
    "    \n",
    "    # calculate bus factor\n",
    "    temp_bus_factor = project_features.compute_bus_factor(temp_commits)\n",
    "    bus_factor_df = bus_factor_df.append({'project': project,\n",
    "                                          'bus_factor': temp_bus_factor},\n",
    "                                        ignore_index=True)\n",
    "    temp_joined_frame['bus_factor'] = temp_bus_factor\n",
    "    \n",
    "    # save cleaned data to intermediary folders\n",
    "    temp_comments.to_csv('../../data/processed_data/'+project+'-processed-comments.csv',\n",
    "                         index=False, header=True)\n",
    "    temp_issues.to_csv('../../data/processed_data/'+project+'-processed-issues.csv',\n",
    "                         index=False, header=True)\n",
    "    temp_commits.to_csv('../../data/processed_data/'+project+'-processed-commits.csv',\n",
    "                         index=False, header=True)\n",
    "    temp_joined_frame.to_csv('../../data/processed_data/'+project+'-processed-joined.csv',\n",
    "                         index=False, header=True)\n",
    "    \n",
    "    # use identical bins sizes for all histograms\n",
    "    bin_number = 50    \n",
    "    fig_dpi = 150\n",
    "    y_label_text = 'Density'\n",
    "    density_choice = True\n",
    "    alpha_level = .5\n",
    "    \n",
    "    # create overlapping histograms for emotion in comment text\n",
    "    plt.figure()\n",
    "    plt.hist(temp_comments['negative_emotion'], \n",
    "             bin_number, density=density_choice, facecolor='r', alpha=alpha_level)\n",
    "    plt.hist(temp_comments['positive_emotion'], \n",
    "             bin_number, density=density_choice, facecolor='g', alpha=alpha_level)\n",
    "    plt.hist(temp_comments['neutral_emotion'], \n",
    "             bin_number, density=density_choice, facecolor='grey', alpha=alpha_level)\n",
    "    plt.title('Histogram of emotion proportions in comment bodies\\nfor '+project)\n",
    "    plt.xlabel('Proportion of emotion words to total words')\n",
    "    plt.ylabel(y_label_text)\n",
    "    plt.grid(True)\n",
    "\n",
    "    # plot comment emotion hisogram\n",
    "    plt.savefig('../../figures/emotion_histograms/'+project+'-comment_body.png',\n",
    "               dpi=fig_dpi)\n",
    "    plt.close()\n",
    "    \n",
    "    # create overlapping histograms for emotion in issue text\n",
    "    plt.figure()\n",
    "    plt.hist(temp_issues['negative_emotion'], \n",
    "             bin_number, density=density_choice, facecolor='r', alpha=alpha_level)\n",
    "    plt.hist(temp_issues['positive_emotion'], \n",
    "             bin_number, density=density_choice, facecolor='g', alpha=alpha_level)\n",
    "    plt.hist(temp_issues['neutral_emotion'], \n",
    "             bin_number, density=density_choice, facecolor='grey', alpha=alpha_level)\n",
    "    plt.title('Histogram of emotion proportions in issue bodies\\nfor '+project)\n",
    "    plt.xlabel('Proportion of emotion words to total words')\n",
    "    plt.ylabel(y_label_text)\n",
    "    plt.grid(True)\n",
    "\n",
    "    # plot comment text\n",
    "    plt.savefig('../../figures/emotion_histograms/'+project+'-issue_body.png',\n",
    "               dpi=fig_dpi)\n",
    "    plt.close()\n",
    "    \n",
    "# save bus factor file\n",
    "bus_factor_df.to_csv('../../data/processed_data/all-bus_factor.csv',\n",
    "                         index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get project names again\n",
    "project_list = os.listdir('../../data/raw_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty frame\n",
    "joined_frame = pd.DataFrame()\n",
    "\n",
    "# read in joined frames for all projects\n",
    "for project in project_list:\n",
    "\n",
    "    # read in the next project's prepared files\n",
    "    temp_joined_frame = pd.read_csv('../../data/processed_data/'+project+'-processed-joined.csv',\n",
    "                                    sep=',').sort_index()\n",
    "\n",
    "    # append to dataframe\n",
    "    joined_frame = joined_frame.append(temp_joined_frame).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any bots and the bot columns\n",
    "joined_frame = (joined_frame.loc[(joined_frame['bot_flag_comment']==False) &\n",
    "                                   (joined_frame['bot_flag_issue']==False)]\n",
    "                            .reset_index(drop=True)\n",
    "                            .drop(columns=['bot_flag_comment','bot_flag_issue']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the timestamp of the author's most recent issue and comment in this group\n",
    "most_recent_comment = (joined_frame.groupby(['project',\n",
    "                                            'author_name_comment'])\n",
    "                                   .max()[['created_at_comment', 'ticket_id_issue']])\n",
    "most_recent_issue = (joined_frame.groupby(['project','author_name_issue'])\n",
    "                                 .max()[['created_at_issue', 'ticket_id_issue']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the most recent timestamps to dataframe\n",
    "joined_frame = (joined_frame.join(most_recent_comment, on=['project', 'author_name_issue'], rsuffix='_last')\n",
    "                               .rename(columns={\"created_at_comment_last\": \"issue_author_last_comment_stamp\",\n",
    "                                                \"ticket_id_issue_last\": \"issue_author_last_comment_ticket\"})\n",
    "                               .join(most_recent_issue, on=['project', 'author_name_issue'], rsuffix='_last')\n",
    "                               .rename(columns={\"created_at_issue_last\": \"issue_author_last_issue_stamp\",\n",
    "                                                \"ticket_id_issue_last\": \"issue_author_last_issue_ticket\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this the first ticket that the ticket author submitted?\n",
    "joined_frame['first_ticket'] = (joined_frame['num_PR_created_issue']==0) & (joined_frame['num_issue_created_issue']==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this issue the last one that the issue author submitted?\n",
    "joined_frame['issue_author_last_issue'] = joined_frame['ticket_id_issue']==joined_frame['issue_author_last_issue_ticket']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this issue the last thing that the author worked on?\n",
    "joined_frame['issue_author_last_comment'] = joined_frame['ticket_id_issue']==joined_frame['issue_author_last_comment_ticket']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if they've never commented, make sure we note that the issue was their last activity\n",
    "joined_frame.loc[joined_frame['issue_author_last_comment_ticket'].isnull()==True, 'issue_author_last_comment'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "joined_frame.to_csv('../../data/analysis_data/all-sentiment_frame.csv',\n",
    "                         index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save one without the comment/ticket bodies for analysis in R\n",
    "joined_frame_for_r = joined_frame.drop(columns=['body_comment','body_issue', 'title', 'labels'])\n",
    "joined_frame_for_r.to_csv('../../data/analysis_data/all-sentiment_frame-for_r.csv',\n",
    "                         index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_frame_for_r.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Currently porting to R for speed. Will later move back to Python.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code testing ground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'mayavi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_factor = pd.read_csv('../../data/processed_data/all-bus_factor.csv',\n",
    "                         sep=',').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_comments = pd.read_csv('../../data/raw_data/'+project+'/comments.tsv',\n",
    "                          sep='\\t', index_col=0).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_issues = pd.read_csv('../../data/raw_data/'+project+'/issues.tsv',\n",
    "                          sep='\\t', index_col=0).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_commits = pd.read_csv('../../data/raw_data/'+project+'/commits.tsv',\n",
    "                               sep='\\t', index_col=0).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate the files with new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_comments, temp_issues = annotate.annotate_logs(temp_comments,temp_issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_comments = temp_comments.drop(columns=['node_id','updated_at','author_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_issues = temp_issues.drop(columns=['node_id','organization','author_id','locked'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_list = pd.read_csv('../bot_names.txt')['bot_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_comments = annotate.body_cleanup(temp_comments, bot_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_issues = annotate.body_cleanup(temp_issues, bot_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_comments = annotate.add_sentiment(temp_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_issues = annotate.add_sentiment(temp_issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gratitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gratitude_list = set(pd.read_csv('./utils/gratitude.txt')['expressions_of_gratitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_comments = annotate.add_gratitude(temp_comments, gratitude_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_issues = annotate.add_gratitude(temp_issues, gratitude_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use identical bins sizes for all histograms\n",
    "bin_number = 50    \n",
    "fig_dpi = 150\n",
    "y_label_text = 'Density'\n",
    "density_choice = True\n",
    "alpha_level = .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create overlapping histograms for emotion in comment text\n",
    "plt.figure()\n",
    "plt.hist(temp_comments['negative_emotion'], \n",
    "         bin_number, density=density_choice, facecolor='r', alpha=alpha_level)\n",
    "plt.hist(temp_comments['positive_emotion'], \n",
    "         bin_number, density=density_choice, facecolor='g', alpha=alpha_level)\n",
    "plt.hist(temp_comments['neutral_emotion'], \n",
    "         bin_number, density=density_choice, facecolor='grey', alpha=alpha_level)\n",
    "plt.title('Histogram of emotion proportions in comment bodies\\nfor '+project)\n",
    "plt.xlabel('Proportion of emotion words to total words')\n",
    "plt.ylabel(y_label_text)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create overlapping histograms for emotion in issue text\n",
    "plt.figure()\n",
    "plt.hist(temp_issues['negative_emotion'], \n",
    "         bin_number, density=density_choice, facecolor='r', alpha=alpha_level)\n",
    "plt.hist(temp_issues['positive_emotion'], \n",
    "         bin_number, density=density_choice, facecolor='g', alpha=alpha_level)\n",
    "plt.hist(temp_issues['neutral_emotion'], \n",
    "         bin_number, density=density_choice, facecolor='grey', alpha=alpha_level)\n",
    "plt.title('Histogram of emotion proportions in issue bodies\\nfor '+project)\n",
    "plt.xlabel('Proportion of emotion words to total words')\n",
    "plt.ylabel(y_label_text)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = temp_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_df = temp_issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_frame = comments_df.join(issues_df, \n",
    "                                lsuffix='_comment',\n",
    "                                rsuffix='_issue',\n",
    "                                on='ticket_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the timestamp of the author's most recent issue and comment in this group\n",
    "most_recent_comment = joined_frame.groupby('author_name_comment').max()['created_at_comment']\n",
    "most_recent_issue = joined_frame.groupby('author_name_issue').max()['created_at_issue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the most recent timestamps to dataframe\n",
    "joined_frame = (joined_frame.join(most_recent_comment, on='author_name_issue', rsuffix='_last')\n",
    "                               .rename(columns={\"created_at_comment_last\": \"issue_author_last_comment_stamp\"})\n",
    "                               .join(most_recent_issue, on='author_name_issue', rsuffix='_last')\n",
    "                               .rename(columns={\"created_at_issue_last\": \"issue_author_last_issue_stamp\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this the first ticket that the ticket author submitted?\n",
    "joined_frame['first_ticket'] = (joined_frame['num_PR_created_issue']==0) & (joined_frame['num_issue_created_issue']==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this issue the last one that the issue author submitted?\n",
    "joined_frame['issue_author_last_issue'] = joined_frame['created_at_issue']==joined_frame['issue_author_last_issue_stamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this issue the last thing that the author worked on?\n",
    "joined_frame['issue_author_last_contribution'] = joined_frame['created_at_issue'] > joined_frame['issue_author_last_comment_stamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if they've never commented, make sure we note that the issue was their last activity\n",
    "joined_frame.loc[joined_frame['issue_author_last_comment_ticket'].isnull()==True, 'issue_author_last_comment'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_frame.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason, we're getting an error for trying to join `object` and\n",
    "`int64` when we try to use `pd.DataFrame.join` on the `project` variable,\n",
    "so this is what we're doing for now instead.\n",
    "\n",
    "**Edit**: Still unsure why this is happening, but it happens whenever you\n",
    "load back in the edited dataframe files and then try to merge them. I've \n",
    "circumvented this issue for now by simply joining the dataframes as soon as \n",
    "they've been edited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_frame['bus_factor'] = (bus_factor[bus_factor['project']==project]\n",
    "                                      .reset_index()['bus_factor'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Survivor curves by emotional tenor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do comments, generally, get more friendly or more hostile over time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the emotional valence of a contributor's first ticket predict whether they'll come back to make a second one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are requesters more or less polite?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does friendliness bring people back?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the number and intensity of negative and positive comments on a first-time contributor's issue \n",
    "change whether they come back to make another ticket?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
