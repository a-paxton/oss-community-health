{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis of open-source software communities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook includes the data preparation and analysis\n",
    "for our project exploring open-source software communities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code last updated**: 6 November 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Preliminaries](#Preliminaries)\n",
    "* [Data preparation](#Data-preparation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, nltk, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import annotate\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cycle through all GitHub project files to clean data and prepare datasets as needed for analysis. \n",
    "For complete list of downloaded variables and new variables created, see `metadata.md` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all projects\n",
    "project_list = os.listdir('../../data/raw_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the list of bots\n",
    "bot_list = pd.read_csv('../bot_names.txt')['bot_name']\n",
    "\n",
    "# cycle through all \n",
    "for project in project_list:\n",
    "    \n",
    "    # read in the next comments and issues files\n",
    "    temp_comments = pd.read_csv('../../data/raw_data/'+project+'/comments.tsv',\n",
    "                                sep='\\t', index_col=0).sort_index()\n",
    "    temp_issues = pd.read_csv('../../data/raw_data/'+project+'/issues.tsv',\n",
    "                              sep='\\t', index_col=0).sort_index()\n",
    "    \n",
    "    # append the current project to each\n",
    "    temp_comments['project'] = project\n",
    "    temp_issues['project'] = project\n",
    "    \n",
    "    # annotate each file\n",
    "    temp_comments, temp_issues = annotate.annotate_comments_tickets(temp_comments,\n",
    "                                                                    temp_issues)\n",
    "    \n",
    "    # drop columns we don't need\n",
    "    temp_comments = temp_comments.drop(columns=['node_id','created_at',\n",
    "                                                'updated_at','author_id'])\n",
    "    temp_issues = temp_issues.drop(columns=['node_id','organization',\n",
    "                                          'author_id','locked'])\n",
    "    \n",
    "    # clean up the text body\n",
    "    temp_comments = annotate.comment_cleanup(temp_comments, bot_list)\n",
    "    temp_issues = annotate.comment_cleanup(temp_issues, bot_list)\n",
    "    \n",
    "    # run sentiment analysis\n",
    "    temp_comments = annotate.add_sentiment(temp_comments)\n",
    "    temp_issues = annotate.add_sentiment(temp_issues)\n",
    "    \n",
    "    # save cleaned data to intermediary folders\n",
    "    temp_comments.to_csv('../../data/processed_data/'+project+'-processed-comments.csv',\n",
    "                         index=False, header=True)\n",
    "    temp_issues.to_csv('../../data/processed_data/'+project+'-processed-issues.csv',\n",
    "                         index=False, header=True)\n",
    "    \n",
    "    # create overlapping histograms\n",
    "    bin_number = 10\n",
    "    plt.hist(temp_comments['negative_emotion'], \n",
    "             bin_number, facecolor='r', alpha=0.5)\n",
    "    plt.hist(temp_comments['positive_emotion'], \n",
    "             bin_number, facecolor='g', alpha=0.5)\n",
    "    plt.hist(temp_comments['neutral_emotion'], \n",
    "             bin_number, facecolor='grey', alpha=0.75)\n",
    "\n",
    "    # create labels\n",
    "    plt.title('Histogram of emotion proportions in comment bodies\\nfor '+project)\n",
    "    plt.xlabel('Proportion of emotion words to total words')\n",
    "    plt.ylabel('Counts')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # plot it\n",
    "    plt.savefig('../../figures/emotion_histograms/'+project+'.png',\n",
    "               dpi=150)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_df = pd.read_csv('../../data/mayavi/issues.tsv',\n",
    "                          sep='\\t', index_col=0).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code testing ground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = pd.read_csv('../../data/raw_data/mayavi/comments.tsv',\n",
    "                          sep='\\t', index_col=0).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_df = pd.read_csv('../../data/raw_data/mayavi/issues.tsv',\n",
    "                          sep='\\t', index_col=0).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate the files with new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_df, issues_df = annotate.annotate_comments_tickets(comments_df,issues_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unnecessary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both dataframes, remove unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_df = comment_df.drop(columns=['node_id','created_at','updated_at','author_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_df = issues_df.drop(columns=['node_id','organization','author_id','locked'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remove text quotes, code blocks, and newlines.\n",
    "* Identify referenced users and non-human users.\n",
    "* Identify referenced users and non-human users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_df = annotate.comment_cleanup(comment_df, \n",
    "                                      pd.read_csv('../bot_names.txt')['bot_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_df = annotate.comment_cleanup(issues_df, \n",
    "                                      pd.read_csv('../bot_names.txt')['bot_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run sentiment analyzer over comment bodies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_df = annotate.add_sentiment(comment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_df = annotate.add_sentiment(issues_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the general emotional tenor of this community?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'mayavi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a bin number\n",
    "bin_number = 10\n",
    "\n",
    "# create overlapping histograms\n",
    "plt.hist(comment_df['negative_emotion'], \n",
    "         bin_number, facecolor='r', alpha=0.5)\n",
    "plt.hist(comment_df['positive_emotion'], \n",
    "         bin_number, facecolor='g', alpha=0.5)\n",
    "plt.hist(comment_df['neutral_emotion'], \n",
    "         bin_number, facecolor='grey', alpha=0.75)\n",
    "\n",
    "# create labels\n",
    "plt.title('Histogram of emotion proportions in comment bodies\\nfor mayavi')\n",
    "plt.xlabel('Proportion of emotion words to total words')\n",
    "plt.ylabel('Counts')\n",
    "plt.grid(True)\n",
    "\n",
    "# plot it\n",
    "plt.savefig('../../figures/emotion_histograms/'+project+'.png',\n",
    "           dpi=150)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
